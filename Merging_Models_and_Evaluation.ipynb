{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3.11 -m pip install --upgrade pip setuptools wheel\n",
    "\n",
    "!python3.11 -m pip install transformers datasets bert-score llama-cpp-python peft trl\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install bert_score llama-cpp-python\n",
    "\n",
    "!{sys.executable} -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 \n",
    "\n",
    "!pip show transformers\n",
    "!pip show trl\n",
    "!pip show peft\n",
    "\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jZMdp0E02735"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEaR65l83sqT"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"----\") # Put in your Hugging Face Token here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345,
     "referenced_widgets": [
      "0994b4f2277f4c7cae295bf8c9e413f6",
      "84c8c20e02774ede96768e4ed9983f62",
      "5b5a332cda7a446d91201e61794658af",
      "eb5693ff20c14e24a210f2e2518780c4",
      "93eab46e8f4e476996d8924f59cc2b70",
      "c75c014eb20f4f23bda9e6f89efa7766",
      "e97e42daf542446993b8d33fc2f20313",
      "fae2590ce87d4f67bad72279a3bfcbc5",
      "cfdfc5378eb144659dcad68fba408887",
      "400561504e604ed183c799bd4dcb32ba",
      "72dad2cfe6af48688783eef9b888feef",
      "79967df77bd14dec808f46ebb7860487",
      "b64101b9cb414947ab3017ed6168533f",
      "e766b80163cc4ed583e33fa4f90ca608",
      "63642d304461443fba6e9f37ab644bab",
      "2c23bdcf40b04c058e6600e6377ce525",
      "d8fc7192f40748899681df2bd01e79b8",
      "7fd720c03370455893704a4c980b3229",
      "2a15e4161972427f83023fac141a7af7",
      "5a7643587f704932bc6a8c47f58e720b",
      "31eb546c6a674e5c9505c2ed6a8592b6",
      "0d15b60eac0244e7baeed958bffe06a4",
      "c91718027fbb42438354b23afa1faa19",
      "90195d993564483c9d7a2ab39f1876fd",
      "7497de783d374200ad461531f5b070f8",
      "43e4cccc375f489eb9cd60522e7b106d",
      "2cbb0bd72b684576b0a22d23d20a1136",
      "ae2269e0a6b84aa8952ebcd2aaa5755c",
      "9909d6f0d22042cbb4d2840d0df04dfe",
      "954deda696d44e149da468cb044a569e",
      "3a0d28bcfd724c7c802bad4c1e35c887",
      "03742ca8f0f64ca4b0f31ec9c094f6fb",
      "446061878beb4ecc8bf07725876f0ac3",
      "a4b932b835234279b361aab1a5cfae9c",
      "ce809809448f42ae86230a68e70c46e0",
      "6948ae96ea4945ab9d6698850d77795e",
      "58bf3d73c97c4f128565aef1f09135b5",
      "9a132782006f45cab2bad7ece20e64cf",
      "76a52ba3e7b544db8c9d546c82e96cd4",
      "9d7f601e1a71457f8a8bea8619ec4bee",
      "8c51a29a6f13436481c793f938544714",
      "b5960a63868c4aa18ac3b507b25750d6",
      "a48f4f5470814f9d99fff6fc26e21c23",
      "eb1ebacb23324f35a1dcfd584d6ff70f",
      "88884cca615f4f1ea9247f12e5624ae0",
      "f684efaa68d140db96ffd07c16432da0",
      "45666996b40a48aab86346d104598396",
      "feeacebb2051403693905f5108ffa216",
      "a1d1b3ca9d814da498ff6fbe84a65aeb",
      "f1dc578700a7412d9b8ac8e90e8bda5b",
      "9e8613fe87e5437ba0b56054ae589b64",
      "56afee73304f46769ba4540e5b948950",
      "1b9b479a729b417288b35d7e063811d2",
      "066899c1d2474d61976be431588b678a",
      "7234a61c87304727ba52bcbbd0237c59",
      "956d81bc64b6496eadedf3e146abf63d",
      "14b27c4a88ca44f1be0dc7c4d5ecdb1d",
      "12638571d5514bd0bdd92eb53fbc85c0",
      "48ab1e8d79f944178c0029c47c3c536c",
      "c525a7d9f0394d55bb9152c5a33b6503",
      "800acb17d0834793b13fd543a93e2d6f",
      "ae7aee0f7d8d4c90842c1edd9e89564a",
      "e0eba376927048dfb4ed23363c45e122",
      "5f868c83de0741af90b6ea4c931edec9",
      "e2f30b8dafa64954b6803a3286b8bf01",
      "ee3092c7a3784539937b00165544bd1b",
      "66da01361dcd4b3cb426ff28814ba317",
      "ed0325dd08a44a68a54dca6ab6bc1ad7",
      "a2794e32c1974e7e8f9e7478baadfbeb",
      "bedf1a44baad417ba144c6149688af5e",
      "d166eeec8d414e9fbe6b807d07648f65",
      "6e6e9450b6264254960b0296233c74c6",
      "b9f84ab2f3d047efbf3a1edf053af384",
      "db069c410e1948b9b1e5fc597fc1bd44",
      "9d620eaffd804253b1a0acbd3264d70d",
      "39a245e31a5046559a33e6c91f383510",
      "8b1ae460628c43cc8b8913a4675e2193"
     ]
    },
    "id": "IZAuNL5w3CMy",
    "outputId": "157e7f44-cf32-4e67-dbfa-e9aa64e8ef03"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b64acf14f84f3cb66ba591b1158d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instruct model: meta-llama/Llama-3.2-3B-Instruct\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./base_instruct_model/tokenizer_config.json',\n",
       " './base_instruct_model/special_tokens_map.json',\n",
       " './base_instruct_model/chat_template.jinja',\n",
       " './base_instruct_model/tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.save_pretrained(\"./base_instruct_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "tokenizer.save_pretrained(\"./base_instruct_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:hf-to-gguf:Loading model: base_instruct_model\n",
      "INFO:hf-to-gguf:Model architecture: LlamaForCausalLM\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:rope_freqs.weight,           torch.float32 --> F32, shape = {64}\n",
      "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00002.safetensors'\n",
      "INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {3072, 128256}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00002.safetensors'\n",
      "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:gguf: context length = 131072\n",
      "INFO:hf-to-gguf:gguf: embedding length = 3072\n",
      "INFO:hf-to-gguf:gguf: feed forward length = 8192\n",
      "INFO:hf-to-gguf:gguf: head count = 24\n",
      "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
      "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
      "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
      "INFO:hf-to-gguf:gguf: file type = 1\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "WARNING:gguf.vocab:Unknown separator token '<|begin_of_text|>' in TemplateProcessing<pair>\n",
      "INFO:gguf.vocab:Adding 280147 merge(s).\n",
      "INFO:gguf.vocab:Setting special token type bos to 128000\n",
      "INFO:gguf.vocab:Setting special token type eos to 128009\n",
      "INFO:gguf.vocab:Setting add_bos_token to True\n",
      "INFO:gguf.vocab:Setting add_sep_token to False\n",
      "INFO:gguf.vocab:Setting chat_template to {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- if strftime_now is defined %}\n",
      "        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n",
      "    {%- else %}\n",
      "        {%- set date_string = \"26 Jul 2024\" %}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "        {{- '\"parameters\": ' }}\n",
      "        {{- tool_call.arguments | tojson }}\n",
      "        {{- \"}\" }}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:quantized_models/fp16-ft-base.gguf: n_tensors = 255, total_size = 6.4G\n",
      "Writing: 100%|██████████████████████████| 6.43G/6.43G [01:12<00:00, 89.0Mbyte/s]\n",
      "INFO:hf-to-gguf:Model successfully exported to quantized_models/fp16-ft-base.gguf\n"
     ]
    }
   ],
   "source": [
    "# Convert instruct model to GGUF - this will be the baseline comparison\n",
    "!python llama.cpp/convert_hf_to_gguf.py ./base_instruct_model --outtype f16 --outfile ./quantized_models/fp16-ft-base.gguf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clone llama.cpp to quantize the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ur6HThz6IKAr",
    "outputId": "d07fa7b2-a749-4107-9da0-256c4f1804f4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'llama.cpp' already exists and is not an empty directory.\n",
      "Already up to date.\n",
      "Makefile:6: *** Build system changed:\n",
      " The Makefile build has been replaced by CMake.\n",
      "\n",
      " For build instructions see:\n",
      " https://github.com/ggml-org/llama.cpp/blob/master/docs/build.md\n",
      "\n",
      ".  Stop.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/nightly, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/nightly, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/nightly\n",
      "Collecting git+https://github.com/huggingface/transformers@v4.56.0-Embedding-Gemma-preview (from -r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 8))\n",
      "  Cloning https://github.com/huggingface/transformers (to revision v4.56.0-Embedding-Gemma-preview) to /tmp/pip-req-build-nz6yja8m\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-nz6yja8m\n",
      "  Running command git checkout -q 60b68e304cf4b6569b0660a13b558b929d4b0e77\n",
      "  Resolved https://github.com/huggingface/transformers to commit 60b68e304cf4b6569b0660a13b558b929d4b0e77\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hIgnoring torch: markers 'platform_machine == \"s390x\"' don't match your environment\n",
      "Ignoring torch: markers 'platform_machine == \"s390x\"' don't match your environment\n",
      "Requirement already satisfied: numpy~=1.26.4 in /tc1apps/anaconda3/lib/python3.12/site-packages (from -r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: sentencepiece~=0.2.0 in ./.local/lib/python3.12/site-packages (from -r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 2)) (0.2.1)\n",
      "Requirement already satisfied: gguf>=0.1.0 in ./.local/lib/python3.12/site-packages (from -r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 13)) (0.17.1)\n",
      "Requirement already satisfied: protobuf<5.0.0,>=4.21.0 in /tc1apps/anaconda3/lib/python3.12/site-packages (from -r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 14)) (4.25.3)\n",
      "Requirement already satisfied: mistral-common>=1.8.3 in ./.local/lib/python3.12/site-packages (from -r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 1)) (1.8.5)\n",
      "Requirement already satisfied: torch~=2.6.0 in ./.local/lib/python3.12/site-packages (from -r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 7)) (2.6.0+cpu)\n",
      "Requirement already satisfied: aiohttp~=3.9.3 in ./.local/lib/python3.12/site-packages (from -r llama.cpp/./requirements/requirements-tool_bench.txt (line 1)) (3.9.5)\n",
      "Requirement already satisfied: pytest~=8.3.3 in ./.local/lib/python3.12/site-packages (from -r llama.cpp/./requirements/requirements-tool_bench.txt (line 2)) (8.3.5)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.34.0 in ./.local/lib/python3.12/site-packages (from -r llama.cpp/./requirements/requirements-tool_bench.txt (line 3)) (0.35.0)\n",
      "Requirement already satisfied: matplotlib~=3.10.0 in ./.local/lib/python3.12/site-packages (from -r llama.cpp/./requirements/requirements-tool_bench.txt (line 4)) (3.10.6)\n",
      "Requirement already satisfied: openai~=1.55.3 in ./.local/lib/python3.12/site-packages (from -r llama.cpp/./requirements/requirements-tool_bench.txt (line 6)) (1.55.3)\n",
      "Requirement already satisfied: pandas~=2.2.3 in ./.local/lib/python3.12/site-packages (from -r llama.cpp/./requirements/requirements-tool_bench.txt (line 7)) (2.2.3)\n",
      "Requirement already satisfied: prometheus-client~=0.20.0 in ./.local/lib/python3.12/site-packages (from -r llama.cpp/./requirements/requirements-tool_bench.txt (line 8)) (0.20.0)\n",
      "Requirement already satisfied: requests~=2.32.3 in /tc1apps/anaconda3/lib/python3.12/site-packages (from -r llama.cpp/./requirements/requirements-tool_bench.txt (line 9)) (2.32.3)\n",
      "Requirement already satisfied: wget~=3.2 in ./.local/lib/python3.12/site-packages (from -r llama.cpp/./requirements/requirements-tool_bench.txt (line 10)) (3.2)\n",
      "Requirement already satisfied: typer~=0.15.1 in ./.local/lib/python3.12/site-packages (from -r llama.cpp/./requirements/requirements-tool_bench.txt (line 11)) (0.15.4)\n",
      "Requirement already satisfied: seaborn~=0.13.2 in /tc1apps/anaconda3/lib/python3.12/site-packages (from -r llama.cpp/./requirements/requirements-tool_bench.txt (line 12)) (0.13.2)\n",
      "Requirement already satisfied: filelock in /tc1apps/anaconda3/lib/python3.12/site-packages (from transformers==4.57.0.dev0->-r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 8)) (3.13.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /tc1apps/anaconda3/lib/python3.12/site-packages (from transformers==4.57.0.dev0->-r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 8)) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /tc1apps/anaconda3/lib/python3.12/site-packages (from transformers==4.57.0.dev0->-r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 8)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /tc1apps/anaconda3/lib/python3.12/site-packages (from transformers==4.57.0.dev0->-r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 8)) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.local/lib/python3.12/site-packages (from transformers==4.57.0.dev0->-r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 8)) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.local/lib/python3.12/site-packages (from transformers==4.57.0.dev0->-r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 8)) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /tc1apps/anaconda3/lib/python3.12/site-packages (from transformers==4.57.0.dev0->-r llama.cpp/./requirements/requirements-convert_legacy_llama.txt (line 8)) (4.66.5)\n",
      "Requirement already satisfied: pydantic<3.0,>=2.7 in /tc1apps/anaconda3/lib/python3.12/site-packages (from mistral-common>=1.8.3->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: jsonschema>=4.21.1 in /tc1apps/anaconda3/lib/python3.12/site-packages (from mistral-common>=1.8.3->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 1)) (4.23.0)\n",
      "Requirement already satisfied: typing-extensions>=4.11.0 in /tc1apps/anaconda3/lib/python3.12/site-packages (from mistral-common>=1.8.3->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in ./.local/lib/python3.12/site-packages (from mistral-common>=1.8.3->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 1)) (0.12.0)\n",
      "Requirement already satisfied: pillow>=10.3.0 in /tc1apps/anaconda3/lib/python3.12/site-packages (from mistral-common>=1.8.3->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 1)) (10.4.0)\n",
      "Requirement already satisfied: pydantic-extra-types>=2.10.5 in ./.local/lib/python3.12/site-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral-common>=1.8.3->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 1)) (2.10.5)\n",
      "Requirement already satisfied: networkx in /tc1apps/anaconda3/lib/python3.12/site-packages (from torch~=2.6.0->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 7)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /tc1apps/anaconda3/lib/python3.12/site-packages (from torch~=2.6.0->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 7)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /tc1apps/anaconda3/lib/python3.12/site-packages (from torch~=2.6.0->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 7)) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /tc1apps/anaconda3/lib/python3.12/site-packages (from torch~=2.6.0->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 7)) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.12/site-packages (from torch~=2.6.0->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 7)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /tc1apps/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch~=2.6.0->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /tc1apps/anaconda3/lib/python3.12/site-packages (from aiohttp~=3.9.3->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /tc1apps/anaconda3/lib/python3.12/site-packages (from aiohttp~=3.9.3->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 1)) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /tc1apps/anaconda3/lib/python3.12/site-packages (from aiohttp~=3.9.3->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /tc1apps/anaconda3/lib/python3.12/site-packages (from aiohttp~=3.9.3->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 1)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /tc1apps/anaconda3/lib/python3.12/site-packages (from aiohttp~=3.9.3->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 1)) (1.11.0)\n",
      "Requirement already satisfied: iniconfig in /tc1apps/anaconda3/lib/python3.12/site-packages (from pytest~=8.3.3->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in ./.local/lib/python3.12/site-packages (from pytest~=8.3.3->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 2)) (1.6.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.local/lib/python3.12/site-packages (from huggingface_hub<1.0,>=0.34.0->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 3)) (1.1.10)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /tc1apps/anaconda3/lib/python3.12/site-packages (from matplotlib~=3.10.0->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /tc1apps/anaconda3/lib/python3.12/site-packages (from matplotlib~=3.10.0->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 4)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /tc1apps/anaconda3/lib/python3.12/site-packages (from matplotlib~=3.10.0->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 4)) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /tc1apps/anaconda3/lib/python3.12/site-packages (from matplotlib~=3.10.0->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 4)) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /tc1apps/anaconda3/lib/python3.12/site-packages (from matplotlib~=3.10.0->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 4)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /tc1apps/anaconda3/lib/python3.12/site-packages (from matplotlib~=3.10.0->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /tc1apps/anaconda3/lib/python3.12/site-packages (from openai~=1.55.3->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 6)) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /tc1apps/anaconda3/lib/python3.12/site-packages (from openai~=1.55.3->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 6)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /tc1apps/anaconda3/lib/python3.12/site-packages (from openai~=1.55.3->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 6)) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.local/lib/python3.12/site-packages (from openai~=1.55.3->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: sniffio in /tc1apps/anaconda3/lib/python3.12/site-packages (from openai~=1.55.3->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /tc1apps/anaconda3/lib/python3.12/site-packages (from pandas~=2.2.3->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 7)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /tc1apps/anaconda3/lib/python3.12/site-packages (from pandas~=2.2.3->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 7)) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /tc1apps/anaconda3/lib/python3.12/site-packages (from requests~=2.32.3->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 9)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /tc1apps/anaconda3/lib/python3.12/site-packages (from requests~=2.32.3->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 9)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /tc1apps/anaconda3/lib/python3.12/site-packages (from requests~=2.32.3->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 9)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /tc1apps/anaconda3/lib/python3.12/site-packages (from requests~=2.32.3->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 9)) (2024.8.30)\n",
      "Requirement already satisfied: click<8.2,>=8.0.0 in /tc1apps/anaconda3/lib/python3.12/site-packages (from typer~=0.15.1->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 11)) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.local/lib/python3.12/site-packages (from typer~=0.15.1->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 11)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /tc1apps/anaconda3/lib/python3.12/site-packages (from typer~=0.15.1->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 11)) (13.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /tc1apps/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai~=1.55.3->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 6)) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /tc1apps/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai~=1.55.3->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 6)) (0.14.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /tc1apps/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.21.1->mistral-common>=1.8.3->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 1)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /tc1apps/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.21.1->mistral-common>=1.8.3->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 1)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /tc1apps/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.21.1->mistral-common>=1.8.3->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 1)) (0.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /tc1apps/anaconda3/lib/python3.12/site-packages (from pydantic<3.0,>=2.7->mistral-common>=1.8.3->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /tc1apps/anaconda3/lib/python3.12/site-packages (from pydantic<3.0,>=2.7->mistral-common>=1.8.3->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 1)) (2.20.1)\n",
      "Requirement already satisfied: pycountry>=23 in ./.local/lib/python3.12/site-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral-common>=1.8.3->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 1)) (24.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /tc1apps/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib~=3.10.0->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /tc1apps/anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->typer~=0.15.1->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 11)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /tc1apps/anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->typer~=0.15.1->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 11)) (2.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /tc1apps/anaconda3/lib/python3.12/site-packages (from jinja2->torch~=2.6.0->-r llama.cpp/./requirements/requirements-convert_hf_to_gguf.txt (line 7)) (2.1.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /tc1apps/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer~=0.15.1->-r llama.cpp/./requirements/requirements-tool_bench.txt (line 11)) (0.1.0)\n",
      "git: 'lfs' is not a git command. See 'git --help'.\n",
      "\n",
      "The most similar command is\n",
      "\trefs\n",
      "fatal: destination path 'career-advisory-lora-llama3.2-3b-v4' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ggerganov/llama.cpp\n",
    "!cd llama.cpp && git pull && make clean && LLAMA_CUBLAS=1 make\n",
    "!pip install -r llama.cpp/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HPWZxEVGIPuq",
    "outputId": "5ef9955f-ec0f-4625-a659-5663990f0cf5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The C compiler identification is GNU 11.5.0\n",
      "-- The CXX compiler identification is GNU 11.5.0\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Check for working C compiler: /usr/bin/cc - skipped\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "\u001b[0mCMAKE_BUILD_TYPE=Release\u001b[0m\n",
      "-- Found Git: /usr/bin/git (found version \"2.47.3\")\n",
      "-- The ASM compiler identification is GNU\n",
      "-- Found assembler: /usr/bin/cc\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
      "-- Found Threads: TRUE\n",
      "-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n",
      "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
      "-- GGML_SYSTEM_ARCH: x86\n",
      "-- Including CPU backend\n",
      "-- Found OpenMP_C: -fopenmp (found version \"4.5\")\n",
      "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\")\n",
      "-- Found OpenMP: TRUE (found version \"4.5\")\n",
      "-- x86 detected\n",
      "-- Adding CPU backend variant ggml-cpu: -march=native \n",
      "-- Found CUDAToolkit: /tc1apps/cuda/12.2/targets/x86_64-linux/include (found version \"12.2.91\")\n",
      "-- CUDA Toolkit found\n",
      "-- Using CUDA architectures: native\n",
      "-- The CUDA compiler identification is NVIDIA 12.2.91 with host compiler GNU 11.5.0\n",
      "-- Detecting CUDA compiler ABI info\n",
      "-- Detecting CUDA compiler ABI info - done\n",
      "-- Check for working CUDA compiler: /tc1apps/cuda/12.2/bin/nvcc - skipped\n",
      "-- Detecting CUDA compile features\n",
      "-- Detecting CUDA compile features - done\n",
      "-- CUDA host compiler is GNU 11.5.0\n",
      "-- Including CUDA backend\n",
      "-- ggml version: 0.9.4\n",
      "-- ggml commit:  d2ee056e\n",
      "-- Configuring done (12.3s)\n",
      "-- Generating done (10.3s)\n",
      "-- Build files have been written to: /home/FYP/shar0097/llama.cpp/build\n",
      "[  2%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/sha1.dir/deps/sha1/sha1.c.o\u001b[0m\n",
      "[  2%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o\u001b[0m\n",
      "[  2%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/sha256.dir/deps/sha256/sha256.c.o\u001b[0m\n",
      "[  2%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o\u001b[0m\n",
      "[  2%] \u001b[32mBuilding CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o\u001b[0m\n",
      "[  2%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o\u001b[0m\n",
      "[  2%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o\u001b[0m\n",
      "[  2%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-llava-cli.dir/deprecation-warning.cpp.o\u001b[0m\n",
      "[  4%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o\u001b[0m\n",
      "[  4%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-gemma3-cli.dir/deprecation-warning.cpp.o\u001b[0m\n",
      "[  5%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-minicpmv-cli.dir/deprecation-warning.cpp.o\u001b[0m\n",
      "[  6%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-qwen2vl-cli.dir/deprecation-warning.cpp.o\u001b[0m\n",
      "[  6%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o\u001b[0m\n",
      "[  6%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o\u001b[0m\n",
      "[  6%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o\u001b[0m\n",
      "[  6%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o\u001b[0m\n",
      "[  6%] \u001b[0mBuilt target build_info\u001b[0m\n",
      "[  6%] \u001b[0mBuilt target sha1\u001b[0m\n",
      "[  6%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-qwen2vl-cli\u001b[0m\n",
      "[  6%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-llava-cli\u001b[0m\n",
      "[  6%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-minicpmv-cli\u001b[0m\n",
      "[  6%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-gemma3-cli\u001b[0m\n",
      "[  6%] \u001b[0mBuilt target sha256\u001b[0m\n",
      "[  6%] \u001b[0mBuilt target llama-qwen2vl-cli\u001b[0m\n",
      "[  6%] \u001b[0mBuilt target llama-minicpmv-cli\u001b[0m\n",
      "[  6%] \u001b[0mBuilt target llama-llava-cli\u001b[0m\n",
      "[  6%] \u001b[0mBuilt target llama-gemma3-cli\u001b[0m\n",
      "[  6%] \u001b[0mBuilt target xxhash\u001b[0m\n",
      "[  7%] \u001b[1m\u001b[32mLinking CXX shared library ../../bin/libggml-base.so\u001b[0m\n",
      "[  7%] \u001b[0mBuilt target ggml-base\u001b[0m\n",
      "[  7%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o\u001b[0m\n",
      "[  7%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o\u001b[0m\n",
      "[  7%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o\u001b[0m\n",
      "[  8%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o\u001b[0m\n",
      "[  8%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o\u001b[0m\n",
      "[  8%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o\u001b[0m\n",
      "[  9%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o\u001b[0m\n",
      "[  9%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/add-id.cu.o\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/arange.cu.o\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argmax.cu.o\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/binbcast.cu.o\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/clamp.cu.o\u001b[0m\n",
      "[ 11%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argsort.cu.o\u001b[0m\n",
      "[ 11%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o\u001b[0m\n",
      "[ 12%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o\u001b[0m\n",
      "[ 12%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o\u001b[0m\n",
      "[ 12%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o\u001b[0m\n",
      "[ 12%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/concat.cu.o\u001b[0m\n",
      "[ 13%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv-transpose-1d.cu.o\u001b[0m\n",
      "[ 13%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv2d-dw.cu.o\u001b[0m\n",
      "[ 13%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o\u001b[0m\n",
      "[ 14%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv2d-transpose.cu.o\u001b[0m\n",
      "[ 14%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/quants.c.o\u001b[0m\n",
      "[ 14%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/repack.cpp.o\u001b[0m\n",
      "[ 15%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv2d.cu.o\u001b[0m\n",
      "[ 15%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/convert.cu.o\u001b[0m\n",
      "[ 15%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/count-equal.cu.o\u001b[0m\n",
      "[ 15%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cpy.cu.o\u001b[0m\n",
      "[ 16%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cross-entropy-loss.cu.o\u001b[0m\n",
      "[ 16%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/diagmask.cu.o\u001b[0m\n",
      "[ 16%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-wmma-f16.cu.o\u001b[0m\n",
      "[ 16%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile.cu.o\u001b[0m\n",
      "[ 17%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn.cu.o\u001b[0m\n",
      "[ 17%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/getrows.cu.o\u001b[0m\n",
      "[ 17%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ggml-cuda.cu.o\u001b[0m\n",
      "[ 18%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/gla.cu.o\u001b[0m\n",
      "[ 18%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/im2col.cu.o\u001b[0m\n",
      "[ 18%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mean.cu.o\u001b[0m\n",
      "[ 18%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmf.cu.o\u001b[0m\n",
      "[ 19%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmq.cu.o\u001b[0m\n",
      "[ 19%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmvf.cu.o\u001b[0m\n",
      "[ 19%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmvq.cu.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/norm.cu.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/opt-step-adamw.cu.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/opt-step-sgd.cu.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/out-prod.cu.o\u001b[0m\n",
      "[ 21%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pad.cu.o\u001b[0m\n",
      "[ 21%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pad_reflect_1d.cu.o\u001b[0m\n",
      "[ 21%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pool2d.cu.o\u001b[0m\n",
      "[ 21%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/quantize.cu.o\u001b[0m\n",
      "[ 22%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/roll.cu.o\u001b[0m\n",
      "[ 22%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/rope.cu.o\u001b[0m\n",
      "[ 22%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/scale.cu.o\u001b[0m\n",
      "[ 23%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/set-rows.cu.o\u001b[0m\n",
      "[ 23%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/softcap.cu.o\u001b[0m\n",
      "[ 23%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/softmax.cu.o\u001b[0m\n",
      "[ 23%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ssm-conv.cu.o\u001b[0m\n",
      "[ 24%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ssm-scan.cu.o\u001b[0m\n",
      "[ 24%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sum.cu.o\u001b[0m\n",
      "[ 24%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sumrows.cu.o\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/topk-moe.cu.o\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/tsembd.cu.o\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/unary.cu.o\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/upscale.cu.o\u001b[0m\n",
      "[ 26%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/wkv.cu.o\u001b[0m\n",
      "[ 26%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_16.cu.o\u001b[0m\n",
      "[ 26%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_8.cu.o\u001b[0m\n",
      "[ 26%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_1.cu.o\u001b[0m\n",
      "[ 27%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_2.cu.o\u001b[0m\n",
      "[ 27%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_4.cu.o\u001b[0m\n",
      "[ 27%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_16.cu.o\u001b[0m\n",
      "[ 28%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_4.cu.o\u001b[0m\n",
      "[ 28%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_8.cu.o\u001b[0m\n",
      "[ 28%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_1.cu.o\u001b[0m\n",
      "[ 28%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_2.cu.o\u001b[0m\n",
      "[ 29%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_16.cu.o\u001b[0m\n",
      "[ 29%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_2.cu.o\u001b[0m\n",
      "[ 29%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_4.cu.o\u001b[0m\n",
      "[ 30%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_8.cu.o\u001b[0m\n",
      "[ 30%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_64-ncols2_1.cu.o\u001b[0m\n",
      "[ 30%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_1.cu.o\u001b[0m\n",
      "[ 30%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_2.cu.o\u001b[0m\n",
      "[ 31%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_4.cu.o\u001b[0m\n",
      "[ 31%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_8.cu.o\u001b[0m\n",
      "[ 31%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq1_s.cu.o\u001b[0m\n",
      "[ 31%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_s.cu.o\u001b[0m\n",
      "[ 32%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xs.cu.o\u001b[0m\n",
      "[ 32%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xxs.cu.o\u001b[0m\n",
      "[ 32%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_s.cu.o\u001b[0m\n",
      "[ 33%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_xxs.cu.o\u001b[0m\n",
      "[ 33%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_nl.cu.o\u001b[0m\n",
      "[ 33%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_xs.cu.o\u001b[0m\n",
      "[ 33%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-mxfp4.cu.o\u001b[0m\n",
      "[ 34%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q2_k.cu.o\u001b[0m\n",
      "[ 34%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q3_k.cu.o\u001b[0m\n",
      "[ 34%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_0.cu.o\u001b[0m\n",
      "[ 35%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_1.cu.o\u001b[0m\n",
      "[ 35%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_k.cu.o\u001b[0m\n",
      "[ 35%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_0.cu.o\u001b[0m\n",
      "[ 35%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_1.cu.o\u001b[0m\n",
      "[ 36%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_k.cu.o\u001b[0m\n",
      "[ 36%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q6_k.cu.o\u001b[0m\n",
      "[ 36%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q8_0.cu.o\u001b[0m\n",
      "[ 36%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_1.cu.o\u001b[0m\n",
      "[ 37%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_10.cu.o\u001b[0m\n",
      "[ 37%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_11.cu.o\u001b[0m\n",
      "[ 37%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_12.cu.o\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_13.cu.o\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_14.cu.o\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_15.cu.o\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_16.cu.o\u001b[0m\n",
      "[ 39%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_2.cu.o\u001b[0m\n",
      "[ 39%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_3.cu.o\u001b[0m\n",
      "[ 39%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_4.cu.o\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_5.cu.o\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_6.cu.o\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_7.cu.o\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_8.cu.o\u001b[0m\n",
      "[ 41%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmf-instance-ncols_9.cu.o\u001b[0m\n",
      "[ 41%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-instance-q4_0-q4_0.cu.o\u001b[0m\n",
      "[ 41%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-instance-q8_0-q8_0.cu.o\u001b[0m\n",
      "[ 41%] \u001b[32mBuilding CUDA object ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-instance-f16-f16.cu.o\u001b[0m\n",
      "[ 41%] \u001b[1m\u001b[32mLinking CXX shared library ../../bin/libggml-cpu.so\u001b[0m\n",
      "[ 41%] \u001b[0mBuilt target ggml-cpu\u001b[0m\n",
      "[ 42%] \u001b[1m\u001b[32mLinking CUDA shared library ../../../bin/libggml-cuda.so\u001b[0m\n",
      "[ 42%] \u001b[0mBuilt target ggml-cuda\u001b[0m\n",
      "[ 42%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o\u001b[0m\n",
      "[ 42%] \u001b[1m\u001b[32mLinking CXX shared library ../../bin/libggml.so\u001b[0m\n",
      "[ 42%] \u001b[0mBuilt target ggml\u001b[0m\n",
      "[ 43%] \u001b[32mBuilding CXX object examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o\u001b[0m\n",
      "[ 43%] \u001b[32mBuilding CXX object examples/gguf/CMakeFiles/llama-gguf.dir/gguf.cpp.o\u001b[0m\n",
      "[ 43%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama.cpp.o\u001b[0m\n",
      "[ 43%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-adapter.cpp.o\u001b[0m\n",
      "[ 44%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-arch.cpp.o\u001b[0m\n",
      "[ 44%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-batch.cpp.o\u001b[0m\n",
      "[ 44%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-chat.cpp.o\u001b[0m\n",
      "[ 44%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-context.cpp.o\u001b[0m\n",
      "[ 45%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-cparams.cpp.o\u001b[0m\n",
      "[ 45%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-grammar.cpp.o\u001b[0m\n",
      "[ 45%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-graph.cpp.o\u001b[0m\n",
      "[ 45%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-impl.cpp.o\u001b[0m\n",
      "[ 46%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-hparams.cpp.o\u001b[0m\n",
      "[ 46%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-io.cpp.o\u001b[0m\n",
      "[ 46%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o\u001b[0m\n",
      "[ 47%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-kv-cache-iswa.cpp.o\u001b[0m\n",
      "[ 47%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-memory.cpp.o\u001b[0m\n",
      "[ 47%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o\u001b[0m\n",
      "[ 47%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o\u001b[0m\n",
      "[ 48%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-mmap.cpp.o\u001b[0m\n",
      "[ 48%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model-loader.cpp.o\u001b[0m\n",
      "[ 48%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model-saver.cpp.o\u001b[0m\n",
      "[ 49%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model.cpp.o\u001b[0m\n",
      "[ 49%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-quant.cpp.o\u001b[0m\n",
      "[ 49%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-sampling.cpp.o\u001b[0m\n",
      "[ 49%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-vocab.cpp.o\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/unicode-data.cpp.o\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/unicode.cpp.o\u001b[0m\n",
      "[ 50%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-gguf\u001b[0m\n",
      "[ 50%] \u001b[0mBuilt target llama-gguf\u001b[0m\n",
      "[ 51%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-gguf-hash\u001b[0m\n",
      "[ 51%] \u001b[0mBuilt target llama-gguf-hash\u001b[0m\n",
      "[ 51%] \u001b[1m\u001b[32mLinking CXX shared library ../bin/libllama.so\u001b[0m\n",
      "[ 51%] \u001b[0mBuilt target llama\u001b[0m\n",
      "[ 51%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/mtmd.cpp.o\u001b[0m\n",
      "[ 52%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/arg.cpp.o\u001b[0m\n",
      "[ 52%] \u001b[32mBuilding CXX object examples/simple/CMakeFiles/llama-simple.dir/simple.cpp.o\u001b[0m\n",
      "[ 52%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/mtmd-audio.cpp.o\u001b[0m\n",
      "[ 52%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/clip.cpp.o\u001b[0m\n",
      "[ 52%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/chat-parser.cpp.o\u001b[0m\n",
      "[ 52%] \u001b[32mBuilding CXX object examples/simple-chat/CMakeFiles/llama-simple-chat.dir/simple-chat.cpp.o\u001b[0m\n",
      "[ 53%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/mtmd-helper.cpp.o\u001b[0m\n",
      "[ 53%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/common.cpp.o\u001b[0m\n",
      "[ 53%] \u001b[32mBuilding C object tests/CMakeFiles/test-c.dir/test-c.c.o\u001b[0m\n",
      "[ 53%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/chat.cpp.o\u001b[0m\n",
      "[ 53%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/console.cpp.o\u001b[0m\n",
      "[ 53%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/json-partial.cpp.o\u001b[0m\n",
      "[ 54%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o\u001b[0m\n",
      "[ 54%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/llguidance.cpp.o\u001b[0m\n",
      "[ 54%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/log.cpp.o\u001b[0m\n",
      "[ 55%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/ngram-cache.cpp.o\u001b[0m\n",
      "[ 55%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/regex-partial.cpp.o\u001b[0m\n",
      "[ 55%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/sampling.cpp.o\u001b[0m\n",
      "[ 55%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/speculative.cpp.o\u001b[0m\n",
      "[ 56%] \u001b[1m\u001b[32mLinking C executable ../bin/test-c\u001b[0m\n",
      "[ 56%] \u001b[0mBuilt target test-c\u001b[0m\n",
      "[ 57%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-simple\u001b[0m\n",
      "[ 57%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-simple-chat\u001b[0m\n",
      "[ 57%] \u001b[0mBuilt target llama-simple\u001b[0m\n",
      "[ 57%] \u001b[0mBuilt target llama-simple-chat\u001b[0m\n",
      "[ 57%] \u001b[1m\u001b[32mLinking CXX shared library ../../bin/libmtmd.so\u001b[0m\n",
      "[ 57%] \u001b[0mBuilt target mtmd\u001b[0m\n",
      "[ 58%] \u001b[1m\u001b[32mLinking CXX static library libcommon.a\u001b[0m\n",
      "[ 58%] \u001b[0mBuilt target common\u001b[0m\n",
      "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-sampling.dir/test-sampling.cpp.o\u001b[0m\n",
      "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-parser.dir/test-grammar-parser.cpp.o\u001b[0m\n",
      "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-0.dir/test-tokenizer-0.cpp.o\u001b[0m\n",
      "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-sampling.dir/get-model.cpp.o\u001b[0m\n",
      "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-integration.dir/test-grammar-integration.cpp.o\u001b[0m\n",
      "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-gbnf-validator.dir/test-gbnf-validator.cpp.o\u001b[0m\n",
      "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-stats.dir/test-quantize-stats.cpp.o\u001b[0m\n",
      "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-parser.dir/get-model.cpp.o\u001b[0m\n",
      "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-integration.dir/get-model.cpp.o\u001b[0m\n",
      "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-llama-grammar.dir/test-llama-grammar.cpp.o\u001b[0m\n",
      "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-llama-grammar.dir/get-model.cpp.o\u001b[0m\n",
      "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat.dir/test-chat.cpp.o\u001b[0m\n",
      "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-schema-to-grammar.dir/test-json-schema-to-grammar.cpp.o\u001b[0m\n",
      "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat.dir/get-model.cpp.o\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-schema-to-grammar.dir/get-model.cpp.o\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-1-bpe.dir/test-tokenizer-1-bpe.cpp.o\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-1-spm.dir/test-tokenizer-1-spm.cpp.o\u001b[0m\n",
      "[ 61%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-parser.dir/test-chat-parser.cpp.o\u001b[0m\n",
      "[ 61%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-parser.dir/get-model.cpp.o\u001b[0m\n",
      "[ 62%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-template.dir/test-chat-template.cpp.o\u001b[0m\n",
      "[ 62%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-partial.dir/test-json-partial.cpp.o\u001b[0m\n",
      "[ 62%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-template.dir/get-model.cpp.o\u001b[0m\n",
      "[ 63%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-partial.dir/get-model.cpp.o\u001b[0m\n",
      "[ 63%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-log.dir/test-log.cpp.o\u001b[0m\n",
      "[ 64%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-log.dir/get-model.cpp.o\u001b[0m\n",
      "[ 64%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-thread-safety.dir/test-thread-safety.cpp.o\u001b[0m\n",
      "[ 64%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-regex-partial.dir/test-regex-partial.cpp.o\u001b[0m\n",
      "[ 64%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-arg-parser.dir/test-arg-parser.cpp.o\u001b[0m\n",
      "[ 64%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-regex-partial.dir/get-model.cpp.o\u001b[0m\n",
      "[ 64%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-thread-safety.dir/get-model.cpp.o\u001b[0m\n",
      "[ 64%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-opt.dir/test-opt.cpp.o\u001b[0m\n",
      "[ 64%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-arg-parser.dir/get-model.cpp.o\u001b[0m\n",
      "[ 64%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-gguf.dir/test-gguf.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-opt.dir/get-model.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-gguf.dir/get-model.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-backend-ops.dir/test-backend-ops.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-model-load-cancel.dir/test-model-load-cancel.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-backend-ops.dir/get-model.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-model-load-cancel.dir/get-model.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-autorelease.dir/test-autorelease.cpp.o\u001b[0m\n",
      "[ 67%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-autorelease.dir/get-model.cpp.o\u001b[0m\n",
      "[ 67%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-barrier.dir/test-barrier.cpp.o\u001b[0m\n",
      "[ 67%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-barrier.dir/get-model.cpp.o\u001b[0m\n",
      "[ 67%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-fns.dir/test-quantize-fns.cpp.o\u001b[0m\n",
      "[ 68%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-fns.dir/get-model.cpp.o\u001b[0m\n",
      "[ 68%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-perf.dir/test-quantize-perf.cpp.o\u001b[0m\n",
      "[ 68%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-rope.dir/test-rope.cpp.o\u001b[0m\n",
      "[ 68%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-perf.dir/get-model.cpp.o\u001b[0m\n",
      "[ 70%] \u001b[32mBuilding C object tests/CMakeFiles/test-mtmd-c-api.dir/test-mtmd-c-api.c.o\u001b[0m\n",
      "[ 70%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-alloc.dir/test-alloc.cpp.o\u001b[0m\n",
      "[ 70%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-rope.dir/get-model.cpp.o\u001b[0m\n",
      "[ 70%] \u001b[32mBuilding CXX object examples/embedding/CMakeFiles/llama-embedding.dir/embedding.cpp.o\u001b[0m\n",
      "[ 71%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-alloc.dir/get-model.cpp.o\u001b[0m\n",
      "[ 71%] \u001b[32mBuilding CXX object examples/batched/CMakeFiles/llama-batched.dir/batched.cpp.o\u001b[0m\n",
      "[ 71%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-mtmd-c-api.dir/get-model.cpp.o\u001b[0m\n",
      "[ 71%] \u001b[32mBuilding CXX object examples/eval-callback/CMakeFiles/llama-eval-callback.dir/eval-callback.cpp.o\u001b[0m\n",
      "[ 71%] \u001b[32mBuilding CXX object examples/lookahead/CMakeFiles/llama-lookahead.dir/lookahead.cpp.o\u001b[0m\n",
      "[ 72%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup.dir/lookup.cpp.o\u001b[0m\n",
      "[ 72%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-create.dir/lookup-create.cpp.o\u001b[0m\n",
      "[ 73%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-merge.dir/lookup-merge.cpp.o\u001b[0m\n",
      "[ 73%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-stats.dir/lookup-stats.cpp.o\u001b[0m\n",
      "[ 73%] \u001b[32mBuilding CXX object examples/parallel/CMakeFiles/llama-parallel.dir/parallel.cpp.o\u001b[0m\n",
      "[ 74%] \u001b[32mBuilding CXX object examples/passkey/CMakeFiles/llama-passkey.dir/passkey.cpp.o\u001b[0m\n",
      "[ 74%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-model-load-cancel\u001b[0m\n",
      "[ 74%] \u001b[32mBuilding CXX object examples/retrieval/CMakeFiles/llama-retrieval.dir/retrieval.cpp.o\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding CXX object examples/save-load-state/CMakeFiles/llama-save-load-state.dir/save-load-state.cpp.o\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding CXX object examples/speculative/CMakeFiles/llama-speculative.dir/speculative.cpp.o\u001b[0m\n",
      "[ 75%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-mtmd-c-api\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding CXX object examples/gen-docs/CMakeFiles/llama-gen-docs.dir/gen-docs.cpp.o\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding CXX object examples/speculative-simple/CMakeFiles/llama-speculative-simple.dir/speculative-simple.cpp.o\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding CXX object examples/training/CMakeFiles/llama-finetune.dir/finetune.cpp.o\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding CXX object examples/diffusion/CMakeFiles/llama-diffusion-cli.dir/diffusion-cli.cpp.o\u001b[0m\n",
      "[ 76%] \u001b[32mBuilding CXX object examples/model-conversion/CMakeFiles/llama-logits.dir/logits.cpp.o\u001b[0m\n",
      "[ 77%] \u001b[32mBuilding CXX object examples/convert-llama2c-to-ggml/CMakeFiles/llama-convert-llama2c-to-ggml.dir/convert-llama2c-to-ggml.cpp.o\u001b[0m\n",
      "[ 79%] \u001b[32mBuilding CXX object pocs/vdot/CMakeFiles/llama-vdot.dir/vdot.cpp.o\u001b[0m\n",
      "[ 79%] \u001b[32mBuilding CXX object pocs/vdot/CMakeFiles/llama-q8dot.dir/q8dot.cpp.o\u001b[0m\n",
      "[ 79%] \u001b[32mBuilding CXX object tools/batched-bench/CMakeFiles/llama-batched-bench.dir/batched-bench.cpp.o\u001b[0m\n",
      "[ 79%] \u001b[32mBuilding CXX object tools/gguf-split/CMakeFiles/llama-gguf-split.dir/gguf-split.cpp.o\u001b[0m\n",
      "[ 79%] \u001b[32mBuilding CXX object tools/imatrix/CMakeFiles/llama-imatrix.dir/imatrix.cpp.o\u001b[0m\n",
      "[ 80%] \u001b[1m\u001b[34mGenerating loading.html.hpp\u001b[0m\n",
      "[ 80%] \u001b[1m\u001b[34mGenerating index.html.gz.hpp\u001b[0m\n",
      "[ 81%] \u001b[32mBuilding CXX object tools/llama-bench/CMakeFiles/llama-bench.dir/llama-bench.cpp.o\u001b[0m\n",
      "[ 81%] \u001b[32mBuilding CXX object tools/perplexity/CMakeFiles/llama-perplexity.dir/perplexity.cpp.o\u001b[0m\n",
      "[ 81%] \u001b[32mBuilding CXX object tools/main/CMakeFiles/llama-cli.dir/main.cpp.o\u001b[0m\n",
      "[ 81%] \u001b[32mBuilding CXX object tools/quantize/CMakeFiles/llama-quantize.dir/quantize.cpp.o\u001b[0m\n",
      "[ 81%] \u001b[32mBuilding CXX object tools/run/CMakeFiles/llama-run.dir/run.cpp.o\u001b[0m\n",
      "[ 81%] \u001b[32mBuilding CXX object tools/run/CMakeFiles/llama-run.dir/linenoise.cpp/linenoise.cpp.o\u001b[0m\n",
      "[ 82%] \u001b[32mBuilding CXX object tools/tokenize/CMakeFiles/llama-tokenize.dir/tokenize.cpp.o\u001b[0m\n",
      "[ 82%] \u001b[32mBuilding CXX object tools/tts/CMakeFiles/llama-tts.dir/tts.cpp.o\u001b[0m\n",
      "[ 82%] \u001b[32mBuilding CXX object tools/cvector-generator/CMakeFiles/llama-cvector-generator.dir/cvector-generator.cpp.o\u001b[0m\n",
      "[ 82%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-mtmd-cli.dir/mtmd-cli.cpp.o\u001b[0m\n",
      "[ 83%] \u001b[32mBuilding CXX object tools/export-lora/CMakeFiles/llama-export-lora.dir/export-lora.cpp.o\u001b[0m\n",
      "[ 83%] \u001b[0mBuilt target test-model-load-cancel\u001b[0m\n",
      "[ 83%] \u001b[0mBuilt target test-mtmd-c-api\u001b[0m\n",
      "[ 84%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-log\u001b[0m\n",
      "[ 84%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-autorelease\u001b[0m\n",
      "[ 84%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-rope\u001b[0m\n",
      "[ 84%] \u001b[0mBuilt target test-log\u001b[0m\n",
      "[ 84%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-barrier\u001b[0m\n",
      "[ 84%] \u001b[0mBuilt target test-autorelease\u001b[0m\n",
      "[ 84%] \u001b[0mBuilt target test-rope\u001b[0m\n",
      "[ 84%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-quantize-fns\u001b[0m\n",
      "[ 84%] \u001b[0mBuilt target test-barrier\u001b[0m\n",
      "[ 84%] \u001b[0mBuilt target test-quantize-fns\u001b[0m\n",
      "[ 84%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-logits\u001b[0m\n",
      "[ 84%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-q8dot\u001b[0m\n",
      "[ 85%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-tokenizer-1-spm\u001b[0m\n",
      "[ 85%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-gbnf-validator\u001b[0m\n",
      "[ 85%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-lookup-merge\u001b[0m\n",
      "[ 86%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-tokenizer-1-bpe\u001b[0m\n",
      "[ 86%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-vdot\u001b[0m\n",
      "[ 86%] \u001b[0mBuilt target llama-logits\u001b[0m\n",
      "[ 86%] \u001b[0mBuilt target test-gbnf-validator\u001b[0m\n",
      "[ 86%] \u001b[0mBuilt target test-tokenizer-1-spm\u001b[0m\n",
      "[ 86%] \u001b[0mBuilt target llama-q8dot\u001b[0m\n",
      "[ 86%] \u001b[0mBuilt target llama-lookup-merge\u001b[0m\n",
      "[ 86%] \u001b[0mBuilt target test-tokenizer-1-bpe\u001b[0m\n",
      "[ 86%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-tokenize\u001b[0m\n",
      "[ 87%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-alloc\u001b[0m\n",
      "[ 87%] \u001b[0mBuilt target llama-vdot\u001b[0m\n",
      "[ 87%] \u001b[0mBuilt target llama-tokenize\u001b[0m\n",
      "[ 87%] \u001b[0mBuilt target test-alloc\u001b[0m\n",
      "[ 87%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-grammar-parser\u001b[0m\n",
      "[ 87%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-gguf-split\u001b[0m\n",
      "[ 88%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-sampling\u001b[0m\n",
      "[ 88%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-tokenizer-0\u001b[0m\n",
      "[ 88%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-finetune\u001b[0m\n",
      "[ 88%] \u001b[0mBuilt target test-grammar-parser\u001b[0m\n",
      "[ 88%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-lookup-create\u001b[0m\n",
      "[ 88%] \u001b[0mBuilt target llama-gguf-split\u001b[0m\n",
      "[ 88%] \u001b[0mBuilt target test-sampling\u001b[0m\n",
      "[ 88%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-eval-callback\u001b[0m\n",
      "[ 89%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-llama-grammar\u001b[0m\n",
      "[ 89%] \u001b[0mBuilt target test-tokenizer-0\u001b[0m\n",
      "[ 89%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-gen-docs\u001b[0m\n",
      "[ 89%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-batched\u001b[0m\n",
      "[ 90%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-thread-safety\u001b[0m\n",
      "[ 90%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-save-load-state\u001b[0m\n",
      "[ 91%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-quantize-perf\u001b[0m\n",
      "[ 91%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-regex-partial\u001b[0m\n",
      "[ 91%] \u001b[32mBuilding CXX object tools/server/CMakeFiles/llama-server.dir/server.cpp.o\u001b[0m\n",
      "[ 92%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-lookup-stats\u001b[0m\n",
      "[ 92%] \u001b[0mBuilt target test-llama-grammar\u001b[0m\n",
      "[ 92%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-speculative-simple\u001b[0m\n",
      "[ 92%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-passkey\u001b[0m\n",
      "[ 92%] \u001b[0mBuilt target llama-finetune\u001b[0m\n",
      "[ 92%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-batched-bench\u001b[0m\n",
      "[ 92%] \u001b[0mBuilt target test-quantize-perf\u001b[0m\n",
      "[ 92%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-lookup\u001b[0m\n",
      "[ 92%] \u001b[0mBuilt target llama-lookup-create\u001b[0m\n",
      "[ 92%] \u001b[0mBuilt target test-regex-partial\u001b[0m\n",
      "[ 92%] \u001b[0mBuilt target llama-eval-callback\u001b[0m\n",
      "[ 92%] \u001b[0mBuilt target llama-gen-docs\u001b[0m\n",
      "[ 92%] \u001b[0mBuilt target llama-batched\u001b[0m\n",
      "[ 92%] \u001b[0mBuilt target test-thread-safety\u001b[0m\n",
      "[ 93%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-arg-parser\u001b[0m\n",
      "[ 93%] \u001b[0mBuilt target llama-save-load-state\u001b[0m\n",
      "[ 93%] \u001b[0mBuilt target llama-lookup-stats\u001b[0m\n",
      "[ 93%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-opt\u001b[0m\n",
      "[ 93%] \u001b[0mBuilt target llama-speculative-simple\u001b[0m\n",
      "[ 93%] \u001b[0mBuilt target llama-passkey\u001b[0m\n",
      "[ 93%] \u001b[0mBuilt target llama-batched-bench\u001b[0m\n",
      "[ 93%] \u001b[0mBuilt target llama-lookup\u001b[0m\n",
      "[ 93%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-lookahead\u001b[0m\n",
      "[ 93%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-convert-llama2c-to-ggml\u001b[0m\n",
      "[ 93%] \u001b[0mBuilt target test-opt\u001b[0m\n",
      "[ 94%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-embedding\u001b[0m\n",
      "[ 94%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-parallel\u001b[0m\n",
      "[ 94%] \u001b[0mBuilt target test-arg-parser\u001b[0m\n",
      "[ 94%] \u001b[0mBuilt target llama-convert-llama2c-to-ggml\u001b[0m\n",
      "[ 95%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-gguf\u001b[0m\n",
      "[ 95%] \u001b[0mBuilt target llama-lookahead\u001b[0m\n",
      "[ 95%] \u001b[0mBuilt target llama-embedding\u001b[0m\n",
      "[ 95%] \u001b[0mBuilt target test-gguf\u001b[0m\n",
      "[ 95%] \u001b[0mBuilt target llama-parallel\u001b[0m\n",
      "[ 96%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-retrieval\u001b[0m\n",
      "[ 96%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-quantize\u001b[0m\n",
      "[ 96%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-export-lora\u001b[0m\n",
      "[ 97%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-mtmd-cli\u001b[0m\n",
      "[ 97%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-chat-template\u001b[0m\n",
      "[ 97%] \u001b[0mBuilt target llama-retrieval\u001b[0m\n",
      "[ 97%] \u001b[0mBuilt target llama-quantize\u001b[0m\n",
      "[ 97%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-diffusion-cli\u001b[0m\n",
      "[ 97%] \u001b[0mBuilt target llama-export-lora\u001b[0m\n",
      "[ 97%] \u001b[0mBuilt target test-chat-template\u001b[0m\n",
      "[ 97%] \u001b[0mBuilt target llama-mtmd-cli\u001b[0m\n",
      "[ 98%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-cvector-generator\u001b[0m\n",
      "[ 98%] \u001b[0mBuilt target llama-diffusion-cli\u001b[0m\n",
      "[ 99%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-speculative\u001b[0m\n",
      "[ 99%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-json-partial\u001b[0m\n",
      "[ 99%] \u001b[0mBuilt target test-json-partial\u001b[0m\n",
      "[ 99%] \u001b[0mBuilt target llama-cvector-generator\u001b[0m\n",
      "[ 99%] \u001b[0mBuilt target llama-speculative\u001b[0m\n",
      "[ 99%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-cli\u001b[0m\n",
      "[ 99%] \u001b[0mBuilt target llama-cli\u001b[0m\n",
      "[ 99%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-quantize-stats\u001b[0m\n",
      "[ 99%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-perplexity\u001b[0m\n",
      "[ 99%] \u001b[0mBuilt target test-quantize-stats\u001b[0m\n",
      "[ 99%] \u001b[0mBuilt target llama-perplexity\u001b[0m\n",
      "[ 99%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-grammar-integration\u001b[0m\n",
      "[ 99%] \u001b[0mBuilt target test-grammar-integration\u001b[0m\n",
      "[ 99%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-chat-parser\u001b[0m\n",
      "[ 99%] \u001b[0mBuilt target test-chat-parser\u001b[0m\n",
      "[ 99%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-json-schema-to-grammar\u001b[0m\n",
      "[100%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-imatrix\u001b[0m\n",
      "[100%] \u001b[0mBuilt target test-json-schema-to-grammar\u001b[0m\n",
      "[100%] \u001b[0mBuilt target llama-imatrix\u001b[0m\n",
      "[100%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-bench\u001b[0m\n",
      "[100%] \u001b[0mBuilt target llama-bench\u001b[0m\n",
      "[100%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-tts\u001b[0m\n",
      "[100%] \u001b[0mBuilt target llama-tts\u001b[0m\n",
      "[100%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-chat\u001b[0m\n",
      "[100%] \u001b[0mBuilt target test-chat\u001b[0m\n",
      "[100%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-backend-ops\u001b[0m\n",
      "[100%] \u001b[0mBuilt target test-backend-ops\u001b[0m\n",
      "[100%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-run\u001b[0m\n",
      "[100%] \u001b[0mBuilt target llama-run\u001b[0m\n",
      "[100%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-server\u001b[0m\n",
      "[100%] \u001b[0mBuilt target llama-server\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# GPU BUILT\n",
    "!rm -rf llama.cpp/build\n",
    "\n",
    "!cmake -DLLAMA_CURL=OFF -DGGML_CUDA=ON -DGGML_OPENMP=ON -B llama.cpp/build -S llama.cpp \\\n",
    "    -DCMAKE_BUILD_TYPE=Release \\\n",
    "    -DCMAKE_C_FLAGS=\"-fopenmp\" \\\n",
    "    -DCMAKE_CXX_FLAGS=\"-fopenmp\" \\\n",
    "    -DCMAKE_EXE_LINKER_FLAGS=\"-fopenmp\"\n",
    "\n",
    "!cmake --build llama.cpp/build --config Release -j\n",
    "\n",
    "#!cmake -DGGML_OPENMP=OFF -DLLAMA_CURL=OFF -B llama.cpp/build -S llama.cpp\n",
    "#!cmake --build llama.cpp/build --config Release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HPWZxEVGIPuq",
    "outputId": "5ef9955f-ec0f-4625-a659-5663990f0cf5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The C compiler identification is GNU 11.5.0\n",
      "-- The CXX compiler identification is GNU 11.5.0\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Check for working C compiler: /usr/bin/cc - skipped\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "\u001b[0mCMAKE_BUILD_TYPE=Release\u001b[0m\n",
      "-- Found Git: /usr/bin/git (found version \"2.47.3\")\n",
      "-- The ASM compiler identification is GNU\n",
      "-- Found assembler: /usr/bin/cc\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
      "-- Found Threads: TRUE\n",
      "-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n",
      "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
      "-- GGML_SYSTEM_ARCH: x86\n",
      "-- Including CPU backend\n",
      "-- x86 detected\n",
      "-- Adding CPU backend variant ggml-cpu: -march=native \n",
      "-- ggml version: 0.9.4\n",
      "-- ggml commit:  d2ee056e\n",
      "-- Configuring done (3.9s)\n",
      "-- Generating done (10.0s)\n",
      "-- Build files have been written to: /home/FYP/shar0097/llama.cpp/build\n",
      "[  1%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o\u001b[0m\n",
      "[  1%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o\u001b[0m\n",
      "[  2%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o\u001b[0m\n",
      "[  2%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o\u001b[0m\n",
      "[  2%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o\u001b[0m\n",
      "[  3%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o\u001b[0m\n",
      "[  3%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o\u001b[0m\n",
      "[  4%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o\u001b[0m\n",
      "[  4%] \u001b[1m\u001b[32mLinking CXX shared library ../../bin/libggml-base.so\u001b[0m\n",
      "[  4%] \u001b[0mBuilt target ggml-base\u001b[0m\n",
      "[  4%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o\u001b[0m\n",
      "[  5%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o\u001b[0m\n",
      "[  5%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o\u001b[0m\n",
      "[  6%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o\u001b[0m\n",
      "[  6%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o\u001b[0m\n",
      "[  6%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o\u001b[0m\n",
      "[  7%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o\u001b[0m\n",
      "[  7%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o\u001b[0m\n",
      "[  8%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o\u001b[0m\n",
      "[  8%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o\u001b[0m\n",
      "[  8%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o\u001b[0m\n",
      "[  9%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o\u001b[0m\n",
      "[  9%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/quants.c.o\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/repack.cpp.o\u001b[0m\n",
      "[ 10%] \u001b[1m\u001b[32mLinking CXX shared library ../../bin/libggml-cpu.so\u001b[0m\n",
      "[ 10%] \u001b[0mBuilt target ggml-cpu\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o\u001b[0m\n",
      "[ 10%] \u001b[1m\u001b[32mLinking CXX shared library ../../bin/libggml.so\u001b[0m\n",
      "[ 10%] \u001b[0mBuilt target ggml\u001b[0m\n",
      "[ 11%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama.cpp.o\u001b[0m\n",
      "[ 11%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-adapter.cpp.o\u001b[0m\n",
      "[ 12%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-arch.cpp.o\u001b[0m\n",
      "[ 12%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-batch.cpp.o\u001b[0m\n",
      "[ 12%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-chat.cpp.o\u001b[0m\n",
      "[ 13%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-context.cpp.o\u001b[0m\n",
      "[ 13%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-cparams.cpp.o\u001b[0m\n",
      "[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-grammar.cpp.o\u001b[0m\n",
      "[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-graph.cpp.o\u001b[0m\n",
      "[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-hparams.cpp.o\u001b[0m\n",
      "[ 15%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-impl.cpp.o\u001b[0m\n",
      "[ 15%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-io.cpp.o\u001b[0m\n",
      "[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o\u001b[0m\n",
      "[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-kv-cache-iswa.cpp.o\u001b[0m\n",
      "[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-memory.cpp.o\u001b[0m\n",
      "[ 17%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o\u001b[0m\n",
      "[ 17%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o\u001b[0m\n",
      "[ 18%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-mmap.cpp.o\u001b[0m\n",
      "[ 18%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model-loader.cpp.o\u001b[0m\n",
      "[ 18%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model-saver.cpp.o\u001b[0m\n",
      "[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-model.cpp.o\u001b[0m\n",
      "[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-quant.cpp.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-sampling.cpp.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/llama-vocab.cpp.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/unicode-data.cpp.o\u001b[0m\n",
      "[ 21%] \u001b[32mBuilding CXX object src/CMakeFiles/llama.dir/unicode.cpp.o\u001b[0m\n",
      "[ 21%] \u001b[1m\u001b[32mLinking CXX shared library ../bin/libllama.so\u001b[0m\n",
      "[ 21%] \u001b[0mBuilt target llama\u001b[0m\n",
      "[ 21%] \u001b[32mBuilding CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o\u001b[0m\n",
      "[ 21%] \u001b[0mBuilt target build_info\u001b[0m\n",
      "[ 21%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/arg.cpp.o\u001b[0m\n",
      "[ 22%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/chat-parser.cpp.o\u001b[0m\n",
      "[ 22%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/chat.cpp.o\u001b[0m\n",
      "[ 23%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/common.cpp.o\u001b[0m\n",
      "[ 23%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/console.cpp.o\u001b[0m\n",
      "[ 23%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/json-partial.cpp.o\u001b[0m\n",
      "[ 24%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o\u001b[0m\n",
      "[ 24%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/llguidance.cpp.o\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/log.cpp.o\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/ngram-cache.cpp.o\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/regex-partial.cpp.o\u001b[0m\n",
      "[ 26%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/sampling.cpp.o\u001b[0m\n",
      "[ 26%] \u001b[32mBuilding CXX object common/CMakeFiles/common.dir/speculative.cpp.o\u001b[0m\n",
      "[ 27%] \u001b[1m\u001b[32mLinking CXX static library libcommon.a\u001b[0m\n",
      "[ 27%] \u001b[0mBuilt target common\u001b[0m\n",
      "[ 27%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-0.dir/test-tokenizer-0.cpp.o\u001b[0m\n",
      "[ 28%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-tokenizer-0\u001b[0m\n",
      "[ 28%] \u001b[0mBuilt target test-tokenizer-0\u001b[0m\n",
      "[ 29%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-sampling.dir/test-sampling.cpp.o\u001b[0m\n",
      "[ 29%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-sampling.dir/get-model.cpp.o\u001b[0m\n",
      "[ 30%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-sampling\u001b[0m\n",
      "[ 30%] \u001b[0mBuilt target test-sampling\u001b[0m\n",
      "[ 31%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-parser.dir/test-grammar-parser.cpp.o\u001b[0m\n",
      "[ 31%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-parser.dir/get-model.cpp.o\u001b[0m\n",
      "[ 31%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-grammar-parser\u001b[0m\n",
      "[ 31%] \u001b[0mBuilt target test-grammar-parser\u001b[0m\n",
      "[ 31%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-integration.dir/test-grammar-integration.cpp.o\u001b[0m\n",
      "[ 32%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-grammar-integration.dir/get-model.cpp.o\u001b[0m\n",
      "[ 32%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-grammar-integration\u001b[0m\n",
      "[ 32%] \u001b[0mBuilt target test-grammar-integration\u001b[0m\n",
      "[ 32%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-llama-grammar.dir/test-llama-grammar.cpp.o\u001b[0m\n",
      "[ 33%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-llama-grammar.dir/get-model.cpp.o\u001b[0m\n",
      "[ 33%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-llama-grammar\u001b[0m\n",
      "[ 33%] \u001b[0mBuilt target test-llama-grammar\u001b[0m\n",
      "[ 34%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat.dir/test-chat.cpp.o\u001b[0m\n",
      "[ 34%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat.dir/get-model.cpp.o\u001b[0m\n",
      "[ 35%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-chat\u001b[0m\n",
      "[ 35%] \u001b[0mBuilt target test-chat\u001b[0m\n",
      "[ 35%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-schema-to-grammar.dir/test-json-schema-to-grammar.cpp.o\u001b[0m\n",
      "[ 35%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-schema-to-grammar.dir/get-model.cpp.o\u001b[0m\n",
      "[ 36%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-json-schema-to-grammar\u001b[0m\n",
      "[ 36%] \u001b[0mBuilt target test-json-schema-to-grammar\u001b[0m\n",
      "[ 37%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-stats.dir/test-quantize-stats.cpp.o\u001b[0m\n",
      "[ 37%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-quantize-stats\u001b[0m\n",
      "[ 37%] \u001b[0mBuilt target test-quantize-stats\u001b[0m\n",
      "[ 37%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-gbnf-validator.dir/test-gbnf-validator.cpp.o\u001b[0m\n",
      "[ 38%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-gbnf-validator\u001b[0m\n",
      "[ 38%] \u001b[0mBuilt target test-gbnf-validator\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-1-bpe.dir/test-tokenizer-1-bpe.cpp.o\u001b[0m\n",
      "[ 38%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-tokenizer-1-bpe\u001b[0m\n",
      "[ 38%] \u001b[0mBuilt target test-tokenizer-1-bpe\u001b[0m\n",
      "[ 39%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-tokenizer-1-spm.dir/test-tokenizer-1-spm.cpp.o\u001b[0m\n",
      "[ 39%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-tokenizer-1-spm\u001b[0m\n",
      "[ 39%] \u001b[0mBuilt target test-tokenizer-1-spm\u001b[0m\n",
      "[ 39%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-parser.dir/test-chat-parser.cpp.o\u001b[0m\n",
      "[ 39%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-parser.dir/get-model.cpp.o\u001b[0m\n",
      "[ 40%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-chat-parser\u001b[0m\n",
      "[ 40%] \u001b[0mBuilt target test-chat-parser\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-template.dir/test-chat-template.cpp.o\u001b[0m\n",
      "[ 41%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-chat-template.dir/get-model.cpp.o\u001b[0m\n",
      "[ 41%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-chat-template\u001b[0m\n",
      "[ 41%] \u001b[0mBuilt target test-chat-template\u001b[0m\n",
      "[ 42%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-partial.dir/test-json-partial.cpp.o\u001b[0m\n",
      "[ 42%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-json-partial.dir/get-model.cpp.o\u001b[0m\n",
      "[ 43%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-json-partial\u001b[0m\n",
      "[ 43%] \u001b[0mBuilt target test-json-partial\u001b[0m\n",
      "[ 43%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-log.dir/test-log.cpp.o\u001b[0m\n",
      "[ 44%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-log.dir/get-model.cpp.o\u001b[0m\n",
      "[ 44%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-log\u001b[0m\n",
      "[ 44%] \u001b[0mBuilt target test-log\u001b[0m\n",
      "[ 44%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-regex-partial.dir/test-regex-partial.cpp.o\u001b[0m\n",
      "[ 45%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-regex-partial.dir/get-model.cpp.o\u001b[0m\n",
      "[ 45%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-regex-partial\u001b[0m\n",
      "[ 45%] \u001b[0mBuilt target test-regex-partial\u001b[0m\n",
      "[ 45%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-thread-safety.dir/test-thread-safety.cpp.o\u001b[0m\n",
      "[ 45%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-thread-safety.dir/get-model.cpp.o\u001b[0m\n",
      "[ 46%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-thread-safety\u001b[0m\n",
      "[ 46%] \u001b[0mBuilt target test-thread-safety\u001b[0m\n",
      "[ 46%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-arg-parser.dir/test-arg-parser.cpp.o\u001b[0m\n",
      "[ 47%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-arg-parser.dir/get-model.cpp.o\u001b[0m\n",
      "[ 47%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-arg-parser\u001b[0m\n",
      "[ 47%] \u001b[0mBuilt target test-arg-parser\u001b[0m\n",
      "[ 47%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-opt.dir/test-opt.cpp.o\u001b[0m\n",
      "[ 47%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-opt.dir/get-model.cpp.o\u001b[0m\n",
      "[ 48%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-opt\u001b[0m\n",
      "[ 48%] \u001b[0mBuilt target test-opt\u001b[0m\n",
      "[ 48%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-gguf.dir/test-gguf.cpp.o\u001b[0m\n",
      "[ 49%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-gguf.dir/get-model.cpp.o\u001b[0m\n",
      "[ 49%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-gguf\u001b[0m\n",
      "[ 49%] \u001b[0mBuilt target test-gguf\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-backend-ops.dir/test-backend-ops.cpp.o\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-backend-ops.dir/get-model.cpp.o\u001b[0m\n",
      "[ 50%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-backend-ops\u001b[0m\n",
      "[ 50%] \u001b[0mBuilt target test-backend-ops\u001b[0m\n",
      "[ 51%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-model-load-cancel.dir/test-model-load-cancel.cpp.o\u001b[0m\n",
      "[ 51%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-model-load-cancel.dir/get-model.cpp.o\u001b[0m\n",
      "[ 51%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-model-load-cancel\u001b[0m\n",
      "[ 51%] \u001b[0mBuilt target test-model-load-cancel\u001b[0m\n",
      "[ 51%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-autorelease.dir/test-autorelease.cpp.o\u001b[0m\n",
      "[ 52%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-autorelease.dir/get-model.cpp.o\u001b[0m\n",
      "[ 52%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-autorelease\u001b[0m\n",
      "[ 52%] \u001b[0mBuilt target test-autorelease\u001b[0m\n",
      "[ 53%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-barrier.dir/test-barrier.cpp.o\u001b[0m\n",
      "[ 53%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-barrier.dir/get-model.cpp.o\u001b[0m\n",
      "[ 54%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-barrier\u001b[0m\n",
      "[ 54%] \u001b[0mBuilt target test-barrier\u001b[0m\n",
      "[ 54%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-fns.dir/test-quantize-fns.cpp.o\u001b[0m\n",
      "[ 55%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-fns.dir/get-model.cpp.o\u001b[0m\n",
      "[ 55%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-quantize-fns\u001b[0m\n",
      "[ 55%] \u001b[0mBuilt target test-quantize-fns\u001b[0m\n",
      "[ 55%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-perf.dir/test-quantize-perf.cpp.o\u001b[0m\n",
      "[ 56%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-quantize-perf.dir/get-model.cpp.o\u001b[0m\n",
      "[ 56%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-quantize-perf\u001b[0m\n",
      "[ 56%] \u001b[0mBuilt target test-quantize-perf\u001b[0m\n",
      "[ 57%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-rope.dir/test-rope.cpp.o\u001b[0m\n",
      "[ 57%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-rope.dir/get-model.cpp.o\u001b[0m\n",
      "[ 57%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-rope\u001b[0m\n",
      "[ 57%] \u001b[0mBuilt target test-rope\u001b[0m\n",
      "[ 57%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/mtmd.cpp.o\u001b[0m\n",
      "[ 58%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/mtmd-audio.cpp.o\u001b[0m\n",
      "[ 58%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/clip.cpp.o\u001b[0m\n",
      "[ 58%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/mtmd.dir/mtmd-helper.cpp.o\u001b[0m\n",
      "[ 59%] \u001b[1m\u001b[32mLinking CXX shared library ../../bin/libmtmd.so\u001b[0m\n",
      "[ 59%] \u001b[0mBuilt target mtmd\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding C object tests/CMakeFiles/test-mtmd-c-api.dir/test-mtmd-c-api.c.o\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-mtmd-c-api.dir/get-model.cpp.o\u001b[0m\n",
      "[ 61%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-mtmd-c-api\u001b[0m\n",
      "[ 61%] \u001b[0mBuilt target test-mtmd-c-api\u001b[0m\n",
      "[ 61%] \u001b[32mBuilding C object tests/CMakeFiles/test-c.dir/test-c.c.o\u001b[0m\n",
      "[ 61%] \u001b[1m\u001b[32mLinking C executable ../bin/test-c\u001b[0m\n",
      "[ 61%] \u001b[0mBuilt target test-c\u001b[0m\n",
      "[ 61%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-alloc.dir/test-alloc.cpp.o\u001b[0m\n",
      "[ 61%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-alloc.dir/get-model.cpp.o\u001b[0m\n",
      "[ 62%] \u001b[1m\u001b[32mLinking CXX executable ../bin/test-alloc\u001b[0m\n",
      "[ 62%] \u001b[0mBuilt target test-alloc\u001b[0m\n",
      "[ 63%] \u001b[32mBuilding CXX object examples/batched/CMakeFiles/llama-batched.dir/batched.cpp.o\u001b[0m\n",
      "[ 63%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-batched\u001b[0m\n",
      "[ 63%] \u001b[0mBuilt target llama-batched\u001b[0m\n",
      "[ 63%] \u001b[32mBuilding CXX object examples/embedding/CMakeFiles/llama-embedding.dir/embedding.cpp.o\u001b[0m\n",
      "[ 64%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-embedding\u001b[0m\n",
      "[ 64%] \u001b[0mBuilt target llama-embedding\u001b[0m\n",
      "[ 64%] \u001b[32mBuilding CXX object examples/eval-callback/CMakeFiles/llama-eval-callback.dir/eval-callback.cpp.o\u001b[0m\n",
      "[ 64%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-eval-callback\u001b[0m\n",
      "[ 64%] \u001b[0mBuilt target llama-eval-callback\u001b[0m\n",
      "[ 65%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/sha256.dir/deps/sha256/sha256.c.o\u001b[0m\n",
      "[ 65%] \u001b[0mBuilt target sha256\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o\u001b[0m\n",
      "[ 66%] \u001b[0mBuilt target xxhash\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding C object examples/gguf-hash/CMakeFiles/sha1.dir/deps/sha1/sha1.c.o\u001b[0m\n",
      "[ 66%] \u001b[0mBuilt target sha1\u001b[0m\n",
      "[ 67%] \u001b[32mBuilding CXX object examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o\u001b[0m\n",
      "[ 67%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-gguf-hash\u001b[0m\n",
      "[ 67%] \u001b[0mBuilt target llama-gguf-hash\u001b[0m\n",
      "[ 67%] \u001b[32mBuilding CXX object examples/gguf/CMakeFiles/llama-gguf.dir/gguf.cpp.o\u001b[0m\n",
      "[ 67%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-gguf\u001b[0m\n",
      "[ 67%] \u001b[0mBuilt target llama-gguf\u001b[0m\n",
      "[ 68%] \u001b[32mBuilding CXX object examples/lookahead/CMakeFiles/llama-lookahead.dir/lookahead.cpp.o\u001b[0m\n",
      "[ 68%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-lookahead\u001b[0m\n",
      "[ 68%] \u001b[0mBuilt target llama-lookahead\u001b[0m\n",
      "[ 69%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup.dir/lookup.cpp.o\u001b[0m\n",
      "[ 69%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-lookup\u001b[0m\n",
      "[ 69%] \u001b[0mBuilt target llama-lookup\u001b[0m\n",
      "[ 69%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-create.dir/lookup-create.cpp.o\u001b[0m\n",
      "[ 70%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-lookup-create\u001b[0m\n",
      "[ 70%] \u001b[0mBuilt target llama-lookup-create\u001b[0m\n",
      "[ 70%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-merge.dir/lookup-merge.cpp.o\u001b[0m\n",
      "[ 71%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-lookup-merge\u001b[0m\n",
      "[ 71%] \u001b[0mBuilt target llama-lookup-merge\u001b[0m\n",
      "[ 71%] \u001b[32mBuilding CXX object examples/lookup/CMakeFiles/llama-lookup-stats.dir/lookup-stats.cpp.o\u001b[0m\n",
      "[ 71%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-lookup-stats\u001b[0m\n",
      "[ 71%] \u001b[0mBuilt target llama-lookup-stats\u001b[0m\n",
      "[ 71%] \u001b[32mBuilding CXX object examples/parallel/CMakeFiles/llama-parallel.dir/parallel.cpp.o\u001b[0m\n",
      "[ 72%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-parallel\u001b[0m\n",
      "[ 72%] \u001b[0mBuilt target llama-parallel\u001b[0m\n",
      "[ 72%] \u001b[32mBuilding CXX object examples/passkey/CMakeFiles/llama-passkey.dir/passkey.cpp.o\u001b[0m\n",
      "[ 73%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-passkey\u001b[0m\n",
      "[ 73%] \u001b[0mBuilt target llama-passkey\u001b[0m\n",
      "[ 73%] \u001b[32mBuilding CXX object examples/retrieval/CMakeFiles/llama-retrieval.dir/retrieval.cpp.o\u001b[0m\n",
      "[ 74%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-retrieval\u001b[0m\n",
      "[ 74%] \u001b[0mBuilt target llama-retrieval\u001b[0m\n",
      "[ 74%] \u001b[32mBuilding CXX object examples/save-load-state/CMakeFiles/llama-save-load-state.dir/save-load-state.cpp.o\u001b[0m\n",
      "[ 75%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-save-load-state\u001b[0m\n",
      "[ 75%] \u001b[0mBuilt target llama-save-load-state\u001b[0m\n",
      "[ 76%] \u001b[32mBuilding CXX object examples/simple/CMakeFiles/llama-simple.dir/simple.cpp.o\u001b[0m\n",
      "[ 76%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-simple\u001b[0m\n",
      "[ 76%] \u001b[0mBuilt target llama-simple\u001b[0m\n",
      "[ 76%] \u001b[32mBuilding CXX object examples/simple-chat/CMakeFiles/llama-simple-chat.dir/simple-chat.cpp.o\u001b[0m\n",
      "[ 77%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-simple-chat\u001b[0m\n",
      "[ 77%] \u001b[0mBuilt target llama-simple-chat\u001b[0m\n",
      "[ 77%] \u001b[32mBuilding CXX object examples/speculative/CMakeFiles/llama-speculative.dir/speculative.cpp.o\u001b[0m\n",
      "[ 78%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-speculative\u001b[0m\n",
      "[ 78%] \u001b[0mBuilt target llama-speculative\u001b[0m\n",
      "[ 78%] \u001b[32mBuilding CXX object examples/speculative-simple/CMakeFiles/llama-speculative-simple.dir/speculative-simple.cpp.o\u001b[0m\n",
      "[ 78%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-speculative-simple\u001b[0m\n",
      "[ 78%] \u001b[0mBuilt target llama-speculative-simple\u001b[0m\n",
      "[ 78%] \u001b[32mBuilding CXX object examples/gen-docs/CMakeFiles/llama-gen-docs.dir/gen-docs.cpp.o\u001b[0m\n",
      "[ 79%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-gen-docs\u001b[0m\n",
      "[ 79%] \u001b[0mBuilt target llama-gen-docs\u001b[0m\n",
      "[ 80%] \u001b[32mBuilding CXX object examples/training/CMakeFiles/llama-finetune.dir/finetune.cpp.o\u001b[0m\n",
      "[ 80%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-finetune\u001b[0m\n",
      "[ 80%] \u001b[0mBuilt target llama-finetune\u001b[0m\n",
      "[ 80%] \u001b[32mBuilding CXX object examples/diffusion/CMakeFiles/llama-diffusion-cli.dir/diffusion-cli.cpp.o\u001b[0m\n",
      "[ 81%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-diffusion-cli\u001b[0m\n",
      "[ 81%] \u001b[0mBuilt target llama-diffusion-cli\u001b[0m\n",
      "[ 81%] \u001b[32mBuilding CXX object examples/model-conversion/CMakeFiles/llama-logits.dir/logits.cpp.o\u001b[0m\n",
      "[ 81%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-logits\u001b[0m\n",
      "[ 81%] \u001b[0mBuilt target llama-logits\u001b[0m\n",
      "[ 82%] \u001b[32mBuilding CXX object examples/convert-llama2c-to-ggml/CMakeFiles/llama-convert-llama2c-to-ggml.dir/convert-llama2c-to-ggml.cpp.o\u001b[0m\n",
      "[ 82%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-convert-llama2c-to-ggml\u001b[0m\n",
      "[ 82%] \u001b[0mBuilt target llama-convert-llama2c-to-ggml\u001b[0m\n",
      "[ 82%] \u001b[32mBuilding CXX object pocs/vdot/CMakeFiles/llama-vdot.dir/vdot.cpp.o\u001b[0m\n",
      "[ 83%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-vdot\u001b[0m\n",
      "[ 83%] \u001b[0mBuilt target llama-vdot\u001b[0m\n",
      "[ 84%] \u001b[32mBuilding CXX object pocs/vdot/CMakeFiles/llama-q8dot.dir/q8dot.cpp.o\u001b[0m\n",
      "[ 84%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-q8dot\u001b[0m\n",
      "[ 84%] \u001b[0mBuilt target llama-q8dot\u001b[0m\n",
      "[ 84%] \u001b[32mBuilding CXX object tools/batched-bench/CMakeFiles/llama-batched-bench.dir/batched-bench.cpp.o\u001b[0m\n",
      "[ 85%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-batched-bench\u001b[0m\n",
      "[ 85%] \u001b[0mBuilt target llama-batched-bench\u001b[0m\n",
      "[ 86%] \u001b[32mBuilding CXX object tools/gguf-split/CMakeFiles/llama-gguf-split.dir/gguf-split.cpp.o\u001b[0m\n",
      "[ 86%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-gguf-split\u001b[0m\n",
      "[ 86%] \u001b[0mBuilt target llama-gguf-split\u001b[0m\n",
      "[ 86%] \u001b[32mBuilding CXX object tools/imatrix/CMakeFiles/llama-imatrix.dir/imatrix.cpp.o\u001b[0m\n",
      "[ 87%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-imatrix\u001b[0m\n",
      "[ 87%] \u001b[0mBuilt target llama-imatrix\u001b[0m\n",
      "[ 87%] \u001b[32mBuilding CXX object tools/llama-bench/CMakeFiles/llama-bench.dir/llama-bench.cpp.o\u001b[0m\n",
      "[ 88%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-bench\u001b[0m\n",
      "[ 88%] \u001b[0mBuilt target llama-bench\u001b[0m\n",
      "[ 88%] \u001b[32mBuilding CXX object tools/main/CMakeFiles/llama-cli.dir/main.cpp.o\u001b[0m\n",
      "[ 88%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-cli\u001b[0m\n",
      "[ 88%] \u001b[0mBuilt target llama-cli\u001b[0m\n",
      "[ 88%] \u001b[32mBuilding CXX object tools/perplexity/CMakeFiles/llama-perplexity.dir/perplexity.cpp.o\u001b[0m\n",
      "[ 88%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-perplexity\u001b[0m\n",
      "[ 88%] \u001b[0mBuilt target llama-perplexity\u001b[0m\n",
      "[ 89%] \u001b[32mBuilding CXX object tools/quantize/CMakeFiles/llama-quantize.dir/quantize.cpp.o\u001b[0m\n",
      "[ 89%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-quantize\u001b[0m\n",
      "[ 89%] \u001b[0mBuilt target llama-quantize\u001b[0m\n",
      "[ 89%] \u001b[1m\u001b[34mGenerating loading.html.hpp\u001b[0m\n",
      "[ 89%] \u001b[1m\u001b[34mGenerating index.html.gz.hpp\u001b[0m\n",
      "[ 90%] \u001b[32mBuilding CXX object tools/server/CMakeFiles/llama-server.dir/server.cpp.o\u001b[0m\n",
      "[ 90%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-server\u001b[0m\n",
      "[ 90%] \u001b[0mBuilt target llama-server\u001b[0m\n",
      "[ 90%] \u001b[32mBuilding CXX object tools/run/CMakeFiles/llama-run.dir/run.cpp.o\u001b[0m\n",
      "[ 90%] \u001b[32mBuilding CXX object tools/run/CMakeFiles/llama-run.dir/linenoise.cpp/linenoise.cpp.o\u001b[0m\n",
      "[ 91%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-run\u001b[0m\n",
      "[ 91%] \u001b[0mBuilt target llama-run\u001b[0m\n",
      "[ 92%] \u001b[32mBuilding CXX object tools/tokenize/CMakeFiles/llama-tokenize.dir/tokenize.cpp.o\u001b[0m\n",
      "[ 92%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-tokenize\u001b[0m\n",
      "[ 92%] \u001b[0mBuilt target llama-tokenize\u001b[0m\n",
      "[ 93%] \u001b[32mBuilding CXX object tools/tts/CMakeFiles/llama-tts.dir/tts.cpp.o\u001b[0m\n",
      "[ 93%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-tts\u001b[0m\n",
      "[ 93%] \u001b[0mBuilt target llama-tts\u001b[0m\n",
      "[ 93%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-llava-cli.dir/deprecation-warning.cpp.o\u001b[0m\n",
      "[ 94%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-llava-cli\u001b[0m\n",
      "[ 94%] \u001b[0mBuilt target llama-llava-cli\u001b[0m\n",
      "[ 94%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-gemma3-cli.dir/deprecation-warning.cpp.o\u001b[0m\n",
      "[ 95%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-gemma3-cli\u001b[0m\n",
      "[ 95%] \u001b[0mBuilt target llama-gemma3-cli\u001b[0m\n",
      "[ 96%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-minicpmv-cli.dir/deprecation-warning.cpp.o\u001b[0m\n",
      "[ 96%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-minicpmv-cli\u001b[0m\n",
      "[ 96%] \u001b[0mBuilt target llama-minicpmv-cli\u001b[0m\n",
      "[ 96%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-qwen2vl-cli.dir/deprecation-warning.cpp.o\u001b[0m\n",
      "[ 97%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-qwen2vl-cli\u001b[0m\n",
      "[ 97%] \u001b[0mBuilt target llama-qwen2vl-cli\u001b[0m\n",
      "[ 98%] \u001b[32mBuilding CXX object tools/mtmd/CMakeFiles/llama-mtmd-cli.dir/mtmd-cli.cpp.o\u001b[0m\n",
      "[ 98%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-mtmd-cli\u001b[0m\n",
      "[ 98%] \u001b[0mBuilt target llama-mtmd-cli\u001b[0m\n",
      "[ 99%] \u001b[32mBuilding CXX object tools/cvector-generator/CMakeFiles/llama-cvector-generator.dir/cvector-generator.cpp.o\u001b[0m\n",
      "[ 99%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-cvector-generator\u001b[0m\n",
      "[ 99%] \u001b[0mBuilt target llama-cvector-generator\u001b[0m\n",
      "[100%] \u001b[32mBuilding CXX object tools/export-lora/CMakeFiles/llama-export-lora.dir/export-lora.cpp.o\u001b[0m\n",
      "[100%] \u001b[1m\u001b[32mLinking CXX executable ../../bin/llama-export-lora\u001b[0m\n",
      "[100%] \u001b[0mBuilt target llama-export-lora\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# CPU BUILT\n",
    "!rm -rf llama.cpp/build\n",
    "!cmake -DGGML_OPENMP=OFF -DLLAMA_CURL=OFF -B llama.cpp/build -S llama.cpp\n",
    "!cmake --build llama.cpp/build --config Release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN =\"-----\" # Put in your Hugging Face Token here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load fine-tuned model using the PEFT library\n",
    "model = PeftModel.from_pretrained(base_model,\"sharshar20/career-advisory-qlora-llama3.2-3b-instruct-v7\", trust_remote_code=True)\n",
    "#3. Merge the model weights\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SafetensorError",
     "evalue": "Error while serializing: I/O error: No space left on device (os error 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSafetensorError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#4. Save the merged model and its tokenizer\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./merged_model_instruct_qlora\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m tokenizer = AutoTokenizer.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mmeta-llama/Llama-3.2-3B-Instruct\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m tokenizer.save_pretrained(\u001b[33m\"\u001b[39m\u001b[33m./merged_model_instruct_qlora\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/py311/lib/python3.11/site-packages/transformers/modeling_utils.py:4177\u001b[39m, in \u001b[36mPreTrainedModel.save_pretrained\u001b[39m\u001b[34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[39m\n\u001b[32m   4172\u001b[39m     gc.collect()\n\u001b[32m   4174\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m safe_serialization:\n\u001b[32m   4175\u001b[39m     \u001b[38;5;66;03m# At some point we will need to deal better with save_function (used for TPU and other distributed\u001b[39;00m\n\u001b[32m   4176\u001b[39m     \u001b[38;5;66;03m# joyfulness), but for now this enough.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4177\u001b[39m     \u001b[43msafe_save_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4178\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4179\u001b[39m     save_function(shard, os.path.join(save_directory, shard_file))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/py311/lib/python3.11/site-packages/safetensors/torch.py:352\u001b[39m, in \u001b[36msave_file\u001b[39m\u001b[34m(tensors, filename, metadata)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave_file\u001b[39m(\n\u001b[32m    322\u001b[39m     tensors: Dict[\u001b[38;5;28mstr\u001b[39m, torch.Tensor],\n\u001b[32m    323\u001b[39m     filename: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    324\u001b[39m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    325\u001b[39m ):\n\u001b[32m    326\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[33;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001b[39;00m\n\u001b[32m    328\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    350\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m     \u001b[43mserialize_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mSafetensorError\u001b[39m: Error while serializing: I/O error: No space left on device (os error 28)"
     ]
    }
   ],
   "source": [
    "#Save the merged model and its tokenizer\n",
    "model.save_pretrained(\"./merged_model_instruct_qlora\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "tokenizer.save_pretrained(\"./merged_model_instruct_qlora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770c9bff3e394e97bef6de667bba72cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42acce30f274cc499acd126271df9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea01b80c78644ad99b1d5246b7fe520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd17f0c38da487a9e0da2c9f48a10a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/sharshar20/qlora-and-instruct-merged-model-v7/commit/63ca988a213869eb09ceba03025bd486edd01feb', commit_message='token_Mergin QLoRA and Instruct model v7', commit_description='', oid='63ca988a213869eb09ceba03025bd486edd01feb', pr_url=None, repo_url=RepoUrl('https://huggingface.co/sharshar20/qlora-and-instruct-merged-model-v7', endpoint='https://huggingface.co', repo_type='model', repo_id='sharshar20/qlora-and-instruct-merged-model-v7'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Push the merged model directory\n",
    "model.push_to_hub(\"sharshar20/qlora-and-instruct-merged-model-v7\",\n",
    "                      commit_message = \"model_Mergin QLoRA and Instruct model v7\",\n",
    "                      token = HF_TOKEN,\n",
    "                      private=False)\n",
    "# Push the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "tokenizer.push_to_hub(\"sharshar20/qlora-and-instruct-merged-model-v7\",\n",
    "                      commit_message = \"token_Mergin QLoRA and Instruct model v7\",\n",
    "                      token = HF_TOKEN,\n",
    "                      private=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|██████████████████████████| 7/7 [00:00<00:00, 458.99it/s]\n",
      "INFO:hf-to-gguf:Downloaded config and tokenizer to /home/FYP/shar0097/.cache/huggingface/hub/models--sharshar20--qlora-and-instruct-merged-model-v7/snapshots/63ca988a213869eb09ceba03025bd486edd01feb\n",
      "INFO:hf-to-gguf:Loading model: 63ca988a213869eb09ceba03025bd486edd01feb\n",
      "INFO:hf-to-gguf:Model architecture: LlamaForCausalLM\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:rope_freqs.weight,           torch.float32 --> F32, shape = {64}\n",
      "INFO:hf-to-gguf:Using remote model with HuggingFace id: sharshar20/qlora-and-instruct-merged-model-v7\n",
      "INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {3072, 128256}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:gguf: context length = 131072\n",
      "INFO:hf-to-gguf:gguf: embedding length = 3072\n",
      "INFO:hf-to-gguf:gguf: feed forward length = 8192\n",
      "INFO:hf-to-gguf:gguf: head count = 24\n",
      "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
      "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
      "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
      "INFO:hf-to-gguf:gguf: file type = 1\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "WARNING:gguf.vocab:Unknown separator token '<|begin_of_text|>' in TemplateProcessing<pair>\n",
      "INFO:gguf.vocab:Adding 280147 merge(s).\n",
      "INFO:gguf.vocab:Setting special token type bos to 128000\n",
      "INFO:gguf.vocab:Setting special token type eos to 128009\n",
      "INFO:gguf.vocab:Setting add_bos_token to True\n",
      "INFO:gguf.vocab:Setting add_sep_token to False\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:quantized_models/fp16-ft-qlora.gguf: n_tensors = 255, total_size = 6.4G\n",
      "Writing:  29%|███████▋                  | 1.90G/6.43G [00:40<01:49, 41.5Mbyte/s]"
     ]
    }
   ],
   "source": [
    "# Convert qlora to fp16\n",
    "#!python llama.cpp/convert_hf_to_gguf.py ./merged_model_instruct_qlora --outtype f16 --outfile ./quantized_models/fp16-ft-qlora.gguf\n",
    "!python3 llama.cpp/convert_hf_to_gguf.py sharshar20/qlora-and-instruct-merged-model-v7 --remote \\\n",
    "  --outfile ./quantized_models/fp16-ft-qlora.gguf \\\n",
    "  --outtype f16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!./llama.cpp/build/bin/llama-quantize ./quantized_models/fp16-ft-qlora.gguf \\\n",
    "    --outfile ./quantized_models/ft-qlora-q4_k_m.gguf \\\n",
    "    --outtype Q4_K_M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98,
     "referenced_widgets": [
      "41ffc4de51854f38bff7cb7c691169aa",
      "1a27e8cef1274ddfb7888c59e0fcaa94",
      "99fb537695074a0099c42bddb9f08171",
      "9bb5835be9cc4bb5acd4d1f7fac92ce7",
      "2c02861753364342b3ff8e140832b52a",
      "0663a3cc37d04fe0979a76abb882597d",
      "d3233dac7f024ac29a9bd4f34c02c8c9",
      "321db23478bf4fa9b4135fcbe42a321d",
      "c2ede3abefb447f38d3f6c17d744af35",
      "f974c4bc87af4bb29e36e1b4cbfed50a",
      "fe1dbdc202a747f58ad6504fb7391a38",
      "1159428d248c4ec5adc88013abe22152",
      "f01ed6bdd5904f60a0ab9b197befbd30",
      "5ecf368fc0d240eba41835848b68ceba",
      "4effd5c268e74bbdaa273e13cedbafac",
      "cc0d5484dfb840fc941c27ba7bfffb1e",
      "7aaf02e821b04233a2d25eba17a8ef44",
      "8bc8765ea4fd4e2b9ae74deabc50bc12",
      "d44ff8e83b9d433a873b10b7e92bef4d",
      "a8364496f60b49658cb1292df2dd08e0",
      "3be525d0fd2f48e3bdcbc144caa0215d",
      "98df1fee28424a1d909be25e9ef169be"
     ]
    },
    "id": "K9CxdBTo3E_P",
    "outputId": "ce871ae2-876a-4901-874c-2b41362cc4bd"
   },
   "outputs": [],
   "source": [
    "#2. Load fine-tuned model using the PEFT library\n",
    "model = PeftModel.from_pretrained(base_model,\"sharshar20/career-advisory-lora-llama3.2-3b-instruct-v7\", trust_remote_code=True)\n",
    "#3. Merge the model weights\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165,
     "referenced_widgets": [
      "91cfa139678142c6ad8c93146829f22f",
      "17eb4d538db640bbaf88ab8a5714a572",
      "0288c3a537534527beca3c9546889619",
      "8749e9f967de43f4ad7e60547cfb0977",
      "77e0da2869bb427db25600549fd5a389",
      "e546e41db58046aaa0676d4e3f5d5ad2",
      "90662068fb2543d187e48a50e7107aaa",
      "79c9cc0a53484b2b8de512ed6e8df4ad",
      "b72ef72f0c0b4979b427023ce2761ddb",
      "2b3f483db9e74a648a073add58ce5be1",
      "ce15639b38a045e2b5ec879a860150e7",
      "8319c55fc8d7432fba3eb7fbf04970e7",
      "3d174d49dfcc4443a91dfd29d9ab5779",
      "379a7d9947e24b4bbbebe7b9b0d68d70",
      "f6d32088da8c42259971d83f977740af",
      "e465145941694efc842e5ffef949376c",
      "6ad9f70e7e5c40d7b11f210c9ffd8889",
      "ee790f82326c4803bf90ac780e93fb44",
      "986d8c7950824d25a7d16abcef3e1980",
      "643a82a3ac5a4fcc88c36c6502a4e7ff",
      "b9a08546be624b909257a7b2a44f98d3",
      "df2749eb46d74c85a57b8bd3c61a76fd",
      "6092d59cc3ce46648dd3d07e53f3e972",
      "7c59587d51c7439a8083068ed4c7e684",
      "6fde98bb3a654885bcc1fc276cb5b079",
      "7da62dcc79214a368d6ff9a68f3404cb",
      "cf93f08baa97487db0f4e103e5c57d1a",
      "d806b3a8d9f0431d8861acee5962bcf3",
      "13140568accd49e7bb86152e6bcaf515",
      "14e59081345d4b1ab34ee1a2179c02dc",
      "8c77b1129830468c9bed8edc907672be",
      "674dda9a47724ba8870530536de5ac32",
      "8ee02eb13cf342a897261e389f5c2ae8"
     ]
    },
    "id": "Reej3IO63Fz5",
    "outputId": "726561d1-f82b-437e-93f8-605aefffa25f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./merged_model_instruct_lora/tokenizer_config.json',\n",
       " './merged_model_instruct_lora/special_tokens_map.json',\n",
       " './merged_model_instruct_lora/chat_template.jinja',\n",
       " './merged_model_instruct_lora/tokenizer.json')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. Save the merged model and its tokenizer\n",
    "model.save_pretrained(\"./merged_model_instruct_lora\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "tokenizer.save_pretrained(\"./merged_model_instruct_lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN = \"-----\" # Put in your Hugging Face Token here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229,
     "referenced_widgets": [
      "e268de2ba38144ce968a0eb6719b0e8a",
      "3a5b729d477047249f880eae85bdabc3",
      "1378b3a8765c4c4d8b0f3bfb44495032",
      "0eb24510fd144cb88c565e35be4e2f12",
      "cbc8f36449104deab1e791f70a67e58e",
      "75c115fb48d84b4786c668ccc7dc7cea",
      "54265dfb860446aa9d3ef4e6eb40ae38",
      "f6286ff0daa3470194da5d945fceb31e",
      "f772c8f163214fdd8e4d8845bf037ced",
      "65a60afee7b144018c41c3462d91d232",
      "8510cce4a0354d30a27490fe0da82cdd",
      "a913bddc21374fcfa56f4ef0afdc4902",
      "67b2740c64ed474a91fa4961299b91ab",
      "63df08a761cf4d16911b109f04bc5700",
      "4e0075ea7dcf4f66975aea94fc47c7ce",
      "2aff03fc4aea4e86b66cad0f8d195b07",
      "6c6dc41f61fd43939a215b362d497156",
      "1e3a2c0ab05e4c2fa7e757ecc34cd818",
      "4a2798e8cb4c4065ba1218c1c277b3f3",
      "1c152f62467c46689c4435bb959410b7",
      "6ede66d7a5d44912b009a699aac5810f",
      "72e87311db4449c980e36e83cdd3b104",
      "4e0b0b0979b04eadb15469f2b4040968",
      "b887cf08ec2e4a17bb1ed2eeb12487c4",
      "3618831bd1734c95a0c7132974e856fe",
      "e026e63e2cba4d53abe032fe47c6fe59",
      "4817179b5911487eb3144202b3c811b2",
      "ca37f765c2c04f93a8397108125630da",
      "fe724c782e5046b5b8620ae89dd95fc4",
      "a4079bfe12b44140b874fee5b3578d41",
      "fc8348e8f2c64404bfb99770882f8a9c",
      "a1f2736db8d24e159e3dc074dbb8c032",
      "5fcedce52f1b423a995eef9725a5ea4a",
      "eacb9bcf8be541828ff3a55006bb2463",
      "e0f21439d9df4265adb93e99983d2a82",
      "71652bc242fc4fa9abc02a6ef71619a3",
      "af3c4516c0354ab3a4d5770d51ad2104",
      "e01eeacbdedc4eb189b6d002b2bf1a6d",
      "fcd2bb823bc94d62a45189d478bcada4",
      "5bd2d31bf2aa4fafa78e598d931ed4ee",
      "84e6b20859094a16be58f6ec99c5c7c4",
      "3be82b3111ca42b5a76d62caa38cbf96",
      "46a5473473534f2882d364dba680a1d4",
      "cb216c94f65b466a9abd25d1ab4cfdfc",
      "7fc16bb542f74248a3b61eeea754bd30",
      "fc95a715f5dc44908ecd59830814938f",
      "48ff244d4472495da478789616a9b04d",
      "fb087ed8f6d24e0895edf7425c77c427",
      "24cda1761122448188b9b010e4b77904",
      "2e3950d23a014c808af0e525f6712253",
      "3347f53c397543c9b07b7cfaa30acac3",
      "5edfc7ef96854c69ab0a2f431150c11e",
      "200d294388bb45c680f1858bc0f8f59a",
      "575ce6cb0fde466484f4f25ff2d655b5",
      "5e5a51d1354640848401b103901d381e"
     ]
    },
    "id": "xqHiTV94-lkd",
    "outputId": "85f1514c-ef13-4240-f5d8-08c0405c8144"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0206e0007834e9b92baaa47de149c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ca089209f04b75a0e1d175a0ee5574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d368a692efba4b92b64a1b5566f773b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1166397389405bbf5e385ba8682128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9824aabe935a44debadc9cd54ac29314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8166524e01a04d7bb05ff83138e8993f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d254b2016c446896a10c83f7695f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a10e970751f426e8d3b9ac18e6d8f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/sharshar20/lora-and-instruct-merged-model-v8/commit/73726fa7ef0ee6120f23358531a4862b42133839', commit_message='token_Mergin LoRA and Instruct model v7', commit_description='', oid='73726fa7ef0ee6120f23358531a4862b42133839', pr_url=None, repo_url=RepoUrl('https://huggingface.co/sharshar20/lora-and-instruct-merged-model-v8', endpoint='https://huggingface.co', repo_type='model', repo_id='sharshar20/lora-and-instruct-merged-model-v8'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Push the merged model directory\n",
    "model.push_to_hub(\"sharshar20/lora-and-instruct-merged-model-v8\",\n",
    "                      commit_message = \"model_Mergin LoRA and Instruct model v7\",\n",
    "                      token = HF_TOKEN,\n",
    "                      private=False)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "# Push the tokenizer\n",
    "tokenizer.push_to_hub(\"sharshar20/lora-and-instruct-merged-model-v8\",\n",
    "                      commit_message = \"token_Mergin LoRA and Instruct model v7\",\n",
    "                      token = HF_TOKEN,\n",
    "                      private=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UWFnnEmLrRf6",
    "outputId": "afa02d38-268e-4923-c680-7807a839fb30"
   },
   "outputs": [],
   "source": [
    "QUANTIZATION_METHODS = [\"q4_k_m\", \"q5_k_m\", \"q8_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NkJq0VjfIVnn",
    "outputId": "8b9e0f7f-e9f4-4714-c74e-14f0dc21338d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|█████████████████████████| 7/7 [00:00<00:00, 4407.77it/s]\n",
      "INFO:hf-to-gguf:Downloaded config and tokenizer to /home/FYP/shar0097/.cache/huggingface/hub/models--sharshar20--lora-and-instruct-merged-model-v8/snapshots/73726fa7ef0ee6120f23358531a4862b42133839\n",
      "INFO:hf-to-gguf:Loading model: 73726fa7ef0ee6120f23358531a4862b42133839\n",
      "INFO:hf-to-gguf:Model architecture: LlamaForCausalLM\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:rope_freqs.weight,           torch.float32 --> F32, shape = {64}\n",
      "INFO:hf-to-gguf:Using remote model with HuggingFace id: sharshar20/lora-and-instruct-merged-model-v8\n",
      "INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {3072, 128256}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
      "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
      "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
      "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float16 --> F16, shape = {3072, 1024}\n",
      "INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {3072}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:gguf: context length = 131072\n",
      "INFO:hf-to-gguf:gguf: embedding length = 3072\n",
      "INFO:hf-to-gguf:gguf: feed forward length = 8192\n",
      "INFO:hf-to-gguf:gguf: head count = 24\n",
      "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
      "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
      "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
      "INFO:hf-to-gguf:gguf: file type = 1\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "WARNING:gguf.vocab:Unknown separator token '<|begin_of_text|>' in TemplateProcessing<pair>\n",
      "INFO:gguf.vocab:Adding 280147 merge(s).\n",
      "INFO:gguf.vocab:Setting special token type bos to 128000\n",
      "INFO:gguf.vocab:Setting special token type eos to 128009\n",
      "INFO:gguf.vocab:Setting add_bos_token to True\n",
      "INFO:gguf.vocab:Setting add_sep_token to False\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:quantized_models/fp16-ft-lora.gguf: n_tensors = 255, total_size = 6.4G\n",
      "Writing: 100%|██████████████████████████| 6.43G/6.43G [07:35<00:00, 14.1Mbyte/s]\n",
      "INFO:hf-to-gguf:Model successfully exported to quantized_models/fp16-ft-lora.gguf\n",
      "main: build = 6713 (d2ee056e)\n",
      "main: built with cc (GCC) 11.5.0 20240719 (Red Hat 11.5.0-5) for x86_64-redhat-linux\n",
      "main: quantizing './quantized_models/fp16-ft-lora.gguf' to './quantized_models/ft-q4_k_m-lora.gguf' as Q4_K_M\n",
      "llama_model_loader: loaded meta data with 28 key-value pairs and 255 tensors from ./quantized_models/fp16-ft-lora.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = sharshar20/lora-and-instruct-merged-m...\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = 73726fa7ef0ee6120f23358531a4862b42133839\n",
      "llama_model_loader: - kv   4:                         general.size_label str              = 3.2B\n",
      "llama_model_loader: - kv   5:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   6:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   7:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   8:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   9:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv  10:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  12:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  13:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  14:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  15:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  16:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  17:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  19:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  20:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  21:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  22:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  23:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  25:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  26:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  27:               tokenizer.ggml.add_sep_token bool             = false\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type  f16:  197 tensors\n",
      "[   1/ 255]                   output_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[   2/ 255]                    rope_freqs.weight - [   64,     1,     1,     1], type =    f32, size =    0.000 MiB\n",
      "[   3/ 255]                    token_embd.weight - [ 3072, 128256,     1,     1], type =    f16, converting to q6_K .. size =   751.50 MiB ->   308.23 MiB\n",
      "[   4/ 255]                  blk.0.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[   5/ 255]               blk.0.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[   6/ 255]             blk.0.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[   7/ 255]                  blk.0.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[   8/ 255]                  blk.0.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[   9/ 255]                blk.0.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[  10/ 255]                blk.0.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  11/ 255]                blk.0.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  12/ 255]                  blk.0.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  13/ 255]                  blk.1.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  14/ 255]               blk.1.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  15/ 255]             blk.1.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  16/ 255]                  blk.1.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  17/ 255]                  blk.1.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[  18/ 255]                blk.1.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[  19/ 255]                blk.1.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  20/ 255]                blk.1.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  21/ 255]                  blk.1.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  22/ 255]                  blk.2.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  23/ 255]               blk.2.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  24/ 255]             blk.2.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  25/ 255]                  blk.2.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  26/ 255]                  blk.2.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[  27/ 255]                blk.2.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[  28/ 255]                blk.2.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  29/ 255]                blk.2.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  30/ 255]                  blk.2.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  31/ 255]                  blk.3.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  32/ 255]               blk.3.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  33/ 255]             blk.3.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  34/ 255]                  blk.3.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  35/ 255]                  blk.3.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  36/ 255]                blk.3.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  37/ 255]                blk.3.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  38/ 255]                blk.3.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  39/ 255]                  blk.3.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  40/ 255]                  blk.4.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  41/ 255]               blk.4.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  42/ 255]             blk.4.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  43/ 255]                  blk.4.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  44/ 255]                  blk.4.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  45/ 255]                blk.4.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  46/ 255]                blk.4.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  47/ 255]                blk.4.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  48/ 255]                  blk.4.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  49/ 255]                  blk.5.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  50/ 255]               blk.5.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  51/ 255]             blk.5.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  52/ 255]                  blk.5.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  53/ 255]                  blk.5.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[  54/ 255]                blk.5.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[  55/ 255]                blk.5.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  56/ 255]                blk.5.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  57/ 255]                  blk.5.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  58/ 255]                  blk.6.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  59/ 255]               blk.6.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  60/ 255]             blk.6.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  61/ 255]                  blk.6.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  62/ 255]                  blk.6.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  63/ 255]                blk.6.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  64/ 255]                blk.6.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  65/ 255]                blk.6.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  66/ 255]                  blk.6.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  67/ 255]                  blk.7.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  68/ 255]               blk.7.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  69/ 255]             blk.7.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  70/ 255]                  blk.7.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  71/ 255]                  blk.7.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  72/ 255]                blk.7.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  73/ 255]                blk.7.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  74/ 255]                blk.7.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  75/ 255]                  blk.7.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  76/ 255]                  blk.8.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  77/ 255]               blk.8.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  78/ 255]             blk.8.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  79/ 255]                  blk.8.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  80/ 255]                  blk.8.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[  81/ 255]                blk.8.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[  82/ 255]                blk.8.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  83/ 255]                blk.8.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  84/ 255]                  blk.8.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  85/ 255]                  blk.9.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  86/ 255]               blk.9.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  87/ 255]             blk.9.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  88/ 255]                  blk.9.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  89/ 255]                  blk.9.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  90/ 255]                blk.9.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  91/ 255]                blk.9.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  92/ 255]                blk.9.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  93/ 255]                  blk.9.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[  94/ 255]                 blk.10.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  95/ 255]              blk.10.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  96/ 255]            blk.10.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  97/ 255]                 blk.10.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[  98/ 255]                 blk.10.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[  99/ 255]               blk.10.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 100/ 255]               blk.10.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 101/ 255]               blk.10.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 102/ 255]                 blk.10.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 103/ 255]                 blk.11.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 104/ 255]              blk.11.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 105/ 255]            blk.11.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 106/ 255]                 blk.11.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 107/ 255]                 blk.11.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 108/ 255]               blk.11.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 109/ 255]               blk.11.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 110/ 255]               blk.11.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 111/ 255]                 blk.11.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 112/ 255]                 blk.12.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 113/ 255]              blk.12.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 114/ 255]            blk.12.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 115/ 255]                 blk.12.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 116/ 255]                 blk.12.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 117/ 255]               blk.12.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 118/ 255]               blk.12.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 119/ 255]               blk.12.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 120/ 255]                 blk.12.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 121/ 255]                 blk.13.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 122/ 255]              blk.13.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 123/ 255]            blk.13.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 124/ 255]                 blk.13.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 125/ 255]                 blk.13.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 126/ 255]               blk.13.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 127/ 255]               blk.13.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 128/ 255]               blk.13.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 129/ 255]                 blk.13.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 130/ 255]                 blk.14.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 131/ 255]              blk.14.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 132/ 255]            blk.14.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 133/ 255]                 blk.14.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 134/ 255]                 blk.14.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 135/ 255]               blk.14.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 136/ 255]               blk.14.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 137/ 255]               blk.14.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 138/ 255]                 blk.14.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 139/ 255]                 blk.15.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 140/ 255]              blk.15.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 141/ 255]            blk.15.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 142/ 255]                 blk.15.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 143/ 255]                 blk.15.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 144/ 255]               blk.15.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 145/ 255]               blk.15.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 146/ 255]               blk.15.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 147/ 255]                 blk.15.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 148/ 255]                 blk.16.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 149/ 255]              blk.16.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 150/ 255]            blk.16.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 151/ 255]                 blk.16.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 152/ 255]                 blk.16.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 153/ 255]               blk.16.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 154/ 255]               blk.16.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 155/ 255]               blk.16.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 156/ 255]                 blk.16.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 157/ 255]                 blk.17.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 158/ 255]              blk.17.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 159/ 255]            blk.17.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 160/ 255]                 blk.17.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 161/ 255]                 blk.17.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 162/ 255]               blk.17.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 163/ 255]               blk.17.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 164/ 255]               blk.17.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 165/ 255]                 blk.17.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 166/ 255]                 blk.18.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 167/ 255]              blk.18.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 168/ 255]            blk.18.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 169/ 255]                 blk.18.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 170/ 255]                 blk.18.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 171/ 255]               blk.18.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 172/ 255]               blk.18.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 173/ 255]               blk.18.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 174/ 255]                 blk.18.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 175/ 255]                 blk.19.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 176/ 255]              blk.19.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 177/ 255]            blk.19.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 178/ 255]                 blk.19.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 179/ 255]                 blk.19.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 180/ 255]               blk.19.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 181/ 255]               blk.19.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 182/ 255]               blk.19.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 183/ 255]                 blk.19.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 184/ 255]                 blk.20.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 185/ 255]              blk.20.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 186/ 255]            blk.20.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 187/ 255]                 blk.20.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 188/ 255]                 blk.20.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 189/ 255]               blk.20.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 190/ 255]               blk.20.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 191/ 255]               blk.20.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 192/ 255]                 blk.20.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 193/ 255]                 blk.21.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 194/ 255]              blk.21.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 195/ 255]            blk.21.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 196/ 255]                 blk.21.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 197/ 255]                 blk.21.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 198/ 255]               blk.21.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 199/ 255]               blk.21.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 200/ 255]               blk.21.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 201/ 255]                 blk.21.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 202/ 255]                 blk.22.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 203/ 255]              blk.22.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 204/ 255]            blk.22.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 205/ 255]                 blk.22.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 206/ 255]                 blk.22.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 207/ 255]               blk.22.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 208/ 255]               blk.22.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 209/ 255]               blk.22.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 210/ 255]                 blk.22.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 211/ 255]                 blk.23.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 212/ 255]              blk.23.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 213/ 255]            blk.23.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 214/ 255]                 blk.23.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 215/ 255]                 blk.23.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 216/ 255]               blk.23.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 217/ 255]               blk.23.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 218/ 255]               blk.23.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 219/ 255]                 blk.23.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 220/ 255]                 blk.24.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 221/ 255]              blk.24.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 222/ 255]            blk.24.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 223/ 255]                 blk.24.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 224/ 255]                 blk.24.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 225/ 255]               blk.24.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 226/ 255]               blk.24.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 227/ 255]               blk.24.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 228/ 255]                 blk.24.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 229/ 255]                 blk.25.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 230/ 255]              blk.25.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 231/ 255]            blk.25.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 232/ 255]                 blk.25.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 233/ 255]                 blk.25.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 234/ 255]               blk.25.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 235/ 255]               blk.25.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 236/ 255]               blk.25.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 237/ 255]                 blk.25.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 238/ 255]                 blk.26.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 239/ 255]              blk.26.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 240/ 255]            blk.26.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 241/ 255]                 blk.26.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 242/ 255]                 blk.26.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 243/ 255]               blk.26.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 244/ 255]               blk.26.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 245/ 255]               blk.26.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 246/ 255]                 blk.26.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 247/ 255]                 blk.27.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q4_K .. size =     6.00 MiB ->     1.69 MiB\n",
      "[ 248/ 255]              blk.27.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 249/ 255]            blk.27.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 250/ 255]                 blk.27.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
      "[ 251/ 255]                 blk.27.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 252/ 255]               blk.27.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 253/ 255]               blk.27.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "[ 254/ 255]               blk.27.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 255/ 255]                 blk.27.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
      "llama_model_quantize_impl: model size  =  6128.17 MiB\n",
      "llama_model_quantize_impl: quant size  =  1918.35 MiB\n",
      "\n",
      "main: quantize time = 275750.95 ms\n",
      "main:    total time = 275750.95 ms\n",
      "main: build = 6713 (d2ee056e)\n",
      "main: built with cc (GCC) 11.5.0 20240719 (Red Hat 11.5.0-5) for x86_64-redhat-linux\n",
      "main: quantizing './quantized_models/fp16-ft-lora.gguf' to './quantized_models/ft-q5_k_m-lora.gguf' as Q5_K_M\n",
      "llama_model_loader: loaded meta data with 28 key-value pairs and 255 tensors from ./quantized_models/fp16-ft-lora.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = sharshar20/lora-and-instruct-merged-m...\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = 73726fa7ef0ee6120f23358531a4862b42133839\n",
      "llama_model_loader: - kv   4:                         general.size_label str              = 3.2B\n",
      "llama_model_loader: - kv   5:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   6:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   7:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   8:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   9:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv  10:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  12:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  13:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  14:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  15:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  16:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  17:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  19:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  20:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  21:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  22:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  23:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  25:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  26:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  27:               tokenizer.ggml.add_sep_token bool             = false\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type  f16:  197 tensors\n",
      "[   1/ 255]                   output_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[   2/ 255]                    rope_freqs.weight - [   64,     1,     1,     1], type =    f32, size =    0.000 MiB\n",
      "[   3/ 255]                    token_embd.weight - [ 3072, 128256,     1,     1], type =    f16, converting to q6_K .. size =   751.50 MiB ->   308.23 MiB\n",
      "[   4/ 255]                  blk.0.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[   5/ 255]               blk.0.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[   6/ 255]             blk.0.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[   7/ 255]                  blk.0.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[   8/ 255]                  blk.0.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[   9/ 255]                blk.0.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[  10/ 255]                blk.0.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  11/ 255]                blk.0.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  12/ 255]                  blk.0.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  13/ 255]                  blk.1.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[  14/ 255]               blk.1.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  15/ 255]             blk.1.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[  16/ 255]                  blk.1.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[  17/ 255]                  blk.1.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[  18/ 255]                blk.1.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[  19/ 255]                blk.1.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  20/ 255]                blk.1.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  21/ 255]                  blk.1.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  22/ 255]                  blk.2.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[  23/ 255]               blk.2.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  24/ 255]             blk.2.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[  25/ 255]                  blk.2.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[  26/ 255]                  blk.2.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[  27/ 255]                blk.2.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[  28/ 255]                blk.2.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  29/ 255]                blk.2.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  30/ 255]                  blk.2.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  31/ 255]                  blk.3.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[  32/ 255]               blk.3.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  33/ 255]             blk.3.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[  34/ 255]                  blk.3.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[  35/ 255]                  blk.3.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[  36/ 255]                blk.3.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  37/ 255]                blk.3.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  38/ 255]                blk.3.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  39/ 255]                  blk.3.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  40/ 255]                  blk.4.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[  41/ 255]               blk.4.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  42/ 255]             blk.4.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[  43/ 255]                  blk.4.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[  44/ 255]                  blk.4.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[  45/ 255]                blk.4.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  46/ 255]                blk.4.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  47/ 255]                blk.4.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  48/ 255]                  blk.4.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  49/ 255]                  blk.5.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[  50/ 255]               blk.5.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  51/ 255]             blk.5.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[  52/ 255]                  blk.5.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[  53/ 255]                  blk.5.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[  54/ 255]                blk.5.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[  55/ 255]                blk.5.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  56/ 255]                blk.5.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  57/ 255]                  blk.5.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  58/ 255]                  blk.6.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[  59/ 255]               blk.6.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  60/ 255]             blk.6.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[  61/ 255]                  blk.6.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[  62/ 255]                  blk.6.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[  63/ 255]                blk.6.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  64/ 255]                blk.6.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  65/ 255]                blk.6.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  66/ 255]                  blk.6.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  67/ 255]                  blk.7.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[  68/ 255]               blk.7.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  69/ 255]             blk.7.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[  70/ 255]                  blk.7.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[  71/ 255]                  blk.7.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[  72/ 255]                blk.7.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  73/ 255]                blk.7.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  74/ 255]                blk.7.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  75/ 255]                  blk.7.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  76/ 255]                  blk.8.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[  77/ 255]               blk.8.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  78/ 255]             blk.8.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[  79/ 255]                  blk.8.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[  80/ 255]                  blk.8.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[  81/ 255]                blk.8.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[  82/ 255]                blk.8.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  83/ 255]                blk.8.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  84/ 255]                  blk.8.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  85/ 255]                  blk.9.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[  86/ 255]               blk.9.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  87/ 255]             blk.9.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[  88/ 255]                  blk.9.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[  89/ 255]                  blk.9.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[  90/ 255]                blk.9.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  91/ 255]                blk.9.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  92/ 255]                blk.9.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  93/ 255]                  blk.9.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[  94/ 255]                 blk.10.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[  95/ 255]              blk.10.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  96/ 255]            blk.10.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[  97/ 255]                 blk.10.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[  98/ 255]                 blk.10.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[  99/ 255]               blk.10.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 100/ 255]               blk.10.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 101/ 255]               blk.10.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 102/ 255]                 blk.10.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 103/ 255]                 blk.11.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 104/ 255]              blk.11.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 105/ 255]            blk.11.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 106/ 255]                 blk.11.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 107/ 255]                 blk.11.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 108/ 255]               blk.11.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 109/ 255]               blk.11.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 110/ 255]               blk.11.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 111/ 255]                 blk.11.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 112/ 255]                 blk.12.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 113/ 255]              blk.12.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 114/ 255]            blk.12.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 115/ 255]                 blk.12.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 116/ 255]                 blk.12.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 117/ 255]               blk.12.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 118/ 255]               blk.12.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 119/ 255]               blk.12.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 120/ 255]                 blk.12.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 121/ 255]                 blk.13.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 122/ 255]              blk.13.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 123/ 255]            blk.13.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 124/ 255]                 blk.13.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 125/ 255]                 blk.13.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 126/ 255]               blk.13.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 127/ 255]               blk.13.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 128/ 255]               blk.13.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 129/ 255]                 blk.13.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 130/ 255]                 blk.14.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 131/ 255]              blk.14.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 132/ 255]            blk.14.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 133/ 255]                 blk.14.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 134/ 255]                 blk.14.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 135/ 255]               blk.14.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 136/ 255]               blk.14.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 137/ 255]               blk.14.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 138/ 255]                 blk.14.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 139/ 255]                 blk.15.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 140/ 255]              blk.15.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 141/ 255]            blk.15.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 142/ 255]                 blk.15.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 143/ 255]                 blk.15.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 144/ 255]               blk.15.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 145/ 255]               blk.15.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 146/ 255]               blk.15.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 147/ 255]                 blk.15.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 148/ 255]                 blk.16.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 149/ 255]              blk.16.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 150/ 255]            blk.16.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 151/ 255]                 blk.16.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 152/ 255]                 blk.16.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 153/ 255]               blk.16.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 154/ 255]               blk.16.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 155/ 255]               blk.16.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 156/ 255]                 blk.16.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 157/ 255]                 blk.17.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 158/ 255]              blk.17.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 159/ 255]            blk.17.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 160/ 255]                 blk.17.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 161/ 255]                 blk.17.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 162/ 255]               blk.17.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 163/ 255]               blk.17.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 164/ 255]               blk.17.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 165/ 255]                 blk.17.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 166/ 255]                 blk.18.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 167/ 255]              blk.18.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 168/ 255]            blk.18.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 169/ 255]                 blk.18.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 170/ 255]                 blk.18.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 171/ 255]               blk.18.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 172/ 255]               blk.18.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 173/ 255]               blk.18.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 174/ 255]                 blk.18.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 175/ 255]                 blk.19.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 176/ 255]              blk.19.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 177/ 255]            blk.19.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 178/ 255]                 blk.19.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 179/ 255]                 blk.19.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 180/ 255]               blk.19.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 181/ 255]               blk.19.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 182/ 255]               blk.19.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 183/ 255]                 blk.19.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 184/ 255]                 blk.20.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 185/ 255]              blk.20.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 186/ 255]            blk.20.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 187/ 255]                 blk.20.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 188/ 255]                 blk.20.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 189/ 255]               blk.20.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 190/ 255]               blk.20.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 191/ 255]               blk.20.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 192/ 255]                 blk.20.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 193/ 255]                 blk.21.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 194/ 255]              blk.21.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 195/ 255]            blk.21.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 196/ 255]                 blk.21.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 197/ 255]                 blk.21.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 198/ 255]               blk.21.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 199/ 255]               blk.21.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 200/ 255]               blk.21.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 201/ 255]                 blk.21.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 202/ 255]                 blk.22.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 203/ 255]              blk.22.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 204/ 255]            blk.22.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 205/ 255]                 blk.22.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 206/ 255]                 blk.22.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 207/ 255]               blk.22.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 208/ 255]               blk.22.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 209/ 255]               blk.22.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 210/ 255]                 blk.22.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 211/ 255]                 blk.23.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 212/ 255]              blk.23.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 213/ 255]            blk.23.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 214/ 255]                 blk.23.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 215/ 255]                 blk.23.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 216/ 255]               blk.23.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 217/ 255]               blk.23.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 218/ 255]               blk.23.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 219/ 255]                 blk.23.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 220/ 255]                 blk.24.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 221/ 255]              blk.24.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 222/ 255]            blk.24.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 223/ 255]                 blk.24.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 224/ 255]                 blk.24.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 225/ 255]               blk.24.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 226/ 255]               blk.24.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 227/ 255]               blk.24.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 228/ 255]                 blk.24.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 229/ 255]                 blk.25.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 230/ 255]              blk.25.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 231/ 255]            blk.25.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 232/ 255]                 blk.25.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 233/ 255]                 blk.25.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 234/ 255]               blk.25.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 235/ 255]               blk.25.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 236/ 255]               blk.25.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 237/ 255]                 blk.25.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 238/ 255]                 blk.26.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 239/ 255]              blk.26.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 240/ 255]            blk.26.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 241/ 255]                 blk.26.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 242/ 255]                 blk.26.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 243/ 255]               blk.26.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 244/ 255]               blk.26.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 245/ 255]               blk.26.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 246/ 255]                 blk.26.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 247/ 255]                 blk.27.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q5_K .. size =     6.00 MiB ->     2.06 MiB\n",
      "[ 248/ 255]              blk.27.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 249/ 255]            blk.27.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 250/ 255]                 blk.27.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q5_K .. size =    18.00 MiB ->     6.19 MiB\n",
      "[ 251/ 255]                 blk.27.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q6_K .. size =     6.00 MiB ->     2.46 MiB\n",
      "[ 252/ 255]               blk.27.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
      "[ 253/ 255]               blk.27.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "[ 254/ 255]               blk.27.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 255/ 255]                 blk.27.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q5_K .. size =    48.00 MiB ->    16.50 MiB\n",
      "llama_model_quantize_impl: model size  =  6128.17 MiB\n",
      "llama_model_quantize_impl: quant size  =  2207.10 MiB\n",
      "\n",
      "main: quantize time = 198999.34 ms\n",
      "main:    total time = 198999.34 ms\n",
      "main: build = 6713 (d2ee056e)\n",
      "main: built with cc (GCC) 11.5.0 20240719 (Red Hat 11.5.0-5) for x86_64-redhat-linux\n",
      "main: quantizing './quantized_models/fp16-ft-lora.gguf' to './quantized_models/ft-q8_0-lora.gguf' as Q8_0\n",
      "llama_model_loader: loaded meta data with 28 key-value pairs and 255 tensors from ./quantized_models/fp16-ft-lora.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = sharshar20/lora-and-instruct-merged-m...\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = 73726fa7ef0ee6120f23358531a4862b42133839\n",
      "llama_model_loader: - kv   4:                         general.size_label str              = 3.2B\n",
      "llama_model_loader: - kv   5:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   6:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   7:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   8:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   9:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv  10:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  12:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  13:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  14:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  15:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  16:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  17:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  19:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  20:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  21:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  22:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  23:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  25:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  26:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  27:               tokenizer.ggml.add_sep_token bool             = false\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type  f16:  197 tensors\n",
      "[   1/ 255]                   output_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[   2/ 255]                    rope_freqs.weight - [   64,     1,     1,     1], type =    f32, size =    0.000 MiB\n",
      "[   3/ 255]                    token_embd.weight - [ 3072, 128256,     1,     1], type =    f16, converting to q8_0 .. size =   751.50 MiB ->   399.23 MiB\n",
      "[   4/ 255]                  blk.0.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[   5/ 255]               blk.0.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[   6/ 255]             blk.0.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[   7/ 255]                  blk.0.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[   8/ 255]                  blk.0.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[   9/ 255]                blk.0.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  10/ 255]                blk.0.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  11/ 255]                blk.0.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  12/ 255]                  blk.0.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  13/ 255]                  blk.1.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  14/ 255]               blk.1.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  15/ 255]             blk.1.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  16/ 255]                  blk.1.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  17/ 255]                  blk.1.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  18/ 255]                blk.1.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  19/ 255]                blk.1.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  20/ 255]                blk.1.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  21/ 255]                  blk.1.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  22/ 255]                  blk.2.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  23/ 255]               blk.2.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  24/ 255]             blk.2.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  25/ 255]                  blk.2.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  26/ 255]                  blk.2.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  27/ 255]                blk.2.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  28/ 255]                blk.2.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  29/ 255]                blk.2.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  30/ 255]                  blk.2.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  31/ 255]                  blk.3.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  32/ 255]               blk.3.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  33/ 255]             blk.3.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  34/ 255]                  blk.3.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  35/ 255]                  blk.3.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  36/ 255]                blk.3.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  37/ 255]                blk.3.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  38/ 255]                blk.3.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  39/ 255]                  blk.3.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  40/ 255]                  blk.4.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  41/ 255]               blk.4.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  42/ 255]             blk.4.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  43/ 255]                  blk.4.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  44/ 255]                  blk.4.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  45/ 255]                blk.4.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  46/ 255]                blk.4.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  47/ 255]                blk.4.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  48/ 255]                  blk.4.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  49/ 255]                  blk.5.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  50/ 255]               blk.5.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  51/ 255]             blk.5.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  52/ 255]                  blk.5.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  53/ 255]                  blk.5.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  54/ 255]                blk.5.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  55/ 255]                blk.5.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  56/ 255]                blk.5.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  57/ 255]                  blk.5.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  58/ 255]                  blk.6.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  59/ 255]               blk.6.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  60/ 255]             blk.6.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  61/ 255]                  blk.6.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  62/ 255]                  blk.6.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  63/ 255]                blk.6.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  64/ 255]                blk.6.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  65/ 255]                blk.6.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  66/ 255]                  blk.6.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  67/ 255]                  blk.7.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  68/ 255]               blk.7.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  69/ 255]             blk.7.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  70/ 255]                  blk.7.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  71/ 255]                  blk.7.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  72/ 255]                blk.7.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  73/ 255]                blk.7.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  74/ 255]                blk.7.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  75/ 255]                  blk.7.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  76/ 255]                  blk.8.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  77/ 255]               blk.8.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  78/ 255]             blk.8.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  79/ 255]                  blk.8.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  80/ 255]                  blk.8.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  81/ 255]                blk.8.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  82/ 255]                blk.8.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  83/ 255]                blk.8.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  84/ 255]                  blk.8.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  85/ 255]                  blk.9.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  86/ 255]               blk.9.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  87/ 255]             blk.9.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  88/ 255]                  blk.9.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  89/ 255]                  blk.9.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  90/ 255]                blk.9.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  91/ 255]                blk.9.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  92/ 255]                blk.9.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  93/ 255]                  blk.9.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[  94/ 255]                 blk.10.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  95/ 255]              blk.10.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[  96/ 255]            blk.10.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  97/ 255]                 blk.10.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[  98/ 255]                 blk.10.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[  99/ 255]               blk.10.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 100/ 255]               blk.10.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 101/ 255]               blk.10.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 102/ 255]                 blk.10.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 103/ 255]                 blk.11.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 104/ 255]              blk.11.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 105/ 255]            blk.11.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 106/ 255]                 blk.11.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 107/ 255]                 blk.11.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 108/ 255]               blk.11.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 109/ 255]               blk.11.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 110/ 255]               blk.11.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 111/ 255]                 blk.11.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 112/ 255]                 blk.12.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 113/ 255]              blk.12.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 114/ 255]            blk.12.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 115/ 255]                 blk.12.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 116/ 255]                 blk.12.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 117/ 255]               blk.12.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 118/ 255]               blk.12.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 119/ 255]               blk.12.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 120/ 255]                 blk.12.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 121/ 255]                 blk.13.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 122/ 255]              blk.13.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 123/ 255]            blk.13.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 124/ 255]                 blk.13.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 125/ 255]                 blk.13.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 126/ 255]               blk.13.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 127/ 255]               blk.13.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 128/ 255]               blk.13.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 129/ 255]                 blk.13.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 130/ 255]                 blk.14.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 131/ 255]              blk.14.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 132/ 255]            blk.14.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 133/ 255]                 blk.14.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 134/ 255]                 blk.14.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 135/ 255]               blk.14.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 136/ 255]               blk.14.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 137/ 255]               blk.14.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 138/ 255]                 blk.14.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 139/ 255]                 blk.15.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 140/ 255]              blk.15.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 141/ 255]            blk.15.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 142/ 255]                 blk.15.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 143/ 255]                 blk.15.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 144/ 255]               blk.15.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 145/ 255]               blk.15.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 146/ 255]               blk.15.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 147/ 255]                 blk.15.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 148/ 255]                 blk.16.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 149/ 255]              blk.16.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 150/ 255]            blk.16.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 151/ 255]                 blk.16.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 152/ 255]                 blk.16.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 153/ 255]               blk.16.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 154/ 255]               blk.16.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 155/ 255]               blk.16.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 156/ 255]                 blk.16.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 157/ 255]                 blk.17.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 158/ 255]              blk.17.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 159/ 255]            blk.17.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 160/ 255]                 blk.17.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 161/ 255]                 blk.17.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 162/ 255]               blk.17.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 163/ 255]               blk.17.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 164/ 255]               blk.17.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 165/ 255]                 blk.17.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 166/ 255]                 blk.18.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 167/ 255]              blk.18.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 168/ 255]            blk.18.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 169/ 255]                 blk.18.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 170/ 255]                 blk.18.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 171/ 255]               blk.18.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 172/ 255]               blk.18.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 173/ 255]               blk.18.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 174/ 255]                 blk.18.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 175/ 255]                 blk.19.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 176/ 255]              blk.19.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 177/ 255]            blk.19.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 178/ 255]                 blk.19.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 179/ 255]                 blk.19.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 180/ 255]               blk.19.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 181/ 255]               blk.19.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 182/ 255]               blk.19.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 183/ 255]                 blk.19.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 184/ 255]                 blk.20.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 185/ 255]              blk.20.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 186/ 255]            blk.20.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 187/ 255]                 blk.20.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 188/ 255]                 blk.20.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 189/ 255]               blk.20.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 190/ 255]               blk.20.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 191/ 255]               blk.20.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 192/ 255]                 blk.20.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 193/ 255]                 blk.21.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 194/ 255]              blk.21.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 195/ 255]            blk.21.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 196/ 255]                 blk.21.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 197/ 255]                 blk.21.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 198/ 255]               blk.21.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 199/ 255]               blk.21.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 200/ 255]               blk.21.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 201/ 255]                 blk.21.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 202/ 255]                 blk.22.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 203/ 255]              blk.22.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 204/ 255]            blk.22.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 205/ 255]                 blk.22.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 206/ 255]                 blk.22.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 207/ 255]               blk.22.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 208/ 255]               blk.22.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 209/ 255]               blk.22.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 210/ 255]                 blk.22.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 211/ 255]                 blk.23.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 212/ 255]              blk.23.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 213/ 255]            blk.23.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 214/ 255]                 blk.23.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 215/ 255]                 blk.23.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 216/ 255]               blk.23.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 217/ 255]               blk.23.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 218/ 255]               blk.23.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 219/ 255]                 blk.23.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 220/ 255]                 blk.24.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 221/ 255]              blk.24.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 222/ 255]            blk.24.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 223/ 255]                 blk.24.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 224/ 255]                 blk.24.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 225/ 255]               blk.24.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 226/ 255]               blk.24.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 227/ 255]               blk.24.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 228/ 255]                 blk.24.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 229/ 255]                 blk.25.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 230/ 255]              blk.25.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 231/ 255]            blk.25.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 232/ 255]                 blk.25.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 233/ 255]                 blk.25.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 234/ 255]               blk.25.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 235/ 255]               blk.25.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 236/ 255]               blk.25.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 237/ 255]                 blk.25.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 238/ 255]                 blk.26.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 239/ 255]              blk.26.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 240/ 255]            blk.26.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 241/ 255]                 blk.26.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 242/ 255]                 blk.26.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 243/ 255]               blk.26.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 244/ 255]               blk.26.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 245/ 255]               blk.26.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 246/ 255]                 blk.26.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 247/ 255]                 blk.27.attn_k.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 248/ 255]              blk.27.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 249/ 255]            blk.27.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 250/ 255]                 blk.27.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    18.00 MiB ->     9.56 MiB\n",
      "[ 251/ 255]                 blk.27.attn_v.weight - [ 3072,  1024,     1,     1], type =    f16, converting to q8_0 .. size =     6.00 MiB ->     3.19 MiB\n",
      "[ 252/ 255]               blk.27.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 253/ 255]               blk.27.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "[ 254/ 255]               blk.27.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MiB\n",
      "[ 255/ 255]                 blk.27.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    48.00 MiB ->    25.50 MiB\n",
      "llama_model_quantize_impl: model size  =  6128.17 MiB\n",
      "llama_model_quantize_impl: quant size  =  3255.90 MiB\n",
      "\n",
      "main: quantize time = 41103.44 ms\n",
      "main:    total time = 41103.44 ms\n"
     ]
    }
   ],
   "source": [
    "# Convert to fp16\n",
    "!python3 llama.cpp/convert_hf_to_gguf.py sharshar20/lora-and-instruct-merged-model-v8 --remote \\\n",
    "  --outfile ./quantized_models/fp16-ft-lora.gguf \\\n",
    "  --outtype f16\n",
    "\n",
    "# Quantize the model for each method in the QUANTIZATION_METHODS list\n",
    "for method in QUANTIZATION_METHODS:\n",
    "    !./llama.cpp/build/bin/llama-quantize ./quantized_models/fp16-ft-lora.gguf ./quantized_models/ft-{method}-lora.gguf {method}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Qk0rLMVIYB3",
    "outputId": "af23e0d4-e46e-485c-eb61-0fbbddaec8b0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your prompt:  I have a degree in computer engineering and have skills in data analysis. What are the possible career pathways for me?\n",
      "Name of the model (options: fp16-ft.gguf, ft-q4_k_m.gguf, ft-q5_k_m.gguf):  fp16-ft.gguf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: no usable GPU found, --gpu-layers option will be ignored\n",
      "warning: one possible reason is that llama.cpp was compiled without GPU support\n",
      "warning: consult docs/build.md for compilation instructions\n",
      "build: 6713 (d2ee056e) with x86_64-conda-linux-gnu-cc (Anaconda gcc) 11.2.0 for x86_64-conda-linux-gnu\n",
      "main: llama backend init\n",
      "main: load the model and apply lora adapter, if any\n",
      "llama_model_loader: loaded meta data with 28 key-value pairs and 255 tensors from ./quantized_models/fp16-ft.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Merged_Model_Instruct_Lora\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 3.2B\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   5:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  14:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  17:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  25:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  26:               tokenizer.ggml.add_sep_token bool             = false\n",
      "llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type  f16:  197 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = F16\n",
      "print_info: file size   = 5.98 GiB (16.00 BPW) \n",
      "load: printing all EOG tokens:\n",
      "load:   - 128001 ('<|end_of_text|>')\n",
      "load:   - 128008 ('<|eom_id|>')\n",
      "load:   - 128009 ('<|eot_id|>')\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.7999 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 3072\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 24\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 3\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 3.21 B\n",
      "print_info: general.name     = Merged_Model_Instruct_Lora\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128009 '<|eot_id|>'\n",
      "print_info: EOT token        = 128009 '<|eot_id|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB\n",
      ".........................................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 4096\n",
      "llama_context: n_ctx_per_seq = 4096\n",
      "llama_context: n_batch       = 2048\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = auto\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 500000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (4096) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "\u001b[0mllama_context:        CPU  output buffer size =     0.49 MiB\n",
      "llama_kv_cache:        CPU KV buffer size =   448.00 MiB\n",
      "llama_kv_cache: size =  448.00 MiB (  4096 cells,  28 layers,  1/1 seqs), K (f16):  224.00 MiB, V (f16):  224.00 MiB\n",
      "llama_context: Flash Attention was auto, set to enabled\n",
      "llama_context:        CPU compute buffer size =   256.50 MiB\n",
      "llama_context: graph nodes  = 875\n",
      "llama_context: graph splits = 1\n",
      "common_init_from_params: added <|end_of_text|> logit bias = -inf\n",
      "common_init_from_params: added <|eom_id|> logit bias = -inf\n",
      "common_init_from_params: added <|eot_id|> logit bias = -inf\n",
      "common_init_from_params: setting dry_penalty_last_n to ctx_size = 4096\n",
      "common_init_from_params: warming up the model with an empty run - please wait ... (--no-warmup to disable)\n",
      "\u001b[0mmain: llama threadpool init, n_threads = 36\n",
      "main: chat template is available, enabling conversation mode (disable it with -no-cnv)\n",
      "*** User-specified prompt will pre-start conversation, did you mean to set --system-prompt (-sys) instead?\n",
      "\u001b[0mmain: chat template example:\n",
      "<|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hello<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Hi there<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "How are you?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "\n",
      "system_info: n_threads = 36 (n_threads_batch = 36) / 72 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | AVX512_VNNI = 1 | LLAMAFILE = 1 | REPACK = 1 | \n",
      "\n",
      "main: interactive mode on.\n",
      "sampler seed: 2698251615\n",
      "sampler params: \n",
      "\trepeat_last_n = 64, repeat_penalty = 1.000, frequency_penalty = 0.000, presence_penalty = 0.000\n",
      "\tdry_multiplier = 0.000, dry_base = 1.750, dry_allowed_length = 2, dry_penalty_last_n = 4096\n",
      "\ttop_k = 40, top_p = 0.950, min_p = 0.050, xtc_probability = 0.000, xtc_threshold = 0.100, typical_p = 1.000, top_n_sigma = -1.000, temp = 0.800\n",
      "\tmirostat = 0, mirostat_lr = 0.100, mirostat_ent = 5.000\n",
      "sampler chain: logits -> logit-bias -> penalties -> dry -> top-n-sigma -> top-k -> typical -> top-p -> min-p -> xtc -> temp-ext -> dist \n",
      "generate: n_ctx = 4096, n_batch = 2048, n_predict = 128, n_keep = 1\n",
      "\n",
      "== Running in interactive mode. ==\n",
      " - Press Ctrl+C to interject at any time.\n",
      " - Press Return to return control to the AI.\n",
      " - To return control without starting a new line, end your input with '/'.\n",
      " - If you want to submit another line, end your input with '\\'.\n",
      "\u001b[33m - Not using system message. To change it, set a different value via -sys PROMPT\n",
      "\n",
      "user\n",
      "\n",
      "I have a degree in computer engineering and have skills in data analysis\u001b[0m. What are the possible career pathways for me?assistant\n",
      "\n",
      "With a"
     ]
    }
   ],
   "source": [
    "model_list = [f for f in os.listdir(\"quantized_models\") if f.endswith(\".gguf\")]\n",
    "\n",
    "prompt = input(\"Enter your prompt: \")\n",
    "chosen_method = input(\"Name of the model (options: \" + \", \".join(model_list) + \"): \")\n",
    "\n",
    "# Verify the chosen method is in the list\n",
    "if chosen_method not in model_list:\n",
    "    print(\"Invalid name\")\n",
    "else:\n",
    "    command = f'./llama.cpp/build/bin/llama-cli -m ./quantized_models/{chosen_method} -n 128 --color -ngl 35 -p \"{prompt}\"'\n",
    "    !{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197,
     "referenced_widgets": [
      "e6450d08b424417882aafd2f5949a41e",
      "e339372b085c432598a97dfd00dcb662",
      "7ae0c882155c4f9d955559ef8b81d209",
      "b4710c592a9d4816a40e1932707f934a",
      "6b8bb3f6c0e747fab63d02da68677ee5",
      "68822745572944bebcbc787374e61425",
      "f1b4287abdec4f32bfc3c106a2720fdd",
      "3d2306ec989142fda86d124359d8e08e",
      "cd8b586bb0544c3fb90c3f9caf39ab01",
      "bbe6a9d638e34703b58012d1c0fe943f",
      "9ae48c1f2ef5408b9801d3d5dc973c06",
      "d41217326bbc4552878e955f31fed033",
      "10e8e5d0112649a6998e829ec7d16a45",
      "36c4f9b4c473493992ca608e6dad1fb2",
      "1290b76a455f4f349338946ee08041d6",
      "d3e8ca177ea94d3281e4baf365cd2078",
      "9653583d2d4e4f06b832eacd902ed78b",
      "81f608c8f5f946a6890d7ac38f0e5753",
      "73a1219c4d0343628c8e3a8446a14f3d",
      "10986a42d3fe4051bc6796b15b7cd423",
      "c10f1a3a1e9e45f399f31a7761bb9450",
      "a31204c7013a4576a02849434438ac7a",
      "2f4e16a1faa649c69574889550e2f5f8",
      "930fef61078540a5a5aae792e889d7ce",
      "846480380db347888c12f25010959867",
      "ff37f5ae2bec4e34981d12a9e40cb1f7",
      "7cb798c039d3491ea18f66d385583b93",
      "2a07ab49b8ba4ea589b8d2b4e3f00299",
      "6e29b86aea584507ab553dd1934c1893",
      "cbfc084fa5c44001b6c199647f0dbc21",
      "35a132df44364f5c9b0e67417708db52",
      "64f79a712cd84e5caaee582a2302ab26",
      "cf290aa1a7e041a4a8f83c2a7ffaa5ef",
      "ecff251e35b34c0fb57a1aecad825a0a",
      "0f8a62fd50574c038a40112963aa6cca",
      "63ad5d7b259a4e93b71de386c99f3721",
      "d27cb34a0b474fecbbea352f75142703",
      "3730040ac5bb44c69845296cea8944e2",
      "640524ea94aa436daabe9e843e6efb71",
      "1d1f9d9423d449a9833bff4c77042a76",
      "5c2874a67c1d4484b474a730c9132563",
      "f3d4eb4aa71349e29ab6fb1b7d2f7646",
      "9dc1ccc23f8847c1b6fbc47a9f485373",
      "183498c56b9b47a88be92bc1bacd0cca"
     ]
    },
    "id": "gWVOFdvBIal5",
    "outputId": "eee9d73b-8da6-4806-d419-5cbc0d88e767"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b3f005836d4a0bad267e26152a8185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c575ad7683e481cbc11eeac7df3fbb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/sharshar20/llama3.2_3B_instruct-GGUF-v7/commit/0e1758a8288f04794914b7504db3201258b6a2f9', commit_message='Upload folder using huggingface_hub', commit_description='', oid='0e1758a8288f04794914b7504db3201258b6a2f9', pr_url=None, repo_url=RepoUrl('https://huggingface.co/sharshar20/llama3.2_3B_instruct-GGUF-v7', endpoint='https://huggingface.co', repo_type='model', repo_id='sharshar20/llama3.2_3B_instruct-GGUF-v7'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install -q huggingface_hub\n",
    "from huggingface_hub import create_repo, HfApi\n",
    "\n",
    "api = HfApi(token=HF_TOKEN)\n",
    "\n",
    "# Upload gguf files\n",
    "api.upload_folder(\n",
    "    folder_path=\"quantized_models\",\n",
    "    repo_id=\"sharshar20/llama3.2_3B_instruct-GGUF-v7\",\n",
    "    allow_patterns=f\"*.gguf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fi_R1YyKMDwu"
   },
   "source": [
    "##### Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_text', 'target_text'],\n",
      "    num_rows: 454\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Get the test tokenized dataset\n",
    "from datasets import load_from_disk\n",
    "\n",
    "# Load the tokenized dataset from the specified directory\n",
    "test_dataset = load_from_disk(\"./dataset/split_combined_dataset_withoutjd/test\")\n",
    "print(test_dataset)\n",
    "\n",
    "small_test = test_dataset.shuffle(seed=42).select(range(50))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from llama_cpp import Llama\n",
    "from bert_score import BERTScorer\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def evaluate_llama_bertscore_withChatTemplate(\n",
    "    model_path,\n",
    "    dataset,\n",
    "    tokenizer,\n",
    "    max_tokens=128,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    repeat_penalty=1.1,\n",
    "    batch_size=32,\n",
    "    n_gpu_layers=-1,\n",
    "    n_threads=8,\n",
    "    scorer_model=\"bert-base-uncased\"\n",
    "):\n",
    "\n",
    "    # Load LLaMA model\n",
    "    model = Llama(\n",
    "        model_path=model_path,\n",
    "        n_ctx=1024,\n",
    "        n_gpu_layers=n_gpu_layers,\n",
    "        n_threads=n_threads,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    predictions, references = [], []\n",
    "    \n",
    "    for sample in tqdm(dataset, desc=\"Generating responses\", total=len(dataset)):\n",
    "        user_message = sample[\"input_text\"]\n",
    "        reference = sample[\"target_text\"]\n",
    "\n",
    "        # Apply the same chat template used during training\n",
    "        chat_prompt = tokenizer.apply_chat_template(\n",
    "            [{\"role\": \"user\", \"content\": user_message}],\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True  # tells model it's the assistant's turn\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            output = model(\n",
    "                chat_prompt,\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=temperature,\n",
    "                top_p=top_p,\n",
    "                repeat_penalty=repeat_penalty\n",
    "            )\n",
    "            pred = output[\"choices\"][0][\"text\"].strip()\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Generation error: {e}\")\n",
    "            pred = \"\"\n",
    "        \n",
    "        predictions.append(pred)\n",
    "        references.append(reference)\n",
    "\n",
    "    # --- Compute BERTScore ---\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    scorer = BERTScorer(model_type=scorer_model, device=device, batch_size=batch_size)\n",
    "    P, R, F1 = scorer.score(predictions, references)\n",
    "    \n",
    "    return {\n",
    "        \"predictions\": predictions,\n",
    "        \"references\": references,\n",
    "        \"precision\": P.mean().item(),\n",
    "        \"recall\": R.mean().item(),\n",
    "        \"f1\": F1.mean().item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from llama_cpp import Llama\n",
    "from bert_score import BERTScorer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_llama_bertscore(\n",
    "    model_path,\n",
    "    dataset,\n",
    "    max_tokens=128,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    repeat_penalty=1.1,\n",
    "    batch_size=32,\n",
    "    n_gpu_layers=-1,\n",
    "    n_threads=8,\n",
    "    scorer_model=\"bert-base-uncased\"\n",
    "):\n",
    "\n",
    "    model = Llama(\n",
    "        model_path=model_path,\n",
    "        n_ctx=1024,\n",
    "        n_gpu_layers=n_gpu_layers,\n",
    "        n_threads=n_threads,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    for sample in tqdm(dataset, desc=\"Generating responses\", total=len(dataset)):\n",
    "        prompt = sample[\"input_text\"]\n",
    "        reference = sample[\"target_text\"]\n",
    "        try:\n",
    "            output = model(\n",
    "                prompt,\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=temperature,\n",
    "                top_p=top_p,\n",
    "                repeat_penalty=repeat_penalty\n",
    "            )\n",
    "            pred = output[\"choices\"][0][\"text\"].strip()\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Generation error: {e}\")\n",
    "            pred = \"\"\n",
    "        predictions.append(pred)\n",
    "        references.append(reference)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    scorer = BERTScorer(model_type=scorer_model, device=device, batch_size=batch_size)\n",
    "    P, R, F1 = scorer.score(predictions, references)\n",
    "    \n",
    "    precision = P.mean().item()\n",
    "    recall = R.mean().item()\n",
    "    f1 = F1.mean().item()\n",
    "    \n",
    "    return {\n",
    "        \"predictions\": predictions,\n",
    "        \"references\": references,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp16-ft-base.gguf   ft-q4_k_m-lora.gguf  ft-qlora-q4_k_m.gguf\n",
      "fp16-ft-lora.gguf   ft-q5_k_m-lora.gguf\n",
      "fp16-ft-qlora.gguf  ft-q8_0-lora.gguf\n"
     ]
    }
   ],
   "source": [
    "!ls ./quantized_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (1024) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "Generating responses: 100%|██████████| 50/50 [54:59<00:00, 65.98s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e278c17ec844cf8d304470e62ba905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d339fdf43d405aa372869443f0dcbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01119a3fde446b2a1fbf1f58300b38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb70ac7fe2443c189a8924fe3c976a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a735ba9ea9b458284c67e8dbb81848c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [\"?\\n\\nThe possible positions for B.E. (Computers) are: Data Science Engineer with an experience requirement of At least 5 years. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, Spack, MongoDB and Python for data scraping and analysis. The related qualifications are Bachelor's Degree in Engineering. The experience requirements are At Least 1 year. The related skills are API Documentation, Client Code, Server Code, Integations, Test Cases, Repository Management, Task Assignment, Performance Monitoring, Skills Translation, User Protection, Data Integrity, System Security, Compliance, Data Backup, Infrastructure Design,\", '?\\nThe possible positions for Bachelor of Business Administration are: Mechanical Engineer with an experience requirement of 2 to 5 years. The related skills are Creating dashboards for sales and profits, Establishing key performance indicators (KPIs), Analyzing data to inform business decisions, Designing reports to help stakeholders make informed decisions, Reporting on sales and profit margins, Customer Engagement, Retail Sales, Store Operations, Inventory Management, Order Tracking, Shipments, Customer Service, Account Management, Field Services, Data Entry, payroll operations, inventory tracking, order management, ship notifications, customer interactions, field visits, data management, payment operations, inventory maintenance', \"?\\nEntry-level requirements typically include a high school diploma or equivalent, completion of an insurance claims adjusting course, and some level of experience in the insurance industry. Some employers may also require a background check or a valid driver's license for those who need to travel to job sites. A Certified Claims Adjuster (CCA) designation can be beneficial in demonstrating expertise and commitment to the field. While an associate's degree is not always required, it can provide an edge in securing employment and advancing in one's career. Some employers may also require a certain level of experience or completion of additional training courses. It is generally best to check the specific entry requirements\", 'What positions match my major in Computer Applications and Computer Applications and my skills in Data Analysis, Machine learning, Data Mining, Natural Language Processing, Linear Regression, Cluster Analysis, Correlation Analysis, Logistic Regression, Principal Component Analysis, Anova, Neural Networks, R, Python, MySQL, Tableau, Excel, SPSS and Decision tree?\\n\\n\\nThe position for Computer Applications and Computer Applications is: Head of Internal Control & Compliance (ICC) - SEVP/DMD. Key responsibilities include: 95+ Test Questions, 14 Days Rush Support, Best Practice Manual, Business Validation, Client Introduction, District Level Support, Executive Level Support,', '?\\n positions positions 1/5\\nThe possible positions for B.Tech are: Data Science Engineer with an experience requirement of At least 2 years. The related skills are Market Research and Data Analysis. The possible positions for Market Research are: Project Coordinator (Civil) with an experience requirement of 3 to 7 years. The related skills are Software Development, Application Programming, Designing Software, Developing Algorithms, Analyzing Data, Creating Database Models, Writing SQL Queries, Managing Teams, Selecting Hardware, Writing Code, Testing Products, Building Systems, Data Protection, Data Storage, System Security, Employee Management, Customer Service, Data Analysis', \"?\\nA Claims Adjuster typically works in an office setting, reviewing and processing claims files. However, they may also travel to clients' homes or business locations to conduct inspections or interviews. The work environment is often fast-paced and requires a high level of accuracy in handling sensitive information. Some companies may also offer flexible working arrangements, such as remote work or part-time schedules. Overall, the work environment is generally professional and supportive, with opportunities for advancement within the company. External factors like natural disasters, industrial accidents, or major economic shifts can impact claims volumes, making the job more demanding during those times.\\n\\nKey responsibilities include:\\n\\n* Reviewing and\", '?\\nCompanies that hire Business Intelligence Analysts include: Retail companies, Financial institutions, Healthcare organizations, Manufacturing firms, Consulting agencies, Technology companies, and large corporations in various sectors. The roles are typically found in the Information Technology (IT), Data Analytics, Marketing, Sales, Operations, and Finance departments. Some common industries for BI Analysts include: Retail, Manufacturing, Technology, Healthcare, Finance, E-commerce, and Non-profit organizations. The positions are usually entry-level to mid-level, with opportunities for advancement into roles like Senior BI Analyst, Business Analyst, or Data Science. Key companies that hire BI Analysts include Amazon, Google, Microsoft', '?\\nMany companies, especially those in the tech and manufacturing sectors, hire AI Software Engineers. Some notable examples include Google, Amazon, Microsoft, IBM, and startups working on AI-powered technologies like self-driving cars or medical diagnostics. Companies also hire AI Software Engineers to work on their machine learning teams within customer relationship management (CRM) platforms or digital marketing platforms. Healthcare companies, retail chains, and other businesses often require AI Software Engineers to develop specialized models for predictive analytics, quality control, or patient care optimization.\\n\\nWhat are the main responsibilities of an AI Software Engineer??\\nThe main responsibilities include designing, developing, testing, and deploying AI algorithms into', '?\\n position \"Head of Internal Control & Compliance (ICC) - SEVP & CMO\"\\nHence, the position \"Head of Internal Control & Compliance (ICC) - SEVP & CMO\" is related to N/A which falls under N/A in terms of industry and N/A in terms of company size. The position also involves N/A other important duties. The candidate should have a strong foundation in N/A and ability to learn N/A. The candidate\\'s skills should include N/A, N/A, N/A and N/A. The candidate should be proficient in N/A and experienced in using N/A. The position requires a', '?\\nA Social Media Analyst monitors and analyzes social media performance, tracking metrics such as engagement rates, follower growth, and content performance. They create reports to share with stakeholders, manage social media accounts, respond to comments or messages on social platforms, and assist in developing social media campaigns. The role requires a strong understanding of social media platforms, analytics tools, and content creation techniques. On a daily basis, the Analyst is engaged in data entry, report writing, task management, and collaboration with teams such as marketing and communications. They must also stay updated on social media trends and best practices to enhance performance. \\n\\nWhat are the main responsibilities of a', '30 Oct 2025\\n\\nA Software Engineer typically expects a collaborative and fast-paced work environment. The role often involves working in teams on projects, debugging code, testing software, and participating in continuous development. Many companies also encourage remote or hybrid work arrangements for flexibility.\\n\\nThe best answers are: Collaborative, Fast-paced, Remote/hybrid, Teams, Debugging, Testing, Continuous development, Innovation, Problem-solving, Communication. Read more to learn about Software Engineer roles! \\n\\nWhat is the average salary for a Junior Software Engineer? 30 Oct 2025\\n\\nThe average salary for a Junior Software Engineer typically ranges from $50,', '?\\nThe average salary for a Product Manager typically ranges from $80,000 to $120,000 annually, depending on factors such as location, experience level, and industry. Salaries may also vary based on specific job requirements or company size.\\n\\nHow do I progress in my career as a Product Manager????\\n\\nTo progress in your career, focus on developing skills such as product strategy, cross-functional collaboration, data analysis, and stakeholder management. Gaining experience in different industries and roles can also help you build a broad perspective. Pursuing certifications or advanced degrees in business, engineering, or computer science might be beneficial for career advancement.', '?\\nThe salary range for a Digital Marketing Manager (Junior level) typically falls between $45,000 and $60,000 annually. However, this can vary depending on factors such as the company size, location, experience, and industry. Some junior-level roles may pay less than $50,000, while others may pay more, especially in larger companies or industries with higher salaries. Experienced professionals may earn higher salaries, but these figures are still generally on the lower end of the marketing management salary spectrum. Salaries can vary based on location as well; cities like New York or San Francisco tend to have higher costs and therefore higher salaries.', \"The possible positions for B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X are: Civil Engineer with an experience requirement of At least 5 years. The related skills are NLP, Web Scraping, BS4, Selenium, Python, OCR, Pytesseract and Tesseract Object Detection. The related qualifications are Bachelor's degree. The possible positions for Bachelor's degree are: Data Science Engineer with an experience requirement of At least 3 years. The related skills are Python, React.js, Node.js, MongoDB, AWS and Git. The related qualifications are Bachelor's degree. The possible positions for Bachelor\", '?\\nEssential skills include strong attention to detail, the ability to reproduce bugs, expertise in testing tools such as Selenium and JUnit, proficiency in debugging, test case writing, and communication with developers. Strong analytical thinking is also crucial for identifying issues and diagnosing problems.\\n\\nThe best answer is: Strong attention to detail, the ability to reproduce bugs, expertise in testing tools, proficiency in debugging, test case writing, and communication with developers. Strong analytical thinking is also crucial.', '?\\nThe job description involves overseeing the operational aspects of a company, managing teams, coordinating projects, ensuring efficiency in processes, and maintaining high standards of performance. Key responsibilities include strategic planning, resource allocation, task management, team supervision, and process optimization.\\n\\nWhat skills are required to become an Operations Executive????\\n\\nSkills required include strong analytical abilities, problem-solving expertise, communication skills, project management experience, familiarity with operational software or systems, attention to detail, and the ability to adapt to changing business environments. Familiarity with industry standards or best practices in operations is also beneficial.\\n\\nHow do I progress in a career as an Operations Executive?', \"?\\n positions Position: Software Engineer with a experience requirement of At least 1 year. The related skills are Market Research and Data Analysis. The related qualifications are Bachelor's degree. The related technologies are Python, Data Structure, SQL, NodeJS, PyJS and R. The position requires Test Planning, Test Execution, Test Analysis, Test Design, Report Generation, Bug Tracking, Test Automation, Server Testing, Client Testing, Database Testing, Power Steering Testing, Microsoft Dynamics TP Testing, Integration Testing, System Testing, Test Collaboration, Test Management, Documentation, Leadership and Team Management. The position also requires Python, AWS for Server Monitoring, TensorFlow\", \"?\\n positions positions 1.  Data Scientist with an experience requirement of At least 3 years. The related skills are NLP, Web Scraping, bs4, OCR, Pytesseract and NERA License for recognizing handwritten texts in images. The related qualifications are Bachelor's degree. The related tools are Python, Keras, TensorFlow, OpenCV, Scikit Learn and Pytorch for building models. The related methods are Data Preparation, Model Training, Data Analysis, Hyperparameter Tuning, Model Evaluation, Data Retrieval, Prediction, Data Validation and Retirement Planning. The related companies are TCS, Infosys, Wipro\", '?\\nDaily tasks include conducting sustainability audits, analyzing data to understand environmental impact, collaborating with clients on sustainable practices, and providing advice on how to reduce carbon footprint. The role also involves staying updated on green technologies and best practices in sustainability. Additional responsibilities may include preparing sustainability reports, helping companies achieve certifications like LEED or ISO 14001, and conducting workshops or training sessions on sustainability topics. The tasks require strong analytical skills, attention to detail, communication expertise, and knowledge of environmental regulations and sustainability standards. A Sustainability Consultant must be proactive, flexible, and able to work closely with various stakeholders, including business leaders, architects, engineers, and', '?\\n\\nThe possible positions for Statistics are: Senior Software Engineer. Key responsibilities include: Collaboration & Partnership, Requirement Analysis, Software Design, Implementation Planning, System Development, Technical Support, Innovation Encourement, Workflow Optimization, Data Management, Application Development, Plug-in Creation, Task Assignment, Feedback Expression, Results Transmission, User Assistance, Version Control, Data Protection, Security & Data Integrity, Cross-Team Collaboration, High Impact Tasks, Role Clarification, Task Execution, Diversity & Inclusion, Problem-Solving, Team Dynamics, Performance Monitoring, Progress Reporting, External Communication, Internal Collaboration, Field Visits, Data Transfer, System Maintenance, Technical Support', \"?\\n positions positions 1/5\\nThe possible positions for Bachelor of Science are: Data Engineer with an experience requirement of At least 3 years. The related skills are Testing, Debugging and Parameter Tuning in Python for testing and debugging and Parameter tuning in SQL for optimizing tests. The related qualifications are Bachelor's degree. The possible positions for Bachelor's degree are: Civil Engineer with an experience requirement of At least 1 year. The related skills are Design Software, CAD Tools, BIM, Architecture, Structural Analysis, Engineering Calculations, Industry Standards, Paper Presentation, Conference Participation, Research Publication, Associate Professor role in Teaching Committee,\", \"The possible positions for B.E. (Computers) are: Sr. Offic (Hygiene - Cleaning Staff) in Indian Army with an experience requirement of 1 to 3 years. The related skills are NLP, ML and Data Analysis. The related qualifications are Bachelor's Degree. The job description involves Natural Language Processing, Machine Learning, Data Analysis, Predictive Modeling, Data Visualization, Text Classification, Object Detection, Image Editing, Statistical Analysis, Algorithm Design, Data Structures, SQL Query, Postgres Node Integration, Python Code Generation, Tesseract Object Recognition, Binary Data Handling, Client Server Communication, Data Translation, High\", \"?\\nEntry-level requirements typically include a degree in Marketing, Advertising, or a related field. Additional skills such as proficiency in media buying platforms (e.g., MediaOcean), Google Analytics, and Excel will be important for success in this role. Experience with paid advertising, online marketplaces, and data analysis can also help qualify candidates for entry-level roles. Certifications like the Google Ads Certification or HubSpot Inbound Marketing Certification are sometimes required to prove a candidate's knowledge of digital marketing platforms. Strong communication skills, attention to detail, and organizational abilities are also essential for success in this role. Salary expectations vary depending on location, company size,\", \"?\\nDaily tasks include writing clean code, debugging issues, optimizing website performance, collaborating with designers and front-end developers, ensuring responsiveness across different devices, managing database queries, and implementing new features. The role requires a strong understanding of front-end development tools like HTML, CSS, JavaScript, and back-end technologies such as Node.js and Django.\\n\\nBeing a good Web Developer involves staying updated on the latest web technologies, learning new programming languages, and continually optimizing website performance to ensure smooth user experiences. The role demands attention to detail, problem-solving skills, and the ability to work efficiently in a collaborative environment. A strong portfolio of projects showcases an individual's\", \"?\\nNo, a degree is not necessarily required to pursue a career as a Customer Relationship Manager. However, having a Bachelor's degree in Business Administration or a related field can be helpful. Relevant experience in customer service or sales roles and certifications like CRM or Salesforce will also enhance the chances of getting hired. Practical knowledge in using CRM tools, communication skills, and ability to build strong relationships are key qualifications for this role.\\nDo I need any special certifications or training to pursue a career as a Customer Relationship Manager??\\nYes, special certifications in customer relationship management (CRM) or sales force can be beneficial. Familiarity with CRM platforms like Salesforce\", '?\\nA Market Development Manager (Junior level) typically uses tools such as market research reports, customer feedback forms, sales and marketing analytics platforms, CRM software, Google Drive or Dropbox for collaboration, Excel for data analysis, and presentation tools like PowerPoint or Google Slides. They may also use online marketing platforms and social media analytics tools to measure the effectiveness of their campaigns. Additionally, they might utilize project management tools like Trello or Asana to manage projects and track progress. The specific tools used can vary depending on the company and industry. Key skills in this role include proficiency with CRM software, Excel, and presentation tools, as well as the', '?\\n\\nThe possible positions for Statistics and Data Analysis and Statistical Computation are: Senior Software Engineer. Key responsibilities include: Software Development, Implementation of Algorithms, Collaboration with Cross-Functional Teams, Software Testing, Maintenance of Code Base, and Research in Emerging Technologies. The possible skills for Senior Software Engineer are: C#, .NET, SQL, XML, XAML, Python, Java, HTML, CSS, Node.js, Test.NET, OpenQAissance and others. The possible positions for Data Analysis, Business Analysis, Statistical Analysis, Regression Analysis, Natural Language Processing, Machine Learning and Numerical Analysis are: Data Science Engineer. Key responsibilities include:', 'A Franchise Manager typically uses tools like franchise management software, CRM systems (Customer Relationship Management), accounting and payroll software, online training platforms, and communication apps to manage and support their franchises. They also use company-branded marketing materials and sales sheets. Additionally, they may use project management tools for supporting multiple store openings or renovations. The specific tools used can vary based on the franchise model, brand values, and operational requirements. \\n\\nWhy is it important to choose a franchise that aligns with your skills and interests? \\nChoosing a franchise that aligns with your skills and interests is crucial because it ensures you are working in an environment where', \"?\\nEntry-level requirements typically include a Bachelor's degree in Legal Studies, Paralegal Studies, or a related field. Gaining experience through internships or entry-level positions can also help build a strong foundation for a career as a Legal Assistant. Familiarity with legal software and technology is essential. Certifications like the Certified Legal Assistant (CLA) designation are often sought after to increase job prospects. A strong understanding of case law, evidence, and trial procedures is also important. Many employers prefer candidates with experience in legal research, document preparation, or court filing. The ability to work efficiently under deadlines and maintain confidentiality is a valuable skill for\", \"?\\nStart by learning programming languages such as C++, Python, and Java. Familiarize yourself with robotics platforms like ROS (Robot Operating System) and gain experience with robotic components like motors, sensors, and microcontrollers. Participate in robotics competitions or internships to build hands-on experience. A Bachelor's degree in Robotics, Mechanical Engineering, Electrical, or Computer Science is usually required. Consider pursuing a Master's for advanced research or specialized roles.\\n\\nHow do I progress in my career as a Robotics Engineer??? Progress can be made by advancing to senior engineer or project manager roles, gaining expertise in specific areas like machine learning, robotics hardware,\", \"?\\nTo become a Data Scientist, you typically need a Bachelor's degree in Computer Science, Statistics, Mathematics, or a related field. A Master's degree can also be beneficial for more advanced roles or specializations like machine learning or deep learning. Online courses and certifications in data science and analytics are also valuable additions to your skill set. Practical experience with programming languages such as Python, R, and SQL, along with familiarity with big data technologies like Hadoop and Spark, is essential. A strong understanding of statistical modeling, machine learning algorithms, and data visualization techniques will also be important for a Data Scientist role. A Data Scientist should have strong\", 'The possible positions for B.E. (Computers) are: Mechanical Engineer with an experience requirement of At least 1 year. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, OCR, Pytesseract and NER Text Classification. The related certifications are: Amazon Web Services (AWS) - Certified Developer. The related jobs are: Data Science Engineer. The related skills are Python, NumPy, SciKit Learn, Matplotlib, Pandas, Turkey IP Checker, Python 3.7 version number checker, PS-file reader, Python 3.7 to 3.12 upgrade', 'The position for N/A is: Senior Software Engineer. The position includes the following responsibilities: Design & Development, Prototyping, Collaboration, Innovation, Problem-Solving, Technical Support, Research, Development, Software Engineering, Documentation, System Analysis, Proposal Preparation, Field Visits, Laboratory Work, Data Translation, Decision Making, Team Collaboration, Innovation Pursuit, Problem Resolution, Technical Communication, R&D Report Preparation, Field Visit Coordination, Laboratory Test Management, Data Handling, Team Support, Innovation Translation, Problem Solving, System Analysis, Proposal Submission, Field Visit Coordination, Testing, Data Management, Team Participation, Research, Development,', '?\\n\\n positions. He/She will be responsible for managing the daily operations of the customer support team. The candidate should have a strong understanding of customer relationship management (CRM) tools and experience in leading a team to provide excellent customer service. Key responsibilities include: * Managing a team of Customer Support Representatives * Handling customer inquiries, issues, and feedback * Providing guidance on product features and usage * Ensuring timely resolution of customer support requests * Collaborating with other departments to resolve complex issues * Monitoring the performance of the customer support team * Identifying opportunities for process improvements in the support operations. The candidate should have a degree in BSc and MSc', \"?\\n\\nThe possible positions for B.E. (Computers) are: Project Coordinator (Civil) with an experience requirement of 5 to 10 years. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, OCR, Pytesseract and NER Text Classification. The related qualifications are Master's degree in Engineering. The experience requirement for Project Coordinator (Civil) is 5 to 10 years. The possible positions for Master's degree in Engineering are: Mechanical Engineer with an experience requirement of 2 to 5 years. The related skills are Data Analysis, EDA, Python Library (Pandas\", '?\\nThe main responsibilities include analyzing social media data to understand audience engagement, creating reports based on the analysis, suggesting improvements in content or strategy, assisting in managing online campaigns, and ensuring that all social media platforms are optimized for performance. The role involves staying updated with social media trends, helping with cross-channel marketing strategies, and contributing to team discussions about social media analytics. \\n\\nIs it difficult to become a Social Media Analyst??\\nIt can be challenging because you need to stay informed about the latest developments in digital marketing, analytics tools, and social media platforms. However, gaining experience through internships or entry-level roles in social media management, content', \"?\\nA Business Intelligence Analyst typically uses tools like Excel, Power BI, Tableau, SQL Server Analysis Manager (SAMS), Data Modeling Tools, and various data visualization platforms. They also use programming languages such as Python or R for advanced analysis tasks. Additionally, they may utilize cloud-based business intelligence services. The specific toolset can vary depending on the organization's technology stack and the nature of their work. \\n\\nDo you have any other questions about Business Intelligence Analysts????\\n\\nYes, here are a few more questions about Business Intelligence Analysts: What are the main responsibilities of a Business Intelligence Analyst? How do Business Intelligence Analysts contribute\", \"?\\nSkills required include: Cloud platform expertise (AWS, Azure, Google Cloud), virtualization knowledge (VMware, Hyper-V), experience with cloud architecture and design, strong communication skills, and the ability to troubleshoot complex issues. Familiarity with cloud security frameworks is also important. \\n\\nCloud Consultant typically requires a Bachelor's degree in Computer Science or Information Technology. Hands-on experience with cloud services, certifications like AWS Certified - Cloud Practitioner or Azure Expert, and continuous learning are essential for career advancement. \\n\\nThe field demands strong problem-solving skills, the ability to communicate complex ideas simply, and the capacity to adapt to changing technologies. In\", '?\\nEssential skills include customer service, sales management, inventory control, team leadership, conflict resolution, and the ability to adapt to changing retail environments. Communication, problem-solving, and organizational abilities are also crucial. Knowledge of point-of-sale systems, store operations, and employee performance analysis is important. Familiarity with labor laws and scheduling tools can be helpful in managing a team. A strong work ethic, attention to detail, and the ability to multitask are essential for success in this role. Effective communication and decision-making skills enable Retail Managers to lead teams, manage inventory, and resolve customer issues quickly and efficiently. Additionally, proficiency in retail', '?\\nThe daily tasks of an Advertising Manager (Junior level) include: Reviewing and analyzing ad performance, Assisting in planning new campaigns, Creating ad copy and media plans, Collaborating with designers to create visual materials, Coordinating ad placements on platforms like Google Ads or Facebook Ads, Working with the sales team to set target budgets for ads, Staying up-to-date on industry trends and advertising best practices, Helping with campaign tracking and reporting. Key responsibilities include: Campaign planning, Ad copy writing, Design coordination, Media buying, Performance analysis, Reporting, Collaboration, and Strategy development. Tasks are often repetitive but require a keen eye for', '?\\nThe average salary for a Policy Advisor is generally between $50,000 and $70,000 annually. However, salaries can vary depending on factors such as location, experience level, and the specific industry or organization. In some cases, higher-paying positions in large corporations or government agencies may command salaries above $80,000.\\n\\n## Step 1: Identify the role and its responsibilities\\nA Policy Advisor is responsible for providing analysis support to policy decisions by examining data sources, understanding organizational needs, and assisting in drafting recommendations based on research findings. This involves working closely with policymakers, stakeholders, and other analysts to ensure that policies are informed by', 'Cloud Database Engineers typically work for large cloud computing companies, such as Google Cloud Platform, Amazon Web Services (AWS), Microsoft Azure, or specialized cloud database services like MongoDB Atlas. They may also work in-house for organizations that have adopted cloud-based infrastructure solutions. The job market is highly competitive due to the rapid growth of cloud technology, so having a strong expertise in cloud computing and database management will help you succeed in this field.\\nWhat are the main responsibilities of a Cloud Database Engineer? Main responsibilities include designing and implementing scalable cloud databases, ensuring data security and availability, managing database performance under high loads, collaborating with development teams to integrate custom applications into', '?\\nDifficulties include dealing with large datasets, handling complex visualizations, ensuring that the visualization is accessible to non-technical users, and meeting tight deadlines while maintaining data integrity. Another challenge is finding the optimal balance between detail and abstraction in a visualization. Additionally, there can be difficulties in communicating effectively across different teams or departments. Data Visualization Specialists must also ensure that their creations are accurate representations of the underlying data, which can sometimes involve making difficult decisions about how to display certain information. Furthermore, there may be challenges in handling ambiguous or open-ended data, as well as dealing with incomplete or missing data. These difficulties require a combination of technical', 'Business Analysts typically work in industries such as finance, healthcare, manufacturing, retail, and technology. They may also work for consulting firms or in-house teams at large corporations.\\n\\nWhy are Business Analysts important? \\nBusiness Analysts are crucial because they help organizations identify areas of improvement, develop solutions to business problems, and ensure that projects align with strategic goals. By acting as a bridge between stakeholders and IT professionals, they facilitate the implementation of new systems and processes. Their ability to communicate effectively and analyze data makes them essential in driving business outcomes.\\n\\nWhat skills are required for a Business Analyst? \\nSkills required include strong analytical abilities, effective', '?\\nA typical day for a Legal Assistant might involve: Reviewing and researching legal documents, drafting correspondence or court filings, assisting lawyers with trial preparation, organizing case files, conducting background checks, preparing evidence packets, making travel arrangements, and helping with event planning. The work environment is typically office-based, although some tasks may require working remotely. Legal Assistants are usually employed by law firms or government agencies. The job can be challenging due to tight deadlines, complex legal issues, and the need for meticulous documentation. However, it also offers a sense of fulfillment in assisting lawyers with their cases and helping individuals navigate the legal system. Salary ranges vary', \"?\\n positions positions\\nConsultant -IT with an experience requirement of 5 to 10 years. The related skills are Software Development, Application Programming, System Analysis, Designing Software, Technical Support, Customer Relationship, Data Analysis, Insights and Decision Making. The related qualifications are Bachelor's Degree in Engineering. The related positions for Bachelor's Degree in Business Administration are: Executive/ Sr. Executive -IT with an experience requirement of 5 to 10 years. The related skills are Application Programming, System Analysis, Software Development, Technical Support, Data Analysis, Systems Design, Team Collaboration, Leadership and Decision Making. The related qualifications are Master's\", '?\\nPosition Title: Senior Software Engineer\\nWith a degree in Bachelor of Science, you can apply for positions such as Data Analyst, Business Intelligence Developer, Machine Learning Engineer, Research Assistant, Statistical Analyst, Operations Executive, Project Coordinator, HR Manager, Marketing Officer, Sales Representative, Customer Support, Field Services, Data Management, Application Development and System Management. The related skills are NLP, Web Scraping, bs4, Python Kickstart Program and Python Kickstart. The positions for Data Analyst are: Machine Learning Engineer. The position requirements are: At least 12 years of experience in the industry, with at least 5 years in a', '?\\nA typical day involves reviewing and analyzing existing automation scripts, identifying areas for improvement, testing new automated solutions, collaborating with other teams to integrate automations into processes, and ensuring that automated tasks are running smoothly. Automation Engineers also participate in on-call rotations where they resolve any issues related to automated systems. The role requires a good understanding of various automation tools and technologies. Many companies offer flexible schedules, allowing for remote work options if needed. The environment can be fast-paced, especially during peak project periods or when dealing with complex system integration challenges. Automation Engineers must stay updated on new tools and techniques in the industry to maintain productivity and solve problems effectively', '?\\nA typical day involves reviewing operational performance metrics, analyzing data on supply chain efficiency, inventory management, and customer service. The role also requires coordinating with cross-functional teams to resolve any operational issues or optimize processes. Meetings with stakeholders, such as logistics managers, IT specialists, and business analysts, are common in this field. Effective communication and problem-solving skills are essential for an Operations Executive to ensure that the organization runs smoothly and efficiently. Additionally, the ability to analyze data and implement changes based on insights is crucial for continuous improvement in operational performance. The role may involve working extended hours or being available on-call during critical operations periods. Overall, a', '?\\nThe job description for a Claims Adjuster includes reviewing claims, investigating losses, negotiating settlements, and ensuring that insurance companies pay out the correct amount to policyholders. The role involves communicating with clients, other claimants, and company employees to gather information about accidents or injuries. Adjusters must be diligent in tracking expenses, verifying facts, and making fair determinations of coverage and compensation. They work under pressure to meet deadlines, manage cases efficiently, and ensure compliance with company and insurance policies. Claims Adjuster roles are often entry-level, but they can progress to more senior positions like Senior Claims Adjuster or Manager. Key responsibilities include: Review'], 'references': ['The possible positions for B.E. (Computers) are: Mechanical Designer with an experience requirement of At least 5 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', \"The possible positions for Bachelor of Business Administration are: Site Engineer with an experience requirement of 1 to 2 years. The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router\", 'Entry-level requirements typically include a high school diploma, some college education or relevant certifications, and a state-issued license. Experience in customer service or insurance is a plus.', 'The possible positions for Computer Applications and Computer Applications are: Senior Software Engineer. Key responsibilities include: Technical Support, Troubleshooting, Collaboration, Documentation, System Monitoring, Software Deployment, Training & Mentorship, Industry Trends, Field Visits', 'The possible positions for B.Tech are: Asst. Manager/ Manger (Administrative) with an experience requirement of At least 5 years. The related skills are Testing, Debugging and Parameter Tuning', 'Claims Adjusters usually work in office environments but may also spend time in the field conducting investigations, meeting with claimants, or inspecting damaged properties. Some positions may offer remote work options.', 'Companies that rely heavily on data-driven decision-making, such as tech companies, financial institutions, retail businesses, and healthcare organizations, hire Business Intelligence Analysts.', 'Tech companies, AI startups, large corporations with AI needs, financial institutions, healthcare organizations, and research labs commonly hire AI Software Engineers.', 'The possible positions for B.Tech are: Data Engineer with an experience requirement of 5 to 8 years. The related skills are NLP and Data Analysis', 'On a daily basis, a Social Media Analyst monitors social media platforms, tracks key performance indicators (KPIs), compiles data into reports, engages with social media teams to optimize strategies, and analyzes trends to guide future campaigns.', 'Software Engineers often work in collaborative environments with other developers, product managers, and designers, with opportunities for remote or in-office work depending on the company.', 'The average salary for an entry-level Product Manager ranges from $60,000 to $90,000 per year, depending on experience and location.', 'The salary range for a Junior Digital Marketing Manager typically falls between $45,000 and $65,000 annually, with senior roles or positions in larger companies offering higher salaries.', 'The possible positions for B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X are: System Administrator (Operation & Maintenance of Server, Storage & Service Desk System) with an experience requirement of 4 to 5 years. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, OCR, Pytesseract and NER Text Classification', 'Essential skills include expertise in manual and automated testing, proficiency with testing tools (like Selenium, QTP, JUnit), understanding of bug-tracking systems, and strong analytical and debugging skills.', \"An Operations Executive is responsible for ensuring that the company's day-to-day activities run efficiently. They monitor operational performance, optimize processes, and assist in resource management and problem-solving.\", 'The possible positions for Bachelor of Engineering are: Sr.Officer / Executive - Internal Audit with an experience requirement of 2 to 4 years. The related skills are Software Development and Application Programming', 'The possible positions for BBA are: Business Development Executive with an experience requirement of 1 to 3 years. The related skills are Data Analysis and Business Analysis', 'Daily tasks include reviewing environmental impact data, assessing energy usage and waste management practices, meeting with clients to discuss sustainability goals, preparing reports, and developing recommendations for improving sustainability efforts.', 'The possible positions for Statistics are: Network Support Engineer. Key responsibilities include: Mikrotik Router Configuration, OLT Device Setup & Management, Integration with Billing Software, Network Monitoring Tools Integration, Connectivity Troubleshooting, Technical Support & Escalation, Installation & Configuration, GPON/EPON Expertise, Cisco, OLT, MikroTik Knowledge', 'The possible positions for Bachelor of Science are: Senior Software Engineer with an experience requirement of At least 1 year. The related skills are Creating dashboards for sales and profits', 'The possible positions for B.E. (Computers) are: DevOps Engineer with an experience requirement of At least 3 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'Entry-level requirements typically include a Bachelor’s degree in Marketing, Advertising, or Communications, along with an understanding of media buying and advertising principles. Internships or hands-on experience in digital marketing can also be helpful.', 'Daily tasks include coding, testing new features, troubleshooting bugs, attending team meetings, reviewing code, and ensuring that websites and web applications are performing well.', 'While a degree in Business, Marketing, or a related field is often preferred, experience in customer service or sales, along with hands-on experience with CRM tools, can also provide an entry point into this role.', 'Tools typically used include market research platforms like Nielsen, Google Analytics for website data, CRM software like Salesforce, and project management tools like Asana or Trello.', 'The possible positions for Statistics and Data Analysis and Statistical Computation are: Database Administrator (DBA). Key responsibilities include: Database Design & Development, SQL Query Optimization, Data Integrity & Security, BI Solutions Development, ETL Process Implementation, Database Maintenance, Backup & Restore Management, Index Rebuilding & Performance Tuning, SQL Server Clustering & High Availability, SQL Server Replication, High Availability Group Management, Database Monitoring & Troubleshooting', 'Franchise Managers typically use franchise management software, scheduling tools, POS systems, customer relationship management (CRM) systems, and business reporting tools like Excel or Google Sheets.', 'Entry-level requirements typically include a Bachelor’s degree or completion of a legal assistant certification program. Some positions may accept candidates with relevant experience or internships in the legal field.', 'To start, focus on obtaining a relevant degree (e.g., Robotics, Mechanical Engineering, Electrical Engineering) and gain hands-on experience with robotic systems, programming, and hardware design through internships or personal projects.', \"A bachelor's or master's degree in fields like Computer Science, Statistics, Mathematics, or Data Science is typically required.\", 'The possible positions for B.E. (Computers) are: Asst. Manager/ Manger (Administrative) with an experience requirement of At least 5 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'The possible positions for N/A are: Manager- Human Resource Management (HRM)\\n. Key responsibilities include: Recruitment Coordination, Appointment Management, Selection Criteria, Employee Orientation, Performance Evaluation, HR Database Management, Report Compilation, Documentation, Event Coordination, Task Execution', 'The possible positions for BSc and MSc are: Senior iOS Engineer with an experience requirement of At least 4 years. The related skills are NLP, ML and Amazon Comprehend Medical API', 'The possible positions for B.E. (Computers) are: Senior Software Engineer with an experience requirement of At least 1 year. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'The main responsibilities include analyzing social media data, tracking engagement metrics, developing reports, identifying trends and insights, monitoring online conversations, managing social media campaigns, and helping to optimize social media strategies.', 'Business Intelligence Analysts typically use BI tools like Power BI, Tableau, and QlikView for data visualization and reporting. They also use SQL-based tools for data querying and may use Excel for data manipulation.', 'Skills include a strong understanding of cloud platforms (AWS, Azure, Google Cloud), knowledge of cloud migration processes, familiarity with security practices, and problem-solving skills in the context of cloud infrastructure.', 'Essential skills include effective leadership, customer service, inventory management, staff training, sales strategies, and proficiency with point-of-sale (POS) systems.', 'Daily tasks include reviewing ad performance, working with the creative team on ad design, preparing reports, managing budgets for campaigns, and ensuring all ads are properly placed on the chosen platforms.', 'The average salary for a Policy Advisor typically ranges from $50,000 to $75,000 annually, depending on experience, location, and the specific employer.', 'Cloud Database Engineers work for tech companies, cloud service providers, consulting firms, and large enterprises that rely on cloud-based database solutions. Many work remotely or in hybrid environments.', 'Data Visualization Specialists often face challenges related to data quality, such as incomplete or messy data, and ensuring that visualizations are intuitive, meaningful, and aligned with business goals.', 'Business Analysts work in a variety of industries, including finance, healthcare, IT, manufacturing, and consulting. They can be employed in both large corporations and smaller companies.', 'A typical day involves preparing and filing legal documents, conducting legal research, organizing case files, assisting lawyers with trial preparation, and communicating with clients or witnesses. They may also attend meetings and hearings.', \"The possible positions for Bachelor of Business Administration are: Project Coordinator (Civil) with an experience requirement of 5 to 10 years. The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router\", 'The possible positions for Bachelor of Science are: Data Science Engineer with an experience requirement of At least 2 years. The related skills are Creating dashboards for sales and profits', 'A typical day involves designing automation processes, writing and testing scripts, debugging automation systems, collaborating with developers, and monitoring automated workflows to ensure they run efficiently.', 'A typical day includes overseeing operations, managing resources, tracking performance metrics, analyzing processes for efficiency, coordinating between departments, and handling any operational issues that arise.', 'A Claims Adjuster reviews and processes insurance claims by assessing the damages, interviewing claimants and witnesses, conducting investigations, and determining the payout based on the insurance policy terms and the extent of the loss.'], 'precision': 0.5921903252601624, 'recall': 0.7315841913223267, 'f1': 0.6527140140533447}\n"
     ]
    }
   ],
   "source": [
    "# fp16 model - lora and instruct merged model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "results = evaluate_llama_bertscore_withChatTemplate(model_path=\"./quantized_models/fp16-ft-lora.gguf\", dataset=small_test, tokenizer=tokenizer)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (1024) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "Generating responses:   0%|          | 0/50 [00:00<?, ?it/s]/home/FYP/shar0097/.local/lib/python3.12/site-packages/llama_cpp/llama.py:1242: RuntimeWarning: Detected duplicate leading \"<|begin_of_text|>\" in prompt, this will likely reduce response quality, consider removing it...\n",
      "  warnings.warn(\n",
      "Generating responses: 100%|██████████| 50/50 [17:00<00:00, 20.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': ['The possible positions for B.E. (Computers) are: Business Development Executive with an experience requirement of At least 1 year. The related skills are NLP, ML and Amazon Comprehend Medical API. The possible positions for NLP, ML and Amazon Comprehend Medical API are: Data Science Engineer with an experience requirement of At least 1 year. The related skills are NLP, ML and Amazon Comprehend Medical API. The possible positions for NLP, ML and Amazon Comprehend Medical API are: Mechanical Engineer with an experience requirement of At least 1 year. The related skills are NLP, ML', 'The possible positions for Bachelor of Business Administration are: Marketing Officer with an experience requirement of At least 1 year. The related skills are NLP, Machine learning and Amazon Comprehend Medical API. The interview process involves Screening, Zoom meeting, In-person interview and Candidate research. The average salary for this position is between $50,000 and $70,000.', \"Entry-level requirements typically include a high school diploma or equivalent, some experience in customer service or insurance sales, and often an associate's degree in business or a related field. Some employers may also require a claim adjusting certification program (CAP).\", 'The possible positions for Computer Applications and Computer Applications are: Executive - VAT. Key responsibilities include: Mushak Forms Maintenance, VAT Software & MS Office Maintenance, VAT Ledger Management, VAT Challan Coordination, Liaison with VAT Office, VAT Documentation, Other Assigned Tasks. The estimated salary range for this position is between Rs. 15,000 and Rs. 25,000.', 'The possible positions for B.Tech are: Sr.Officer / Executive - Internal Audit with an experience requirement of At least 5 years. The related skills are NLP and Data Analysis. The possible positions for NLP and Data Analysis are: Mechanical Engineer with an experience requirement of At least 5 years. The related skills are Software Development, Application Programming, Designing Software, Developing Documentation, Testing, User Validation, Server Management, Data Management, File Transmission, Client Management, Performance Monitoring, Data Analysis, Task Completion, Communication, Team Collaboration, Innovation, Problem-Solving, Software Development, Project Coordination, Innovation, Problem-S', 'Claims Adjusters generally work in an office setting, reviewing and processing claims files. They may also spend time out in the field to inspect damaged properties or interview claimants and witnesses. The job can be stressful during peak seasons, but most adjusters enjoy interacting with clients and helping them resolve their insurance issues. Some roles may require occasional travel for inspections or meetings.', 'Business Intelligence Analysts are typically hired by companies in the finance, retail, healthcare, technology, and consulting sectors. They work with large corporations, startups, and government agencies. The hiring process usually focuses on experience with data analysis tools, software skills, business acumen, and strong communication abilities. Key employers include financial services firms (e.g., banks), tech giants, insurance companies, pharmaceutical companies, consulting firms, and healthcare organizations. Other notable employers include retail chains, manufacturing companies, and large corporations in various sectors.', 'Companies in the tech industry, particularly those specializing in AI, machine learning, and data analytics, hire AI Software Engineers. Other industries such as healthcare, finance, and retail also employ them to work on AI-powered projects. Startups and research institutions are also significant employers of AI Software Engineers.', \"The possible positions for B.Tech are: Head of Internal Control & Compliance (ICC) - SEVP/DMD with an experience requirement of At least 15 years. The related skills are NLP, Machine learning and Amazon Comprehend Medical API. The related qualifications are Bachelor's degree in Electrical Engineering. The possible positions for Bachelor's degree are: Data Engineer with an experience requirement of At least 12 years. The related skills are Software Development, Application Programming, Designing Database Systems, System Analysis, Integration Planning, Troubleshooting, Documentation, and Team Collaboration. The related qualifications are Master's degree in Computer Science or Information Technology\", 'On a daily basis, a Social Media Analyst monitors social media platforms for trending topics and content opportunities. They analyze engagement metrics, create reports on performance data, respond to comments or messages, optimize posts and ads for better visibility, collaborate with marketing teams to develop new strategies, and track the performance of campaigns across various channels.', 'Software Engineers typically work in office environments, although some companies also offer remote or hybrid work options. They often collaborate with cross-functional teams, including product management, design, and QA. The environment is usually fast-paced, with an emphasis on solving complex software problems.', 'The average salary for a Product Manager is generally between $70,000 and $100,000 annually. However, this can vary based on factors such as experience level, company size, location, and industry. Senior-level or executive roles may earn higher salaries.', 'The salary range for a Digital Marketing Manager (Junior level) is generally between $50,000 and $65,000 annually, depending on experience, location, and the company size. Junior-level roles typically start at around $45,000 to $55,000 per year. Senior roles may earn more, with salaries up to $80,000 or higher.', \"The possible positions for B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X are: Senior Software Engineer with an experience requirement of At least 5 years. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, OCR, Pytesseract and NER Text Classification. The related qualifications are Bachelor's degree. The average salary for this position is ₹8 to ₹15 lakh per annum. The related technologies are Python, Keras, NLTK, scipy, pillow, tensorflow, openCV, mysql, postgreSql, redis, nodejs, angular and docker. The\", 'Essential skills include attention to detail, thoroughness in testing, strong analytical skills, the ability to understand software architecture and behavior, proficiency with automation tools such as Selenium or Appium, knowledge of test management frameworks like JIRA, and good communication skills. Experience with Agile development methodologies is highly valued.', 'The Operations Executive is responsible for overseeing the day-to-day operations of a company or department. They manage workflows, coordinate tasks, and ensure that all processes are running efficiently to meet business goals. This role involves managing inventory, supervising staff, optimizing resources, and maintaining compliance with operational standards. The Operations Executive also helps in implementing new systems and procedures to improve performance and productivity.', 'The possible positions for Bachelor of Engineering are: System Administrator (Operation & Maintenance of Server, Storage & Service Desk System) with an experience requirement of 3 to 5 years. The related skills are NLP and Data Analysis. The possible positions for NLP and Data Analysis are: Machine Learning Engineer with an experience requirement of 4 to 6 years. The related skills are Software Development and Application Programming. The possible positions for Software Development and Application Programming are: Mechanical Engineer with an experience requirement of 2 to 3 years. The related skills are Manufacturing Process, Quality Control, Troubleshooting, Cost Analysis, Budgeting, Material', 'The possible positions for BBA are: Full Stack Developer (Python,React js) with an experience requirement of At least 1 year. The related skills are NLP and Data Analysis. The possible positions for NLP are: Machine Learning (ML) Engineer with an experience requirement of At least 1 year. The related skills are Software Development and Application Programming. The possible positions for Software Development are: Data Science Engineer with an experience requirement of At least 1 year. The related skills are Mechanical, Electrical, Civil, Computer and Chemical with an experience requirement of At least 1 year. The possible positions for Mechanical, Electrical, Civil', 'Daily tasks include conducting environmental impact assessments, developing sustainability reports, collaborating with internal teams to implement sustainable practices, analyzing data on energy consumption or waste management, and providing recommendations for cost-effective sustainability improvements. They also engage in stakeholder communication and community outreach.', 'The possible positions for Statistics are: Network Support Engineer. Key responsibilities include: Mikrotik Router Configuration, OLT Device Setup & Management, Integration with Billing Software, Network Monitoring Tools Integration, Connectivity Troubleshooting, Technical Support & Escalation, Installation & Configuration, GPON/EPON Expertise, Cisco, OLT, MikroTik Knowledge, Network Optimization, Connectivity Expansion, Technical Documentation, System Administration, Field Installations & Troubilities, Backend Development (Python), Data Cleaning, Data Preparation, Data Analysis, Predictive Modeling, Data Analytics, Pivot Table, SQL, PostgreSQL, Analytics, Excel, Machine Learning and', 'The possible positions for Bachelor of Science are: Executive - VAT with an experience requirement of 5 to 10 years. The related skills are Market Research and Data Analysis. The possible positions for Market Research are: Senior Software Engineer with an experience requirement of 6 to 12 years. The related skills are Software Development, System Analysis, Requirements Gathering, File Management, Browser Notification API, Server-Sent Ocean Client (TOC) and Stream API. The possible positions for Senior Software Engineer are: Mechanical Engineer with an experience requirement of 5 to 10 years. The related skills are Designing Mechanical Components, Conducting Tests, Analyzing', 'The possible positions for B.E. (Computers) are: Senior Software Engineer with an experience requirement of At least 1 year. The related skills are Market Research and Data Analysis. The possible positions for Market Research are: Mechanical Engineer. The related skills are Civil, Structural, Mechanical, Electrical, Computer Aided Design (CAD), BIM, BPA, BDN, BCA, BCC, BSC, CBC, BDI, BDH, BA, LAN, WiFi, MS Office, Amazon Web Services (AWS), Server Monitoring, Datadog, Roster, Slack, TensorFlow, Python, C++,', 'Entry-level requirements typically include a degree in marketing, advertising, or a related field. Strong attention to detail and proficiency with media buying tools are also essential. Experience in internships or entry-level sales roles can help build relevant skills.', 'Daily tasks include coding, debugging code, maintaining websites and applications, optimizing performance, updating content, testing new features, and collaborating with designers or project managers.', 'While a degree is not strictly required, having one in Business Administration, Marketing, or Communications can be beneficial. Many people enter this role through experience in customer service or sales roles. Relevant certifications, such as CRM software training, are also important.', 'A Market Development Manager (Junior level) typically uses tools such as CRM systems like Salesforce, Excel for data analysis and budgeting, social media platforms for marketing campaigns, Google Analytics or SEMrush to track online presence, and market research reports to analyze trends. They may also use presentation software like PowerPoint or Google Slides to create presentations and sales materials.', 'The possible positions for Statistics and Data Analysis and Statistical Computation are: Full Stack Developer (Python,React js). Key responsibilities include: Full Stack Development, Front-end: ReactJS, NextJS, Back-end: Python, Django, API Design, Server-Side Logic, DRF (Django REST Framework), Database Management (PostgreSQL, MySQL), Version Control (Git), AWS (ECR, RDS, ALB, ECS, Terraform), Linux, Shell Scripting, System Monitoring, Bug Fixing, Feature Development, Code Review, Collaboration, Documentation, Server Management, Client Management, Task Assignment, Troubleshooting,', 'A Franchise Manager typically uses tools like franchise management software, CRM systems (e.g., Salesforce), accounting and inventory management software, online training platforms for employees, and customer relationship management apps. They may also use spreadsheets for data analysis.', \"Entry-level requirements typically include a high school diploma or equivalent, proficiency in Microsoft Office Suite (Word, Excel, PowerPoint), and some knowledge of legal terminology. Some employers may also require a paralegal certification or associate's degree.\", 'To start a career as a Robotics Engineer, focus on gaining strong foundation knowledge in computer science, electrical engineering, and robotics. Pursuing internships or entry-level roles at robotics companies can provide valuable hands-on experience. Additionally, earning advanced degrees such as Master’s or Ph.D. in Robotics Engineering can help build a robust skillset. Networking with professionals in the field is also crucial for gaining insights into emerging trends and advancements in robotics technology.', \"To become a Data Scientist, you typically need a Bachelor's degree in Computer Science, Statistics, Mathematics, or Engineering. A Master's degree or Ph.D. can also be beneficial for advanced roles or those focusing on specialized fields like machine learning. Additionally, proficiency in programming languages, data analysis tools, and experience with statistical modeling are essential. Certifications such as Certified Data Scientist (CDS) or Certified Analytics Professional (CAP) can demonstrate expertise. Practical experience through projects and internships is crucial to build a strong portfolio.\", \"The possible positions for B.E. (Computers) are: Mechanical Engineer with an experience requirement of At least 5 years. The related skills are NLP, ML and Amazon Comprehend Medical API. The related qualifications are Bachelor's degree in B.E. (Computers). The related tools are Python, Keras and TensorFlow. The possible positions for NLP, ML and Amazon Comprehend Medical API are: Data Engineer with an experience requirement of At least 5 years. The related skills are Software Design, Troubleshooting, Repair, Maintenance, Customer Support, Supervision, Guidance, Operations, Sales, Executive, Management\", 'The possible positions for N/A are: System Administrator (Operation & Maintenance of Server, Storage & Service Desk System). Key responsibilities include: Hardware & Network Installation, Troubleshooting & Diagnostics, User Training & Capacity Building, Hardware Replacement, Fault Repair & System Setup, Software License & Account Management, Backup Management, System Updates & Maintenance, Server & Storage Management, Documentation & Technical Specifications, Data Protection & Disaster Recovery, Storage & Database Planning, Power & Disk Backup, Incident Management & Escalation, Service Restoration, User Communication & Collaboration, Incident Classification & Resolution, Major Incident Escalation, Problem & Error Management, Task Assignment &', \"The possible positions for BSc and MSc are: Head of Internal Control & Compliance (ICC) - SEVP/DMD with an experience requirement of At least 15 years. The related skills are NLP, ML and Amazon Comprehend Medical API. The related qualifications are Bachelor's degree in BSc and MSc. The related technologies are Python, AWS and NodeJS. The related careers are Mechanical Engineer. The related qualifications are High School Diploma or Equivalent. The related skills are Data Analysis, Business Analysis, Predictive Modeling, Data Mining, CRM Integration, Tableau, Excel, SQL and AWS Services. The related technologies are\", 'The possible positions for B.E. (Computers) are: Network Support Engineer with an experience requirement of At least 5 years. The related skills are Software Development and Application Programming. The possible positions for Software Development are: Senior Software Engineer with an experience requirement of At least 3 years. The related skills are Mechanical, Electrical, Civil, Instrumenation, Engineering Software, FEA, FINCT, MSC.AD, MSC.SLDP, SLP, INTEL PROCTOR, MAYA ERATOR, BOM TOOL, ENGINEING SOFTWARE, LCF, RCC, BCC, PC, LA-TEST, MS', 'The main responsibilities include analyzing social media data to understand trends and audience behavior, tracking engagement metrics, creating reports on performance, suggesting strategies to improve engagement rates, managing social media campaigns, and ensuring consistency across all platforms.', 'A Business Intelligence Analyst typically uses tools like Excel, SQL, Tableau, Power BI, and other data visualization and reporting software. They may also use ETL (Extract, Transform, Load) tools for data integration. Other tools include data modeling and analysis software, such as R or Python. Cloud-based platforms like Amazon QuickView or Google Data Studio are also used for data visualization.', 'Skills required include knowledge of cloud platforms (AWS, Azure, GCP), experience with cloud architecture and design, understanding of security principles, expertise in migration strategies, familiarity with monitoring tools, and strong communication skills to explain complex concepts. Cloud certifications like AWS Certified Cloud Practitioner or Microsoft Certified Azure Developer are valuable.', 'Essential skills include excellent customer service, effective inventory management, strong leadership and communication abilities, the ability to multitask in a fast-paced environment, attention to detail, and proficiency in retail software and systems. A Retail Manager should also be able to coach employees, handle conflicts, and maintain store operations efficiently.', 'Daily tasks include reviewing campaign performance, creating ad content and copy, analyzing data to optimize ads, collaborating with designers for visual elements, and ensuring that all advertising efforts align with business objectives. The manager also handles reporting, scheduling, and budget management.', 'The average salary for a Policy Advisor typically ranges from $50,000 to $75,000 annually, depending on factors such as location, experience level, and the organization. Senior-level or specialized roles may command higher salaries.', 'Cloud Database Engineers typically work at large tech companies, consulting firms, or as employees of cloud services providers such as Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform (GCP), and Oracle. They may also work for in-house database teams at organizations that use cloud-based databases.', 'Difficulties include dealing with complex, messy data, ensuring that visualizations are clear and concise, handling large datasets in real-time, and meeting the needs of various stakeholders. Additionally, finding creative ways to communicate insights and trends can be challenging.', 'Business Analysts typically work in corporate environments, such as consulting firms, large corporations, and government agencies. They may also work for IT companies or software development firms that provide business analysis services. Some Business Analysts may choose to start their own consulting practices or freelance as a Business Analyst.', 'A typical day involves researching case laws, drafting documents, preparing court filings, assisting attorneys with trial preparation, reviewing contracts and agreements, managing client records, and communicating with clients or other legal professionals. The role also requires attention to detail and proficiency in using legal software and technology.', 'The possible positions for Bachelor of Business Administration are: Executive/ Sr. Executive -IT with an experience requirement of At least 1 year. The related skills are Market Research and Data Analysis. The possible positions for Market Research are: Software Engineer. The related skills are NLP, ML and Amazon Comprehend Medical API for medical insights, Amazon Comprehend Text API for text analysis, Amazon Tesseract OCR API for image recognition, Amazon Tye GraphQL API for building services, AWS Lambda for serverless architecture, Docker for containerization, AWS EC2 for scalable infrastructure, RStudio for data science, AWS RDS for relational databases,', 'The possible positions for Bachelor of Science are: Executive/ Senior Executive- Trade Marketing, Hygiene Products with an experience requirement of At least 3 years. The related skills are NLP and Machine learning. The possible positions for NLP and Machine learning are: Full Stack Developer (Python,React js) with an experience requirement of At least 3 years. The related skills are Software Development and Application Programming in languages like Python, Java or C#. The possible position for Software Development is: Mechanical Engineer with an experience requirement of At least 4 years. The related skills are Civil Engineering and Building Construction. The possible positions for Civil Engineering are', 'A typical day involves reviewing code, analyzing logs to identify issues, automating tasks in production environments, fixing bugs, and collaborating with developers or QA teams. Automation Engineers also work on improving the efficiency of automated processes.', 'A typical day involves monitoring production processes, tracking inventory levels, handling operational issues, coordinating with teams to resolve problems, ensuring that production targets are met, and communicating with stakeholders about production schedules. The role also requires data analysis and reporting on operational performance.', \"A Claims Adjuster is responsible for evaluating claims, assessing damages or losses, negotiating settlements with policyholders and other parties involved, preparing reports, and ensuring that the insurance company's interests are protected. They must be skilled in communication, negotiation, and analytical thinking to ensure fair outcomes for both the insurance company and its clients.\"], 'references': ['The possible positions for B.E. (Computers) are: Mechanical Designer with an experience requirement of At least 5 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', \"The possible positions for Bachelor of Business Administration are: Site Engineer with an experience requirement of 1 to 2 years. The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router\", 'Entry-level requirements typically include a high school diploma, some college education or relevant certifications, and a state-issued license. Experience in customer service or insurance is a plus.', 'The possible positions for Computer Applications and Computer Applications are: Senior Software Engineer. Key responsibilities include: Technical Support, Troubleshooting, Collaboration, Documentation, System Monitoring, Software Deployment, Training & Mentorship, Industry Trends, Field Visits', 'The possible positions for B.Tech are: Asst. Manager/ Manger (Administrative) with an experience requirement of At least 5 years. The related skills are Testing, Debugging and Parameter Tuning', 'Claims Adjusters usually work in office environments but may also spend time in the field conducting investigations, meeting with claimants, or inspecting damaged properties. Some positions may offer remote work options.', 'Companies that rely heavily on data-driven decision-making, such as tech companies, financial institutions, retail businesses, and healthcare organizations, hire Business Intelligence Analysts.', 'Tech companies, AI startups, large corporations with AI needs, financial institutions, healthcare organizations, and research labs commonly hire AI Software Engineers.', 'The possible positions for B.Tech are: Data Engineer with an experience requirement of 5 to 8 years. The related skills are NLP and Data Analysis', 'On a daily basis, a Social Media Analyst monitors social media platforms, tracks key performance indicators (KPIs), compiles data into reports, engages with social media teams to optimize strategies, and analyzes trends to guide future campaigns.', 'Software Engineers often work in collaborative environments with other developers, product managers, and designers, with opportunities for remote or in-office work depending on the company.', 'The average salary for an entry-level Product Manager ranges from $60,000 to $90,000 per year, depending on experience and location.', 'The salary range for a Junior Digital Marketing Manager typically falls between $45,000 and $65,000 annually, with senior roles or positions in larger companies offering higher salaries.', 'The possible positions for B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X are: System Administrator (Operation & Maintenance of Server, Storage & Service Desk System) with an experience requirement of 4 to 5 years. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, OCR, Pytesseract and NER Text Classification', 'Essential skills include expertise in manual and automated testing, proficiency with testing tools (like Selenium, QTP, JUnit), understanding of bug-tracking systems, and strong analytical and debugging skills.', \"An Operations Executive is responsible for ensuring that the company's day-to-day activities run efficiently. They monitor operational performance, optimize processes, and assist in resource management and problem-solving.\", 'The possible positions for Bachelor of Engineering are: Sr.Officer / Executive - Internal Audit with an experience requirement of 2 to 4 years. The related skills are Software Development and Application Programming', 'The possible positions for BBA are: Business Development Executive with an experience requirement of 1 to 3 years. The related skills are Data Analysis and Business Analysis', 'Daily tasks include reviewing environmental impact data, assessing energy usage and waste management practices, meeting with clients to discuss sustainability goals, preparing reports, and developing recommendations for improving sustainability efforts.', 'The possible positions for Statistics are: Network Support Engineer. Key responsibilities include: Mikrotik Router Configuration, OLT Device Setup & Management, Integration with Billing Software, Network Monitoring Tools Integration, Connectivity Troubleshooting, Technical Support & Escalation, Installation & Configuration, GPON/EPON Expertise, Cisco, OLT, MikroTik Knowledge', 'The possible positions for Bachelor of Science are: Senior Software Engineer with an experience requirement of At least 1 year. The related skills are Creating dashboards for sales and profits', 'The possible positions for B.E. (Computers) are: DevOps Engineer with an experience requirement of At least 3 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'Entry-level requirements typically include a Bachelor’s degree in Marketing, Advertising, or Communications, along with an understanding of media buying and advertising principles. Internships or hands-on experience in digital marketing can also be helpful.', 'Daily tasks include coding, testing new features, troubleshooting bugs, attending team meetings, reviewing code, and ensuring that websites and web applications are performing well.', 'While a degree in Business, Marketing, or a related field is often preferred, experience in customer service or sales, along with hands-on experience with CRM tools, can also provide an entry point into this role.', 'Tools typically used include market research platforms like Nielsen, Google Analytics for website data, CRM software like Salesforce, and project management tools like Asana or Trello.', 'The possible positions for Statistics and Data Analysis and Statistical Computation are: Database Administrator (DBA). Key responsibilities include: Database Design & Development, SQL Query Optimization, Data Integrity & Security, BI Solutions Development, ETL Process Implementation, Database Maintenance, Backup & Restore Management, Index Rebuilding & Performance Tuning, SQL Server Clustering & High Availability, SQL Server Replication, High Availability Group Management, Database Monitoring & Troubleshooting', 'Franchise Managers typically use franchise management software, scheduling tools, POS systems, customer relationship management (CRM) systems, and business reporting tools like Excel or Google Sheets.', 'Entry-level requirements typically include a Bachelor’s degree or completion of a legal assistant certification program. Some positions may accept candidates with relevant experience or internships in the legal field.', 'To start, focus on obtaining a relevant degree (e.g., Robotics, Mechanical Engineering, Electrical Engineering) and gain hands-on experience with robotic systems, programming, and hardware design through internships or personal projects.', \"A bachelor's or master's degree in fields like Computer Science, Statistics, Mathematics, or Data Science is typically required.\", 'The possible positions for B.E. (Computers) are: Asst. Manager/ Manger (Administrative) with an experience requirement of At least 5 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'The possible positions for N/A are: Manager- Human Resource Management (HRM)\\n. Key responsibilities include: Recruitment Coordination, Appointment Management, Selection Criteria, Employee Orientation, Performance Evaluation, HR Database Management, Report Compilation, Documentation, Event Coordination, Task Execution', 'The possible positions for BSc and MSc are: Senior iOS Engineer with an experience requirement of At least 4 years. The related skills are NLP, ML and Amazon Comprehend Medical API', 'The possible positions for B.E. (Computers) are: Senior Software Engineer with an experience requirement of At least 1 year. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'The main responsibilities include analyzing social media data, tracking engagement metrics, developing reports, identifying trends and insights, monitoring online conversations, managing social media campaigns, and helping to optimize social media strategies.', 'Business Intelligence Analysts typically use BI tools like Power BI, Tableau, and QlikView for data visualization and reporting. They also use SQL-based tools for data querying and may use Excel for data manipulation.', 'Skills include a strong understanding of cloud platforms (AWS, Azure, Google Cloud), knowledge of cloud migration processes, familiarity with security practices, and problem-solving skills in the context of cloud infrastructure.', 'Essential skills include effective leadership, customer service, inventory management, staff training, sales strategies, and proficiency with point-of-sale (POS) systems.', 'Daily tasks include reviewing ad performance, working with the creative team on ad design, preparing reports, managing budgets for campaigns, and ensuring all ads are properly placed on the chosen platforms.', 'The average salary for a Policy Advisor typically ranges from $50,000 to $75,000 annually, depending on experience, location, and the specific employer.', 'Cloud Database Engineers work for tech companies, cloud service providers, consulting firms, and large enterprises that rely on cloud-based database solutions. Many work remotely or in hybrid environments.', 'Data Visualization Specialists often face challenges related to data quality, such as incomplete or messy data, and ensuring that visualizations are intuitive, meaningful, and aligned with business goals.', 'Business Analysts work in a variety of industries, including finance, healthcare, IT, manufacturing, and consulting. They can be employed in both large corporations and smaller companies.', 'A typical day involves preparing and filing legal documents, conducting legal research, organizing case files, assisting lawyers with trial preparation, and communicating with clients or witnesses. They may also attend meetings and hearings.', \"The possible positions for Bachelor of Business Administration are: Project Coordinator (Civil) with an experience requirement of 5 to 10 years. The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router\", 'The possible positions for Bachelor of Science are: Data Science Engineer with an experience requirement of At least 2 years. The related skills are Creating dashboards for sales and profits', 'A typical day involves designing automation processes, writing and testing scripts, debugging automation systems, collaborating with developers, and monitoring automated workflows to ensure they run efficiently.', 'A typical day includes overseeing operations, managing resources, tracking performance metrics, analyzing processes for efficiency, coordinating between departments, and handling any operational issues that arise.', 'A Claims Adjuster reviews and processes insurance claims by assessing the damages, interviewing claimants and witnesses, conducting investigations, and determining the payout based on the insurance policy terms and the extent of the loss.'], 'precision': 0.6858484745025635, 'recall': 0.7718873620033264, 'f1': 0.725498378276825}\n"
     ]
    }
   ],
   "source": [
    "# LoRA Q4_K_M gguf model bertscore\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "results = evaluate_llama_bertscore_withChatTemplate(model_path=\"./quantized_models/ft-q4_k_m-lora.gguf\", dataset=small_test, tokenizer=tokenizer)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (1024) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "Generating responses:   0%|          | 0/50 [00:00<?, ?it/s]/home/FYP/shar0097/.local/lib/python3.12/site-packages/llama_cpp/llama.py:1242: RuntimeWarning: Detected duplicate leading \"<|begin_of_text|>\" in prompt, this will likely reduce response quality, consider removing it...\n",
      "  warnings.warn(\n",
      "Generating responses: 100%|██████████| 50/50 [21:17<00:00, 25.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': ['The possible positions for B.E. (Computers) are: Marketing Officer with an experience requirement of At least 1 year. The related skills are Testing, Debugging and Parameter Tuning, Automation, API Integration, LDA Modeling, Data Cleaning, Data Transformation, Predictive Analysis, Machine Learning, Statistical Analysis, Risk Assessment, Decision Support, Operational Excellence, System Administration, Server Management, Data Security, Access Control, Mail Server Management, Linux Operating System, Network Architecture, Disaster Recovery, Backup & Restore, Infrastructure Design, Team Collaboration, Customer Communication, Customer Engagement, User Support, Application Development, Troubleshooting, Field Service,', 'The possible positions for Bachelor of Business Administration are: Marketing Officer with an experience requirement of 1 to 3 years. The related skills are NLP, ML and Amazon Comprehend Medical API. The related qualifications are Degree in Engineering. The industry for this position is Manufacturing. The average salary range for Marketing Officer is Rs. 15 lakhs to Rs. 30 lakhs.', 'Entry-level requirements typically include a high school diploma, some college or vocational training in insurance or claims handling, and strong communication skills. A background check is often required for the position.', 'The possible positions for Computer Applications and Computer Applications are: Senior iOS Engineer. Key responsibilities include: Technical Leadership, iOS Architecture, API Design, iOS Implementation, Technical Documentation, Collaboration, and Troubleshooting. The required skills are Python, AWS, RDS, EC2, IAM, Security, Netflix Architecture, Lambda Functions, API Gateway, DynamoDB, TypeScript, NodeJS and Amazon Web Services (AWS). The related major is Electrical Engineering and the related skills are Data Analysis, Machine Learning, Data Mining, Natural Language Processing, Linear Regression, Cluster Analysis, Correlation Analysis, Logistic Regression, Principal Component Analysis, Anova, Neural Networks', 'The possible positions for B.Tech are: Data Engineer with an experience requirement of At least 5 years. The related skills are NLP and Data Analysis. The possible positions for NLP are: Machine Learning (ML) Engineer with an experience requirement of At least 4 years. The related skills are C, C++, JAVA, Python and system programming. The possible positions for C, C++, JAVA, Python and system programming are: System Administrator (Operation & Maintenance of Server, Storage & Service Desk System) with an experience requirement of At least 3 years. The related skills are Data Analysis, Business Analysis, Predictive Modeling,', 'A Claims Adjuster can expect to work in an office setting, often in a team environment. They may also conduct on-site visits or investigations at the claims locations. The job requires strong communication and organizational skills, as well as attention to detail and problem-solving abilities. Adjusters typically work regular business hours but may be required to respond to urgent claims outside of those hours.', 'Business Intelligence Analysts are commonly hired by companies in the finance, retail, healthcare, technology, and consulting industries. They also work with organizations that rely heavily on data analysis to make business decisions. Examples include software companies, financial institutions, management consulting firms, e-commerce businesses, and large enterprises.', 'Companies in the tech industry, particularly those involved in AI research and development, software companies, consulting firms, healthcare organizations, finance institutions, and automotive companies often hire AI Software Engineers. Additionally, companies like Google, Amazon, Microsoft, Facebook, and startups in AI-focused industries also employ AI Software Engineers.', 'The possible positions for B.Tech are: Manager- Human Resource Management (HRM)\\n with an experience requirement of 5 to 6 years. The related skills are Data Analysis and Business Analysis. The possible positions for Data Analysis are: Senior Software Engineer. The experience requirement is 4 to 5 years. The related skills are Software Development, Application Programming, System Analysis, Design, Development, Test, Client Management, Collaboration, Communication, Problem Solving, Innovation, Task Execution, Research, Development, Technical Support, Documentation, Industry Trends, Field Visits, Data Management, Team Collaboration, Performance Monitoring, Report Preparation, Innovation,', 'On a daily basis, a Social Media Analyst monitors and analyzes social media platforms for engagement metrics (likes, comments, shares), tracks brand mentions, reviews content performance, optimizes posts for better visibility, helps create engaging content strategies, assists in managing online reputation, and reports on key metrics to stakeholders. They also perform tasks like posting updates, responding to comments, and collaborating with other teams to integrate social media goals into overall business objectives.', 'Software Engineers typically work in office environments, although some roles may be remote or hybrid. The environment is often collaborative and fast-paced, with a focus on solving complex technical problems. Most companies have open-plan offices where teams can interact easily. However, some jobs might require more focused individual work or travel for conferences or meetings.', 'The average salary for a Product Manager is between $80,000 and $120,000 annually. However, salaries can vary depending on factors such as experience, location, company size, and industry. Senior-level or executive roles may command higher salaries.', 'The salary range for a Digital Marketing Manager (Junior level) is generally between $50,000 and $65,000 annually, depending on experience, location, and company size. Senior-level positions may earn more.', 'The possible positions for B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X are: Mechanical Designer with an experience requirement of At least 5 years. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, OCR, Pytesseract and NER Text Classification. The related qualifications are MSc (Any Discipline) and BSc (Any Discipline). The job description includes Maintaining the inventory of raw materials, Supervising the store staff, Receiving and storing goods, Managing cash transactions, Supervising other engineers, Maintaining equipment, Ensuring work safety, Providing technical support', 'Essential skills include attention to detail, understanding of software development methodologies, experience with testing frameworks (e.g., Selenium), proficiency in using tools like JUnit or PyUnit for unit testing, and strong analytical and problem-solving abilities. Communication and collaboration are also important traits.', 'The job description involves overseeing daily operations, managing resources, ensuring smooth workflow execution, maintaining inventory levels, supervising staff members, and optimizing business processes. The role also includes coordinating with other departments like HR, finance, and marketing to ensure a cohesive work environment. Additionally, the Operations Executive is responsible for monitoring performance metrics, identifying areas of improvement, and implementing strategies to enhance operational efficiency.', 'The possible positions for Bachelor of Engineering are: Civil Engineer with an experience requirement of 3 to 5 years. The related skills are Market Research and Data Analysis. The possible positions for Market Research and Data Analysis are: Business Development Executive with an experience requirement of 2 to 4 years. The related skills are Software Development, Application Programming, System Analysis, Designing & Development of Software, Team Collaboration, Technical Support, Software Licensing, Development Services, Operation & Maintenance, Client Management, Innovation, Problem-Solving, Task Completion, Communication, Data Driven Decision Making, Translation, Interpretation and Customer Engagement. The possible positions for Software', 'The possible positions for BBA are: Site Engineer with an experience requirement of At least 5 years. The related skills are Software Development and Application Programming. The related qualifications are Bachelor of Business Administration. The job description includes Designing Software Features, Implementing Software Solutions, Collaborating with Cross-Functional Teams, Developing Documentation and Code, Troubleshooting Software Issues, Managing Software Development Lifecycle, Developing APIs, Integrations, and Systems, Leading Software Development Teams, Participating in Code Reviews, and Identifying Technical Debt. The average salary for this position is between Rs. 15 lakhs and Rs. 30 lakhs.', 'Daily tasks include conducting environmental impact assessments, reviewing company sustainability reports, collaborating with stakeholders on sustainable practices, providing recommendations for reducing waste and energy consumption, and helping to develop strategies for sustainable supply chain management.', 'The possible positions for Statistics are: Manager- Human Resource Management (HRM)\\n. Key responsibilities include: Recruitment Coordination, Appointment Management, Selection Criteria, Employee Orientation, Performance Evaluation, HR Database Management, Report Compilation, Documentation, Event Coordination, Task Execution, Communication, Team Collaboration, Compliance, Task Management, Strategy Development, Innovation Encouragement, Team Support, Quality Assurance, Research Assistance, Task Completion, Data Analysis, Report Generation, Innovation Promotion, Team Collaboration, Compliance, Task Management, Strategy Development, Enforcement, Innovation Encouragement, Single-User License for Microsoft Office 365 (Business Grande) $59.99 AUD', \"The possible positions for Bachelor of Science are: Data Engineer with an experience requirement of At least 5 years. The related skills are Testing, Debugging and Parameter Tuning in Python and SciKit Learn. The related qualifications are Master's degree in Engineering. The candidate should have a strong foundation in mechanical principles and proficiency in CAD software. The position requires at least 3 to 4 years of experience in Mechanical Design or a related field. The related skills are Data Analysis, Business Intelligence, Power BI, SQL, Tableau, Excel, Machine Learning and Data Modeling. The position requires an MBA or Master's degree in Business Administration. The\", 'The possible positions for B.E. (Computers) are: System Administrator (Operation & Maintenance of Server, Storage & Service Desk System) with an experience requirement of 4 to 5 years. The related skills are Natural Language Processing and Python NLP. The possible positions for NLP are: Machine Learning Engineer with an experience requirement of 4 to 5 years. The related skills are Data Analysis, Business Analysis, Accurate Prediction, Business Prediction, Detailed Reporting, Data Visualization, Market Research, Client Management and Python Programming. The possible positions for Data Science are: Software Engineer with an experience requirement of 2 to 3 years', 'Entry-level requirements typically include a degree in marketing, communications, or a related field. Gaining experience with digital advertising platforms and understanding basic media buying concepts are also important skills for this role. Certification in media buying can be beneficial but is not always required.', 'Daily tasks include coding, debugging code, writing and editing HTML, CSS, and JavaScript files, optimizing website performance, creating responsive designs, collaborating with designers on visual elements, testing sites for usability, and ensuring that the site is updated regularly. Additionally, developers maintain databases, work on new features, and troubleshoot issues as needed.', 'A degree in business, marketing, or a related field is often helpful. However, some employers may prioritize experience and skills in customer service over formal education. Certifications in customer service or sales can also be beneficial.', 'Tools typically used by a Market Development Manager (Junior level) include CRM software, Google Analytics for tracking marketing performance and customer behavior, Excel or Tableau for data analysis, and communication tools like Slack or Microsoft Teams. They may also use social media listening tools to monitor market trends.', 'The possible positions for Statistics and Data Analysis and Statistical Computation are: Head of Internal Control & Compliance (ICC) - SEVP/DMD. Key responsibilities include: 15+ Years Banking Experience, Audit/Inspection/ICC Leadership, Internal Audit & Compliance, Risk-Based Operational Reviews, System-Based Audit Expertise, Knowledge of Bangladeshi Laws & Regulations, Industry Best Practices, Team Leadership & Guidance, Internal Control & Compliance Design, Monitoring & Enforcement, Field Audit Coordination, Reporting & Documentation, Support to Higher Authorities, Other Relevant Duties. The estimated salary range for Head of Internal Control & Compliance (ICC) - SE', 'A Franchise Manager typically uses tools like franchise management software, customer relationship management (CRM) systems, inventory tracking systems, payroll processing tools, and communication platforms to manage day-to-day operations. They may also use tools for financial management and performance analysis.', \"Entry-level requirements typically include a Bachelor's degree in Legal Studies, Paralegal Studies, or a related field. Certification through the Nationalsystem\\n\\n Entry-level requirements typically include a Bachelor's degree in Legal Studies, Paralegal Studies, or a related field. Certification through the National Association of Legal Assistants (NALA) is often preferred.\", 'To start a career as a Robotics Engineer, focus on gaining education in robotics and electrical engineering, internships or research opportunities with robotics projects, building a portfolio of personal projects, learning programming languages like C++, Python, and understanding machine learning algorithms. Gaining experience with robotic systems and working with industry partners is also beneficial. Certifications in robotics can help in advancing the career. Networking and staying updated with advancements in robotics technology will aid in further development.', \"Qualifications typically include a Bachelor's degree in Computer Science, Mathematics, Statistics, or a related field. A Master's degree is often preferred for more senior roles or specialized fields like AI. Certifications like Google Cloud Data Engineer and AWS Certified Data Scientist can also enhance qualifications. Practical experience with data science tools and languages is essential.\", 'The possible positions for B.E. (Computers) are: Mechanical Engineer with an experience requirement of At least 5 years. The related skills are NLP, ML and Amazon Comprehend Medical API. The job description includes Natural Language Processing (NLP), Machine Learning (ML) and AWS services like Lambda, API Gateway, DynamoDB, EC2, RDS and S3. The possible positions for B.E. (Electrical Engineers) are: Sr.Officer / Executive - Internal Audit with an experience requirement of At least 5 years. The related skills are NLP, ML and Amazon Comprehend Text API', 'The possible positions for N/A are: Project Coordinator (Civil). Key responsibilities include: Project Design, Data Analysis, ACCORD/Alliance Knowledge, BNBC Standards, Cost Estimation, Feasibility Studies, Documentation, Site Monitoring, Policy Compliance, Legal Compliance, Site Establishment, Material Management, Team Collaboration, Quality Assurance, Inventory Management, Field Operations, Technical Support, Report Preparation, Consulting, Field Visits, Documentation, Storage, Inventory, Technical Specifications, Staff Development, Customer Services, Business Opportunities, Market Research, Product Design, Prototyping, Testing, Sales, Technical Support, Inventory Management, Field Work, Report Writing, Staff', \"The possible positions for BSc and MSc are: Civil Engineer with an experience requirement of 2 to 5 years. The related skills are NLP, ML and Amazon Comprehend Medical API. The related qualifications are Bachelor's degree in Mechanical Engineering. The related tools are NLTK, spaCy, GNNs, KNN, CNN, RNN, PyTorch and TensorFlow for NLP tasks and Python, NumPy, SciKit Learn for Machine Learning tasks. The position is Data Scientist with an experience requirement of 3 to 6 years. The related skills are NLP, ML and Amazon Comprehend\", 'The possible positions for B.E. (Computers) are: Full Stack Developer (Python,React js) with an experience requirement of 2 to 5 years. The related skills are NLP and Data Analysis and Machine learning (ML) and Python. The possible positions for NLP and Data Analysis and Machine Learning (ML) are: Software Engineer. The experience required for this position is 1 to 3 years. The related skills are Electrical Engineering and Maintenance of Machinery, System, Equipment. The possible positions for Electrical Engineering and Maintenance of Machinery, System, Equipment are: Mechanical Engineer with an experience requirement of 2 to', 'The main responsibilities include analyzing social media data to understand audience behavior, creating reports based on insights, developing and implementing social media strategies, monitoring brand mentions and competitors online, conducting A/B testing for content optimization, and ensuring that all social media platforms are up-to-date and functioning correctly.', 'Business Intelligence Analysts typically use tools such as Excel, Tableau, Power BI, SQL, MySQL, and other data analysis tools. They also utilize ETL (Extract, Transform, Load) software for data integration and reporting. Additionally, they may use cloud-based platforms like AWS or Azure for big data analytics.', 'Skills required include knowledge of cloud platforms (AWS, Azure), experience with cloud architecture, security expertise, proficiency in cloud management tools like AWS CloudWatch or Azure Monitor, and strong problem-solving abilities. Additionally, understanding of data storage, scalability, and cost optimization is important. Experience with DevOps practices can also be beneficial.', 'Essential skills include strong communication and interpersonal skills, attention to detail, ability to multitask, knowledge of customer service standards, inventory management expertise, leadership abilities, problem-solving skills, and the ability to maintain a positive work environment.', 'Daily tasks include researching market trends, assisting in creating ad copy and designs, working with the design team to create visual assets for ads, tracking campaign performance through analytics tools, and collaborating with other teams to ensure that messaging aligns across different channels. They may also be involved in scheduling ad placements and helping to optimize ad campaigns.', 'The average salary for a Policy Advisor typically ranges from $50,000 to $70,000 annually, depending on factors such as location, experience level, and industry. Senior positions or those in specialized fields may command higher salaries.', 'Cloud Database Engineers typically work at companies that utilize cloud computing, such as Google Cloud Platform, Amazon Web Services, Microsoft Azure, or hybrid environments. They may also work for cloud-focused service providers, system integrators, and consulting firms. Many companies now offer remote work options, making it possible to work from anywhere.', 'Difficulties include dealing with complex, messy data, meeting tight deadlines, ensuring that visualizations are both informative and aesthetically pleasing, handling user feedback or criticism, and staying updated on the latest visualization tools and trends. Additionally, balancing detail and simplicity in visual representation is a significant challenge.', 'Business Analysts typically work in industries such as finance, healthcare, retail, technology, and government. They may be employed by large corporations, consulting firms, or small businesses. Many Business Analysts also work remotely or freelance for clients across various sectors.', 'A typical day involves preparing and reviewing legal documents, conducting research to gather information for cases or contracts, assisting attorneys in drafting and filing court filings, communicating with clients about their case status, and maintaining organizational records. The role also includes working on tasks like document review, transcription services, and data entry.', 'The possible positions for Bachelor of Business Administration are: Executive/ Senior Executive- Trade Marketing, Hygiene Products with an experience requirement of At least 3 years. The related skills are Market Research and Data Analysis. The possible positions for Market Research and Data Analysis are: Sr.Officer / Executive -Internal Audit with an experience requirement of At least 2 years. The related skills are Software Development, Application Programming, System Analysis, Design, Development, Test, Client Support, Server Management, Data Protection, Disaster Recovery, Security, Networking, Integration Services, Troubleshooting, Technical Support, Non-Technical Support, Documentation, Plugin Development,', \"The possible positions for Bachelor of Science are: Mechanical Engineer with an experience requirement of At least 5 years. The related skills are NLP, ML and Amazon Comprehend Medical API. The related qualifications are Bachelor's degree in Engineering. The average salary range is between Rs.15 lakhs and Rs.30 lakhs per annum.\", 'A typical day involves reviewing code, fixing bugs, writing new automation scripts, collaborating with developers and product teams to integrate automated processes, monitoring systems for performance issues, and optimizing existing workflows. The role also requires staying updated on emerging technologies in automation.', 'A typical day involves monitoring production processes, identifying bottlenecks, collaborating with teams to optimize workflows, managing inventory and supply chains, responding to operational issues, and ensuring that business objectives are met. The role also requires problem-solving, data analysis, and communication skills.', 'A Claims Adjuster is responsible for investigating and assessing insurance claims, negotiating with policyholders and third parties, determining claim settlements, and ensuring that all claims are handled fairly and efficiently. They work closely with underwriters to determine coverage and costs associated with claims. The role involves reviewing paperwork, conducting site visits, communicating with customers, and making decisions on claim payouts. Claims Adjusters often work in the insurance industry or as independent contractors for third-party adjusters.'], 'references': ['The possible positions for B.E. (Computers) are: Mechanical Designer with an experience requirement of At least 5 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', \"The possible positions for Bachelor of Business Administration are: Site Engineer with an experience requirement of 1 to 2 years. The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router\", 'Entry-level requirements typically include a high school diploma, some college education or relevant certifications, and a state-issued license. Experience in customer service or insurance is a plus.', 'The possible positions for Computer Applications and Computer Applications are: Senior Software Engineer. Key responsibilities include: Technical Support, Troubleshooting, Collaboration, Documentation, System Monitoring, Software Deployment, Training & Mentorship, Industry Trends, Field Visits', 'The possible positions for B.Tech are: Asst. Manager/ Manger (Administrative) with an experience requirement of At least 5 years. The related skills are Testing, Debugging and Parameter Tuning', 'Claims Adjusters usually work in office environments but may also spend time in the field conducting investigations, meeting with claimants, or inspecting damaged properties. Some positions may offer remote work options.', 'Companies that rely heavily on data-driven decision-making, such as tech companies, financial institutions, retail businesses, and healthcare organizations, hire Business Intelligence Analysts.', 'Tech companies, AI startups, large corporations with AI needs, financial institutions, healthcare organizations, and research labs commonly hire AI Software Engineers.', 'The possible positions for B.Tech are: Data Engineer with an experience requirement of 5 to 8 years. The related skills are NLP and Data Analysis', 'On a daily basis, a Social Media Analyst monitors social media platforms, tracks key performance indicators (KPIs), compiles data into reports, engages with social media teams to optimize strategies, and analyzes trends to guide future campaigns.', 'Software Engineers often work in collaborative environments with other developers, product managers, and designers, with opportunities for remote or in-office work depending on the company.', 'The average salary for an entry-level Product Manager ranges from $60,000 to $90,000 per year, depending on experience and location.', 'The salary range for a Junior Digital Marketing Manager typically falls between $45,000 and $65,000 annually, with senior roles or positions in larger companies offering higher salaries.', 'The possible positions for B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X are: System Administrator (Operation & Maintenance of Server, Storage & Service Desk System) with an experience requirement of 4 to 5 years. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, OCR, Pytesseract and NER Text Classification', 'Essential skills include expertise in manual and automated testing, proficiency with testing tools (like Selenium, QTP, JUnit), understanding of bug-tracking systems, and strong analytical and debugging skills.', \"An Operations Executive is responsible for ensuring that the company's day-to-day activities run efficiently. They monitor operational performance, optimize processes, and assist in resource management and problem-solving.\", 'The possible positions for Bachelor of Engineering are: Sr.Officer / Executive - Internal Audit with an experience requirement of 2 to 4 years. The related skills are Software Development and Application Programming', 'The possible positions for BBA are: Business Development Executive with an experience requirement of 1 to 3 years. The related skills are Data Analysis and Business Analysis', 'Daily tasks include reviewing environmental impact data, assessing energy usage and waste management practices, meeting with clients to discuss sustainability goals, preparing reports, and developing recommendations for improving sustainability efforts.', 'The possible positions for Statistics are: Network Support Engineer. Key responsibilities include: Mikrotik Router Configuration, OLT Device Setup & Management, Integration with Billing Software, Network Monitoring Tools Integration, Connectivity Troubleshooting, Technical Support & Escalation, Installation & Configuration, GPON/EPON Expertise, Cisco, OLT, MikroTik Knowledge', 'The possible positions for Bachelor of Science are: Senior Software Engineer with an experience requirement of At least 1 year. The related skills are Creating dashboards for sales and profits', 'The possible positions for B.E. (Computers) are: DevOps Engineer with an experience requirement of At least 3 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'Entry-level requirements typically include a Bachelor’s degree in Marketing, Advertising, or Communications, along with an understanding of media buying and advertising principles. Internships or hands-on experience in digital marketing can also be helpful.', 'Daily tasks include coding, testing new features, troubleshooting bugs, attending team meetings, reviewing code, and ensuring that websites and web applications are performing well.', 'While a degree in Business, Marketing, or a related field is often preferred, experience in customer service or sales, along with hands-on experience with CRM tools, can also provide an entry point into this role.', 'Tools typically used include market research platforms like Nielsen, Google Analytics for website data, CRM software like Salesforce, and project management tools like Asana or Trello.', 'The possible positions for Statistics and Data Analysis and Statistical Computation are: Database Administrator (DBA). Key responsibilities include: Database Design & Development, SQL Query Optimization, Data Integrity & Security, BI Solutions Development, ETL Process Implementation, Database Maintenance, Backup & Restore Management, Index Rebuilding & Performance Tuning, SQL Server Clustering & High Availability, SQL Server Replication, High Availability Group Management, Database Monitoring & Troubleshooting', 'Franchise Managers typically use franchise management software, scheduling tools, POS systems, customer relationship management (CRM) systems, and business reporting tools like Excel or Google Sheets.', 'Entry-level requirements typically include a Bachelor’s degree or completion of a legal assistant certification program. Some positions may accept candidates with relevant experience or internships in the legal field.', 'To start, focus on obtaining a relevant degree (e.g., Robotics, Mechanical Engineering, Electrical Engineering) and gain hands-on experience with robotic systems, programming, and hardware design through internships or personal projects.', \"A bachelor's or master's degree in fields like Computer Science, Statistics, Mathematics, or Data Science is typically required.\", 'The possible positions for B.E. (Computers) are: Asst. Manager/ Manger (Administrative) with an experience requirement of At least 5 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'The possible positions for N/A are: Manager- Human Resource Management (HRM)\\n. Key responsibilities include: Recruitment Coordination, Appointment Management, Selection Criteria, Employee Orientation, Performance Evaluation, HR Database Management, Report Compilation, Documentation, Event Coordination, Task Execution', 'The possible positions for BSc and MSc are: Senior iOS Engineer with an experience requirement of At least 4 years. The related skills are NLP, ML and Amazon Comprehend Medical API', 'The possible positions for B.E. (Computers) are: Senior Software Engineer with an experience requirement of At least 1 year. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'The main responsibilities include analyzing social media data, tracking engagement metrics, developing reports, identifying trends and insights, monitoring online conversations, managing social media campaigns, and helping to optimize social media strategies.', 'Business Intelligence Analysts typically use BI tools like Power BI, Tableau, and QlikView for data visualization and reporting. They also use SQL-based tools for data querying and may use Excel for data manipulation.', 'Skills include a strong understanding of cloud platforms (AWS, Azure, Google Cloud), knowledge of cloud migration processes, familiarity with security practices, and problem-solving skills in the context of cloud infrastructure.', 'Essential skills include effective leadership, customer service, inventory management, staff training, sales strategies, and proficiency with point-of-sale (POS) systems.', 'Daily tasks include reviewing ad performance, working with the creative team on ad design, preparing reports, managing budgets for campaigns, and ensuring all ads are properly placed on the chosen platforms.', 'The average salary for a Policy Advisor typically ranges from $50,000 to $75,000 annually, depending on experience, location, and the specific employer.', 'Cloud Database Engineers work for tech companies, cloud service providers, consulting firms, and large enterprises that rely on cloud-based database solutions. Many work remotely or in hybrid environments.', 'Data Visualization Specialists often face challenges related to data quality, such as incomplete or messy data, and ensuring that visualizations are intuitive, meaningful, and aligned with business goals.', 'Business Analysts work in a variety of industries, including finance, healthcare, IT, manufacturing, and consulting. They can be employed in both large corporations and smaller companies.', 'A typical day involves preparing and filing legal documents, conducting legal research, organizing case files, assisting lawyers with trial preparation, and communicating with clients or witnesses. They may also attend meetings and hearings.', \"The possible positions for Bachelor of Business Administration are: Project Coordinator (Civil) with an experience requirement of 5 to 10 years. The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router\", 'The possible positions for Bachelor of Science are: Data Science Engineer with an experience requirement of At least 2 years. The related skills are Creating dashboards for sales and profits', 'A typical day involves designing automation processes, writing and testing scripts, debugging automation systems, collaborating with developers, and monitoring automated workflows to ensure they run efficiently.', 'A typical day includes overseeing operations, managing resources, tracking performance metrics, analyzing processes for efficiency, coordinating between departments, and handling any operational issues that arise.', 'A Claims Adjuster reviews and processes insurance claims by assessing the damages, interviewing claimants and witnesses, conducting investigations, and determining the payout based on the insurance policy terms and the extent of the loss.'], 'precision': 0.6814438104629517, 'recall': 0.7657464742660522, 'f1': 0.7198733687400818}\n"
     ]
    }
   ],
   "source": [
    "# LoRA Q5_K_M gguf model bertscore\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "results = evaluate_llama_bertscore_withChatTemplate(model_path=\"./quantized_models/ft-q5_k_m-lora.gguf\", dataset=small_test, tokenizer=tokenizer)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (1024) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "Generating responses: 100%|██████████| 50/50 [30:17<00:00, 36.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': ['The possible positions for B.E. (Computers) are: Network Support Engineer with an experience requirement of At least 1 year. The related skills are Electrical and Mechanical Equipment, System Analysis, Decision Making, Data Communication, Transducer/Converter, Microcomputer/Computer, Electrical/Mechanical Test, Customer Service, Field Technical Services, Repair, Diagnostics, Documentation, Operations, Management, Teamwork, Product Sales, Transfer, Sales, Customer, Error Reporting, Replacement, Troubleshooting, Parts Inventory, Payroll, Account, Field Visits, Debugging, Data Entry, File Management, Supervisory Assistance, Testing,', \"? The possible positions for Bachelor of Business Administration are: Mechanical Engineer with an experience requirement of 5 to 8 years. The related skills are Software Development and Application Programming. The related qualifications are Bachelor's Degree. The possible positions for Bachelor's Degree are: Data Science Engineer. The experience requirement is 2 to 4 years. The related skills are Software Development, Application Programming and System Analysis. The related qualifications are Bachelor's Degree. The possible positions for Bachelor's Degree are: Machine Learning (ML) Engineer. The experience requirement is 5 to 8 years. The related skills are Software Development and Application Programming. The related qualifications\", '?\\nEntry-level requirements typically include a high school diploma or equivalent, completion of an apprenticeship program in claims adjusting, and passing a certification exam such as the Certified Claims Adjuster (CCA) or Associate in Claims Adjusting (ACA). Some employers may also require relevant experience. Salary expectations for entry-level Claims Adjusters can range from $40,000 to $60,000 annually, depending on the employer, location, and level of experience. Key skills include strong communication, analytical thinking, attention to detail, and knowledge of insurance laws and practices. (Source: CareerAdvisor.com)', 'The position for Computer Applications and Computer Applications is: Machine Learning (ML) Engineer. The position for Data Analysis, Machine learning, Data Mining, Natural Language Processing, Linear Regression, Cluster Analysis, Correlation Analysis, Logistic Regression, Principal Component Analysis, Anova, Neural Networks, R, Python, MySQL, Tableau, Excel, SPSS and Decision tree is: Senior iOS Engineer. He/She will be responsible for designing and developing the user interface for iOS applications. The team will collaborate with cross-functional groups to ensure that features are implemented correctly and efficiently. The candidate should have a strong passion for mobile development and excellent UI design', '?\\n positions  position  description      employer  Location  Experience  Required  Skills  Education  Competencies  Career Growth  Salary  The project manager will oversee the entire project lifecycle, from planning and execution to monitoring and evaluation. He/she will ensure that all tasks are completed on time and within budget. The successful candidate will have a strong understanding of IT projects, experience with project management tools like Jira or Microsoft Project, and excellent communication skills. In this role, you will work closely with cross-functional teams such as development, QA, and operations to ensure the smooth delivery of our products. The ideal candidate will have a deep understanding of', \"31 Oct 2025\\n\\nA Claims Adjuster typically works in an office environment, with some on-site visits to clients' homes or businesses. They may also work from remote locations, such as mobile adjusters or investigators. The role often involves traveling to different areas to assess losses and negotiate settlements. The work can be physically demanding at times, requiring the adjuster to spend long hours in the field or dealing with stressful situations. However, most claims adjusting roles are office-based, allowing for a more predictable schedule. The job typically requires good communication skills, both written and verbal, as well as the ability to navigate complex legal issues and\", '?\\nCompanies that hire Business Intelligence Analysts include financial institutions, healthcare organizations, technology firms, retail companies, and any organization looking to improve data-driven decision-making. This role can be found in various industries such as finance, insurance, banking, medical, tech, manufacturing, etc.\\n\\nWhat are the essential skills for a successful Business Intelligence Analyst??\\nThe essential skills include proficiency in BI tools (Power BI, Tableau), SQL knowledge, ability to analyze and interpret data, understanding of business operations, and the ability to communicate insights effectively. Strong data visualization skills, project management, and collaboration with various teams are also important.\\n\\nWhat is the career', '?\\nMany companies, especially those in the tech and financial sectors, hire AI Software Engineers. Some notable examples include Google, Amazon, Microsoft, Facebook, and IBM. Additionally, startups, research institutions, and academia often employ AI Software Engineers to work on cutting-edge projects. Companies that operate in industries such as retail, healthcare, finance, and logistics may also hire AI Software Engineers to help them integrate machine learning into their operations.\\n\\nWhat are the essential skills for an AI Software Engineer??\\n\\nEssential skills include proficiency in programming languages (especially Python), familiarity with deep learning frameworks like TensorFlow or PyTorch, expertise in machine learning algorithms, understanding', \"?\\nposition_position>\\nThe possible positions for B.Tech are: Project Coordinator (Civil) with an experience requirement of At least 5 years. The related skills are NLP and Data Analysis. The related qualifications is Bachelor's degree in Engineering. The related tools are Python, Keras and TensorFlow. The related technologies are AWS, Azure and Google Cloud. The possible positions for Master's degree are: Mechanical Engineer with an experience requirement of At least 3 years. The related skills are Software Development, Application Programming, System Analysis, Client Management, Server Management, Data Science, Machine Learning, Python Programming, AWS Migration Strategy, Azure Services,\", '?\\nA Social Media Analyst spends their day monitoring social media platforms for updates, analyzing engagement metrics (e.g., likes, comments, shares), tracking the performance of social media campaigns, and providing data-driven insights to support marketing decisions. They also assist in creating content schedules, engage with online communities, and may help manage social media advertising budgets. Their work is focused on optimizing the impact of a company’s digital presence across multiple platforms. On any given day, they might be responding to comments on social media posts, analyzing Google Analytics data, or assisting in crafting new marketing messages for various channels. The role requires constant attention to changes in social media', '18 Oct 2025\\n\\nA Software Engineer can expect to work in a collaborative office environment. They will often be part of teams working on complex projects, with opportunities for remote or hybrid work arrangements depending on the company and role. The environment is usually fast-paced, requiring quick problem-solving and communication between team members.\\n\\nKey characteristics include:\\n\\n- Collaboration: Software Engineers work closely with other developers, product managers, and designers to ensure seamless project execution.\\n- Problem-solving: They are often involved in resolving bugs or issues within the codebase, so strong analytical skills are necessary.\\n- Communication: Clear and concise communication is crucial for ensuring that design', '?\\nThe average salary for a Product Manager typically ranges from $80,000 to $120,000 annually, depending on factors such as location, experience level, and the company’s industry. Senior Product Managers or those in leadership roles may earn higher salaries.\\n\\nWhat are the main responsibilities of a Product Manager??\\n\\nMain responsibilities include defining product features, working with cross-functional teams like development, design, and marketing, conducting market research, setting product roadmaps, managing project timelines, and ensuring that products meet customer needs. The role involves balancing business goals with user feedback to create successful products.\\n\\nWhat is the typical career path for a Product Manager?', \"?\\n\\nThe salary range for a Digital Marketing Manager (Junior level) is generally between $45,000 and $55,000 annually. However, this can vary based on factors like location, experience, and industry. Senior-level or specialized roles may have higher salaries. It's also worth noting that salary ranges are typically higher in larger cities or major metropolitan areas. The range may be lower for entry-level positions or those with less relevant experience.\", \"The possible positions for B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X are: DevOps Engineer with an experience requirement of At least 3 years. The related skills are Natural Language Processing, Python and Machine learning for NLP. The related qualifications are Master's degree or higher. The related tools are TensorFlow, Keras and Python library for building neural networks. The possible positions for B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X are: Site Engineer with an experience requirement of At least 4 years. The related skills are Electrical Systems, Maintenance, Repair, Operations\", '?\\nEssential skills include strong attention to detail, the ability to reproduce issues, expertise in testing methodologies, proficiency in automation tools like Selenium or Appium, and understanding of database testing. Soft skills such as effective communication, collaboration, and problem-solving are also crucial. \\n\\nThe best answer is: Strong attention to detail, reproducibility, test methodologies, automation (Selenium, Appium), database testing, and effective communication.', '?\\nThe job description involves overseeing the operational aspects of a company, managing teams, optimizing processes, ensuring efficiency in operations, and coordinating with other departments to ensure smooth execution. The role requires strong analytical skills, attention to detail, and excellent communication abilities.\\n\\nKey responsibilities include:\\n\\n*   Overseeing operational activities such as manufacturing, logistics, or customer service\\n*   Managing cross-functional teams responsible for day-to-day operations\\n*   Analyzing data to identify areas for process improvements\\n*   Implementing changes to operational workflows and processes\\n*   Collaborating with other departments like sales, marketing, and finance to ensure alignment\\n*   Ensuring', \"?\\nThe possible positions for Bachelor of Engineering are: DevOps Engineer with an experience requirement of 4 to 7 years. The related skills are NLP, ML and Amazon Comprehend Medical API. The related qualifications are Master's degree in AI or Machine learning. The candidate should have a strong background in machine learning algorithms and their applications. The candidate should also be familiar with Python programming language. The experience requirement for DevOps Engineer is 4 to 7 years. The position requires a Master's degree in AI or Machine learning. The related skills are Data Analysis, Business Analysis, Data Mining, Predictive Analysis, Business Prediction,\", '?\\nThe possible positions for BBA are: Mechanical Designer with an experience requirement of 5 to 10 years. The related skills are Software Development, Application Programming, System Analysis, Designing Objects in CAD software, Engineering Services, Test Report Preparation, Data Translation, Expert Witness, Salary Negotiation, Performance Reporting, Field Investigations, Documentation, Data Management, Team Collaboration, Software Selection, Innovation, Industry Trends, Field Work, Research, Paper Publication, Presentation, Skills Transfer, Employee Training, Customer Engagement, Market Research, Sales Forecasting, Buying Selling, Head of Department, Executive, Mr. Rajesh Garg and Additional Salary Insights at', '?\\nDaily tasks include conducting environmental impact assessments, analyzing data on resource usage and carbon footprint, collaborating with clients to develop sustainable practices, recommending sustainable technologies or strategies, staying updated on sustainability regulations and best practices, and communicating results to stakeholders. The role also involves supporting sustainability initiatives, facilitating workshops or training sessions, and reporting on progress towards sustainability goals. External interactions are common, including meetings with business leaders, government representatives, or community groups. A Sustainability Consultant’s work is often project-based, so they may work on multiple projects simultaneously, managing timelines and coordinating efforts to achieve desired outcomes. The role also involves staying informed about new technologies, methodologies,', 'The position for Statistics is: DevOps Engineer. The skills required are Python, Jenkins, Git, SVN, Docker, Kubernetes, CI/CD Culture, Node JS and Server Side Validation. The position requires Experience in CI/CD pipelines, Dockerization, Kubernetes deployment, Jenkinsfile editing, Docker Compose usage, SVN & Git repository management, SVN & Git commit monitoring, Build Automation (Jenkins, Docker, Kinubla), Server Side Validation, Node JS for server and Client side validation, AWS CLI for Amazon RDS & EC2, Terraform for infrastructure provisioning, Bash for Unix system & Anlogy testing, TestNG', '?\\nPosition Match for Bachelor of Science is: Executive/ Senior Executive with an experience requirement of 5 to 10 years. The related skills are Market Research, Data Analysis and Business Analytics. The related qualifications are Bachelor of Science. The related tools are Microsoft Office, Tableau, Google Data Studio and Python. The related industry is Retail. The related job description is To perform market research, analyze data, create reports, and help businesses make informed decisions about their products or services. This role requires the ability to conduct surveys, interviews, and other forms of data collection. It also needs strong analytical skills and the ability to interpret results in a', \"The possible positions for B.E. (Computers) are: Machine Learning (ML) Engineer with an experience requirement of At least 2 years. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, OCR, Pytesseract and NER Text Classification in Python. The related qualifications are Bachelor's Degree. The job description is To design and develop scalable machine learning models that can handle large datasets. The key responsibilities include Data Preparation, Model Training, Integration with APIs, Predictive Analysis, Integration testing, System analysis, Report generation, Field trips, User support, Account management, Inventory management,\", '?\\nEntry-level requirements typically include a degree in Marketing, Advertising, or a related field. A Media Buyer should also have strong knowledge of digital marketing platforms, data analysis tools, and campaign management software. Practical experience through internships or entry-level media buying roles is crucial for securing positions at larger agencies or companies. Certifications in media buying or digital advertising can be beneficial. An understanding of SEO principles, Google Analytics expertise, and familiarity with Ad Exchange platforms will help an individual succeed in this role. A strong communication skill set, attention to detail, and the ability to manage multiple campaigns are essential for a Media Buyer. Pay rates vary by location', \"?\\nDaily tasks include writing HTML and CSS, debugging web pages, optimizing website performance, updating and maintaining existing websites, and integrating new features. A Web Developer may also be involved in designing user interfaces, working on front-end development projects, and collaborating with backend developers or designers. Tasks can vary depending on the project, company, and specific role within a team. Key tasks include writing clean code, debugging issues, and ensuring web pages render correctly across different browsers and devices. A Web Developer's day may involve reviewing design files, testing new features in development environments, and communicating with stakeholders to clarify requirements or resolve issues. The work is often iterative\", \"?\\nWhile a degree is not strictly necessary, it can certainly help in securing a job. Many employers require at least a Bachelor's degree in Business or a related field. However, relevant experience, strong communication skills, and the ability to build relationships are essential for success in this role.\\n\\nDo I need a degree to pursue a career as a Customer Relationship Manager??\\nWhile a degree is not strictly necessary, it can certainly help in securing a job. Many employers require at least a Bachelor's degree in Business or a related field. However, relevant experience, strong communication skills, and the ability to build relationships are essential for success in this role\", 'A Market Development Manager (Junior level) typically uses tools such as market research software, CRM platforms like Salesforce, Google Analytics, and Excel for data analysis. They may also use tools specific to their company or industry. The emphasis is on finding the right tools that support a strong focus on customer development and sales processes. \\n\\nWhy are Market Development Managers important in a company??\\nMarket Development Managers play a crucial role by helping companies expand into new markets, identify potential customers, and develop effective strategies for growth. This expertise supports businesses to increase their market share, improve revenue, and enhance overall competitiveness. A good Market Development Manager ensures that the', 'The possible positions for Statistics and Data Analysis and Statistical Computation are: Mechanical Engineer. Key responsibilities include: Machinery Maintenance, Troubleshooting, Repair Orders, Log Books, Safety Monitoring, Customer Communication, Team Collaboration, Inventory Management, Task Assignment, and Equipment Operation. The position requires a strong foundation in mechanical principles, problem-solving skills, ability to work with various machinery types, and effective communication. Self-motivation, attention to detail, and the ability to work in a team environment are also essential. The salary range for Mechanical Engineer is between $50,000 and $70,000 annually. Other related positions include: Senior Mechanical', 'A Franchise Manager typically uses tools like franchise management software, CRM systems, accounting and payroll tools, marketing automation platforms, and communication tools to manage and support the operations of the franchised business. \\n\\nWhy are franchise models successful? \\nFranchise models are successful because they allow businesses to leverage their brand, expertise, and operational efficiency in new markets without requiring a significant investment from each franchisee. This can lead to widespread growth while maintaining control over the overall brand experience.\\n\\nWhat skills are required to succeed as a Franchise Manager? \\nSkills required include strong communication, leadership, and problem-solving abilities, as well as the ability to manage', \"?\\nThe entry-level requirements typically include a Bachelor's degree in Legal Studies, Paralegal Studies, or a related field. Some employers may also require certification from the National Association of Legal Assistants (NALA) or the American Bar Association (ABA). Relevant experience and strong communication skills are also important. An internship or entry-level legal assistant position can provide valuable training for those who pursue this career path. The requirement varies by location, but a degree in legal studies is usually preferred. A Bachelor's degree is generally the minimum educational requirement for an entry-level Legal Assistant. Relevant work experience, such as internships or entry-level positions, may\", \"?\\nStarting a career as a Robotics Engineer typically requires a strong foundation in engineering and robotics. Here are some steps to follow:\\n\\n1.  **Gain a Bachelor's degree**: Earn a degree in Mechanical Engineering, Electrical Engineering, Computer Science, or a related field. A Master's degree can be beneficial for advanced roles.\\n2.  **Learn robotics programming languages**: Familiarize yourself with Python, C++, and ROS (Robot Operating System) to develop skills in robotics programming.\\n3.  **Gain experience with robotic systems**: Participate in internships, projects, or volunteer work that involve building and controlling robots.\\n4.  **\", \"?\\nThe qualifications typically include a Bachelor's degree in Computer Science, Information Technology, or Mathematics. A Master's degree is often preferred for advanced roles and expertise. Certifications such as Certified Data Scientist (CDS) can also be beneficial. Experience with programming languages like Python, R, and SQL, along with proficiency in data analysis tools and machine learning algorithms, is essential for a Data Scientist role. Strong analytical skills, attention to detail, and the ability to communicate complex ideas are also crucial. Internships or research projects in data science can provide valuable practical experience. The field of Data Science is constantly evolving, so staying up-to-date with\", \"The possible positions for B.E. (Computers) are: Mechanical Engineer with an experience requirement of At least 5 years. The related skills are Market Research and Data Analysis. The related qualifications are Post Graduate. The other positions in the same field are: DevOps Engineer with an experience requirement of At least 7 years. The related skills are Software Development, Application Programming, System Analysis, Technical Support, Client Management and Team Collaboration. The related qualifications are Bachelor's. The other positions in the same field are: Data Scientist with an experience requirement of At least 5 years. The related skills are Data Science, Machine Learning and\", '?\\n\\nThe position for N/A is: Senior Software Engineer. The position includes: Project Coordination, Requirement Gathering, Design Creation, Prototype Development, Feature Implementation, Quality Assurance, Project Monitoring, Collaboration, Data Management, Application Development, Innovation Encouragement, Problem Solving, Code Writing, Test Running, Field Work, Laboratory Work, Data Transcription, Report Writing, Task Completion, Field Visitions, Headquarters Visits, Data Analysis, Statistical Analysis, Model Selection, Parameter Estimation, Data Representation, Team Integration, Client Communication, Application Testing, System Analysis, Data Science, Machine Learning, Python, R, AWS Services, NodeJS', '?\\n\\n positions. He/She will be responsible for maintaining the accuracy of our data, performing complex statistical analysis, and contributing to the development of new tools and models. The role requires a strong foundation in statistics, machine learning, and data science. Experience with big data analytics is also important. The salary range for this position is between $60,000 and $100,000 annually, depending on factors such as location, experience, and industry. Key responsibilities include: * Data Preparation: Ensuring that the data is clean, accurate, and in a suitable format for analysis. * Statistical Analysis: Conducting statistical tests to identify trends, patterns', 'The possible positions for B.E. (Computers) are: Executive/ Sr. Executive -IT with an experience requirement of At least 3 years. The possible positions for B.E. (Computers) are: Machine Learning Engineer with an experience requirement of At least 2 years. The possible positions for B.E. (Computers) are: Data Science Engineer with an experience requirement of At least 2 years. The possible positions for B.E. (Computers) are: Software Engineering Manager with an experience requirement of At least 5 years. The possible positions for B.E. (Computers) are: Network Support', '?\\nThe main responsibilities include analyzing social media data to understand audience engagement, identifying trends in online conversations, creating reports on key performance indicators (KPIs) such as followers and engagement rates, helping develop social media strategies based on the analysis, and ensuring that social media channels are optimized for maximum reach and effectiveness. They also support content creation teams by providing insights into how social media platforms can be used to amplify brand messages and campaigns. Additionally, they monitor online reputation metrics and help manage negative conversations or PR issues on social media. The role requires a deep understanding of social media tools, data analytics, and communication skills to effectively convey findings and recommendations', 'A Business Intelligence Analyst typically uses tools like Excel, Power BI, Tableau, SQL, and data integration tools for data preparation. They may also use machine learning platforms or statistical software for advanced analysis. The specific tools used can vary depending on the organization and the project requirements.\\n\\nWhat skills are required to become a successful Business Intelligence Analyst? \\nSkills required include proficiency in data visualization tools, SQL programming skills, expertise with business intelligence tools like Power BI or Tableau, experience with data preparation and transformation, and strong analytical thinking. Communication and storytelling skills for presenting insights also play a significant role. Experience working with large datasets is beneficial.\\n\\nHow', '?\\nSkills required include knowledge of cloud computing platforms (AWS, Azure, Google Cloud), cloud security, data migration, virtualization, networking, and cloud architecture. Familiarity with cloud-based tools like cloud storage, backup, and disaster recovery services is also important. Cloud consultants must be able to communicate effectively with clients about their cloud strategies and help them make the most of their cloud investments. Strong analytical skills are necessary for diagnosing issues and optimizing cloud performance. Cloud consultants should stay up-to-date on the latest cloud trends and technologies. Experience in IT or software engineering can provide a strong foundation. A certification like AWS Certified Cloud Consultant or Azure', '?\\nEssential skills include excellent customer service, ability to manage inventory and sales, leadership and team management skills, conflict resolution, adaptability, and time management. Experience in retail operations or customer service is also beneficial. Certification programs like the Certified Retail Manager (CRM) can help individuals develop these skills and advance their careers. Key responsibilities include overseeing store staff, coordinating visual merchandising, managing inventory, and ensuring customer satisfaction through excellent service. The ability to multitask, communicate effectively with team members, and work in a fast-paced environment is also important. Strong analytical skills are necessary for analyzing sales data and optimizing store operations. Overall, a', '?\\nThe daily tasks of an Advertising Manager (Junior level) include: Creating and editing online ads, Campaign management, Analyzing ad performance data, Collaborating with the Marketing team to develop new campaigns, Designing print ads if needed, Helping to optimize digital ad spend by experimenting with different targeting options and budget allocations. Other tasks might include monitoring social media advertising performance, Creating reports on campaign results, Managing media buying schedules, Working closely with external agencies or media outlets as required, Conducting research on competitor ads to inform our strategy, And assisting in the development of new marketing channels or platforms. The focus is on supporting the team in developing and', '?\\nThe average salary for a Policy Advisor is generally between $50,000 and $70,000 annually. However, salaries can vary depending on factors such as location, industry, experience level, and specific employer.\\n\\nHere are some average salary ranges for Policy Advisors in different regions of the United States:\\n\\n* New York City: $60,000 - $80,000\\n* Washington D.C.: $55,000 - $75,000\\n* San Francisco Bay Area: $65,000 - $90,000\\n* Midwest and Southern states: $50,000 - $70,000\\n\\nKeep in mind that these are', '**\\nCloud Database Engineers typically work for large technology companies, IT consulting firms, and cloud infrastructure providers such as Google Cloud, Amazon Web Services (AWS), Microsoft Azure, or cloud database platforms like Google BigData Service. They may also work in-house for organizations that use these services.\\n\\nWhat skills are required to become a Cloud Database Engineer?**\\n\\nSkills include proficiency in cloud databases (e.g., PostgreSQL, MySQL, SQL Server), expertise in cloud infrastructure and storage (e.g., AWS RDS, Azure Database), knowledge of database performance tuning, experience with automated backup and disaster recovery solutions, familiarity with monitoring tools, and strong problem-solving skills.', '?\\nDifficulties include dealing with complex and messy data, ensuring that visualizations are accessible to a wide audience, managing the pace of projects, and maintaining up-to-date skills in visualization tools. Some specialists also face challenges in communicating insights effectively or translating technical data into user-friendly visualizations. Additionally, handling large datasets, meeting tight deadlines, and staying current with new data visualization tools can be challenging. The need to balance detail and simplicity in visualizations adds another layer of complexity to the role. Furthermore, Data Visualization Specialists must ensure that their work is both aesthetically pleasing and informative, making it a challenging task to balance these two objectives', 'Business Analysts typically work in industries such as finance, healthcare, manufacturing, and technology. They may also work in-house for large corporations or in consulting firms.\\n\\nWhy is automation important in business analysis?  \\nAutomation helps streamline processes like data visualization, reporting, and testing. It allows for more efficient collaboration between stakeholders, reduces errors, and enhances the overall productivity of the team.\\n\\nWhat are the key skills required to be a successful Business Analyst?  \\nKey skills include strong analytical abilities, effective communication, problem-solving, and familiarity with business intelligence tools and methodologies. The ability to work across different departments also helps in building comprehensive solutions.\\n\\nWhat is', '?\\nA typical day for a Legal Assistant will involve assisting attorneys with drafting legal documents, conducting research on case law and statutes, managing filing systems, preparing trial exhibits, and providing administrative support to the firm or attorney. The day may also include responding to client inquiries, reviewing financial documents, and helping with trial preparation. Pay attention to the work environment, as Legal Assistants often spend their days working in a law office setting. This role will require strong organizational skills, excellent communication abilities, and proficiency in legal research software. A successful Legal Assistant will be comfortable working in a fast-paced legal environment while maintaining high levels of accuracy and efficiency. Key', \"?\\nThe possible positions for Bachelor of Business Administration are: Data Scientist with an experience requirement of At least 5 years. The related skills are Market Research and Data Analysis. The related qualifications are Bachelor's Degree in Engineering. The skill requirements are Communication, Collaboration, Problem-Solving, Technical Expertise, Customer Service, Data Management, Team Work, Innovation, Accuracy, Compliance, Scality, Planing, Project Management, Field Sales, Business Sales, Customer Representative, Error Handling, Data Transfer, Field Traffic, Paperless Day, Scaly Server, Project Planning, Field Sales Training, Business Sales Training, Customer Services Training, Error Handling Training\", '?\\nPosition Title: Senior Software Engineer\\nJob Description: The candidate will be responsible for designing and developing software solutions. They will work closely with other teams to ensure that the software meets the required specifications. This role demands strong problem-solving skills, the ability to collaborate with others, and a deep understanding of software development. The candidate will also be expected to contribute to the improvement of existing software systems and participate in code reviews. Key responsibilities include developing software features, testing new features, and contributing to the overall architecture of the system. The role is challenging, but it offers opportunities for growth and learning within the company.\\nKey Skills: Software development,', '?\\nA typical day involves reviewing and analyzing logs, testing automation scripts, collaborating with development teams to resolve issues, identifying areas for optimization in the automated workflow, and implementing changes to improve efficiency. The role also requires communication between different departments or teams involved in the project. Automation Engineers work on automating complex processes so that they can be performed at scale by machines.\\nKey tasks include:\\n- Writing new automation scripts\\n- Debugging issues with existing scripts\\n- Integrating new tools into automated workflows\\n- Collaborating with developers to fix bugs and optimize performance\\n- Monitoring and troubleshooting automated systems\\n- Improving the efficiency of existing automations', '?\\nA typical day involves reviewing operational performance metrics, collaborating with cross-functional teams (Sales, Marketing, Product), identifying areas for process improvements, communicating with stakeholders to gather feedback or resolve issues, and planning strategic initiatives to enhance efficiency. The role also involves managing project timelines, resource allocation, and overseeing the implementation of new processes or technologies.\\n\\nKey responsibilities include:\\n- Monitoring and analyzing operational performance data\\n- Identifying opportunities for cost reduction and process optimization\\n- Collaborating with other departments on projects that align with company goals\\n- Managing project resources and tracking their progress\\n- Communicating with stakeholders to ensure smooth operations\\n- Developing and implementing operational', '?\\nThe job description for a Claims Adjuster includes reviewing claims, investigating losses, negotiating settlements, and ensuring that companies or organizations are not overpaying for insurance. The role requires strong communication skills, attention to detail, and the ability to manage large volumes of paperwork and data. Claims Adjusters may also have to visit sites where accidents occurred to gather information. Their main goal is to resolve claims in a fair and efficient manner. \\n\\nKey responsibilities include:\\n\\n- Reviewing policy details\\n- Interviewing claimants\\n- Inspecting property or vehicles involved in the accident\\n- Gathering evidence, such as photographs and witness statements\\n- Analyzing'], 'references': ['The possible positions for B.E. (Computers) are: Mechanical Designer with an experience requirement of At least 5 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', \"The possible positions for Bachelor of Business Administration are: Site Engineer with an experience requirement of 1 to 2 years. The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router\", 'Entry-level requirements typically include a high school diploma, some college education or relevant certifications, and a state-issued license. Experience in customer service or insurance is a plus.', 'The possible positions for Computer Applications and Computer Applications are: Senior Software Engineer. Key responsibilities include: Technical Support, Troubleshooting, Collaboration, Documentation, System Monitoring, Software Deployment, Training & Mentorship, Industry Trends, Field Visits', 'The possible positions for B.Tech are: Asst. Manager/ Manger (Administrative) with an experience requirement of At least 5 years. The related skills are Testing, Debugging and Parameter Tuning', 'Claims Adjusters usually work in office environments but may also spend time in the field conducting investigations, meeting with claimants, or inspecting damaged properties. Some positions may offer remote work options.', 'Companies that rely heavily on data-driven decision-making, such as tech companies, financial institutions, retail businesses, and healthcare organizations, hire Business Intelligence Analysts.', 'Tech companies, AI startups, large corporations with AI needs, financial institutions, healthcare organizations, and research labs commonly hire AI Software Engineers.', 'The possible positions for B.Tech are: Data Engineer with an experience requirement of 5 to 8 years. The related skills are NLP and Data Analysis', 'On a daily basis, a Social Media Analyst monitors social media platforms, tracks key performance indicators (KPIs), compiles data into reports, engages with social media teams to optimize strategies, and analyzes trends to guide future campaigns.', 'Software Engineers often work in collaborative environments with other developers, product managers, and designers, with opportunities for remote or in-office work depending on the company.', 'The average salary for an entry-level Product Manager ranges from $60,000 to $90,000 per year, depending on experience and location.', 'The salary range for a Junior Digital Marketing Manager typically falls between $45,000 and $65,000 annually, with senior roles or positions in larger companies offering higher salaries.', 'The possible positions for B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X are: System Administrator (Operation & Maintenance of Server, Storage & Service Desk System) with an experience requirement of 4 to 5 years. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, OCR, Pytesseract and NER Text Classification', 'Essential skills include expertise in manual and automated testing, proficiency with testing tools (like Selenium, QTP, JUnit), understanding of bug-tracking systems, and strong analytical and debugging skills.', \"An Operations Executive is responsible for ensuring that the company's day-to-day activities run efficiently. They monitor operational performance, optimize processes, and assist in resource management and problem-solving.\", 'The possible positions for Bachelor of Engineering are: Sr.Officer / Executive - Internal Audit with an experience requirement of 2 to 4 years. The related skills are Software Development and Application Programming', 'The possible positions for BBA are: Business Development Executive with an experience requirement of 1 to 3 years. The related skills are Data Analysis and Business Analysis', 'Daily tasks include reviewing environmental impact data, assessing energy usage and waste management practices, meeting with clients to discuss sustainability goals, preparing reports, and developing recommendations for improving sustainability efforts.', 'The possible positions for Statistics are: Network Support Engineer. Key responsibilities include: Mikrotik Router Configuration, OLT Device Setup & Management, Integration with Billing Software, Network Monitoring Tools Integration, Connectivity Troubleshooting, Technical Support & Escalation, Installation & Configuration, GPON/EPON Expertise, Cisco, OLT, MikroTik Knowledge', 'The possible positions for Bachelor of Science are: Senior Software Engineer with an experience requirement of At least 1 year. The related skills are Creating dashboards for sales and profits', 'The possible positions for B.E. (Computers) are: DevOps Engineer with an experience requirement of At least 3 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'Entry-level requirements typically include a Bachelor’s degree in Marketing, Advertising, or Communications, along with an understanding of media buying and advertising principles. Internships or hands-on experience in digital marketing can also be helpful.', 'Daily tasks include coding, testing new features, troubleshooting bugs, attending team meetings, reviewing code, and ensuring that websites and web applications are performing well.', 'While a degree in Business, Marketing, or a related field is often preferred, experience in customer service or sales, along with hands-on experience with CRM tools, can also provide an entry point into this role.', 'Tools typically used include market research platforms like Nielsen, Google Analytics for website data, CRM software like Salesforce, and project management tools like Asana or Trello.', 'The possible positions for Statistics and Data Analysis and Statistical Computation are: Database Administrator (DBA). Key responsibilities include: Database Design & Development, SQL Query Optimization, Data Integrity & Security, BI Solutions Development, ETL Process Implementation, Database Maintenance, Backup & Restore Management, Index Rebuilding & Performance Tuning, SQL Server Clustering & High Availability, SQL Server Replication, High Availability Group Management, Database Monitoring & Troubleshooting', 'Franchise Managers typically use franchise management software, scheduling tools, POS systems, customer relationship management (CRM) systems, and business reporting tools like Excel or Google Sheets.', 'Entry-level requirements typically include a Bachelor’s degree or completion of a legal assistant certification program. Some positions may accept candidates with relevant experience or internships in the legal field.', 'To start, focus on obtaining a relevant degree (e.g., Robotics, Mechanical Engineering, Electrical Engineering) and gain hands-on experience with robotic systems, programming, and hardware design through internships or personal projects.', \"A bachelor's or master's degree in fields like Computer Science, Statistics, Mathematics, or Data Science is typically required.\", 'The possible positions for B.E. (Computers) are: Asst. Manager/ Manger (Administrative) with an experience requirement of At least 5 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'The possible positions for N/A are: Manager- Human Resource Management (HRM)\\n. Key responsibilities include: Recruitment Coordination, Appointment Management, Selection Criteria, Employee Orientation, Performance Evaluation, HR Database Management, Report Compilation, Documentation, Event Coordination, Task Execution', 'The possible positions for BSc and MSc are: Senior iOS Engineer with an experience requirement of At least 4 years. The related skills are NLP, ML and Amazon Comprehend Medical API', 'The possible positions for B.E. (Computers) are: Senior Software Engineer with an experience requirement of At least 1 year. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'The main responsibilities include analyzing social media data, tracking engagement metrics, developing reports, identifying trends and insights, monitoring online conversations, managing social media campaigns, and helping to optimize social media strategies.', 'Business Intelligence Analysts typically use BI tools like Power BI, Tableau, and QlikView for data visualization and reporting. They also use SQL-based tools for data querying and may use Excel for data manipulation.', 'Skills include a strong understanding of cloud platforms (AWS, Azure, Google Cloud), knowledge of cloud migration processes, familiarity with security practices, and problem-solving skills in the context of cloud infrastructure.', 'Essential skills include effective leadership, customer service, inventory management, staff training, sales strategies, and proficiency with point-of-sale (POS) systems.', 'Daily tasks include reviewing ad performance, working with the creative team on ad design, preparing reports, managing budgets for campaigns, and ensuring all ads are properly placed on the chosen platforms.', 'The average salary for a Policy Advisor typically ranges from $50,000 to $75,000 annually, depending on experience, location, and the specific employer.', 'Cloud Database Engineers work for tech companies, cloud service providers, consulting firms, and large enterprises that rely on cloud-based database solutions. Many work remotely or in hybrid environments.', 'Data Visualization Specialists often face challenges related to data quality, such as incomplete or messy data, and ensuring that visualizations are intuitive, meaningful, and aligned with business goals.', 'Business Analysts work in a variety of industries, including finance, healthcare, IT, manufacturing, and consulting. They can be employed in both large corporations and smaller companies.', 'A typical day involves preparing and filing legal documents, conducting legal research, organizing case files, assisting lawyers with trial preparation, and communicating with clients or witnesses. They may also attend meetings and hearings.', \"The possible positions for Bachelor of Business Administration are: Project Coordinator (Civil) with an experience requirement of 5 to 10 years. The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router\", 'The possible positions for Bachelor of Science are: Data Science Engineer with an experience requirement of At least 2 years. The related skills are Creating dashboards for sales and profits', 'A typical day involves designing automation processes, writing and testing scripts, debugging automation systems, collaborating with developers, and monitoring automated workflows to ensure they run efficiently.', 'A typical day includes overseeing operations, managing resources, tracking performance metrics, analyzing processes for efficiency, coordinating between departments, and handling any operational issues that arise.', 'A Claims Adjuster reviews and processes insurance claims by assessing the damages, interviewing claimants and witnesses, conducting investigations, and determining the payout based on the insurance policy terms and the extent of the loss.'], 'precision': 0.5895230770111084, 'recall': 0.7295581102371216, 'f1': 0.6497299075126648}\n"
     ]
    }
   ],
   "source": [
    "# LoRA Q5_K_M gguf model bertscore\n",
    "results = evaluate_llama_bertscore(model_path=\"./quantized_models/ft-q5_k_m-lora.gguf\", dataset=small_test,)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (1024) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "Generating responses: 100%|██████████| 50/50 [56:11<00:00, 67.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': ['A Bachelor of Engineering (B.E.) in Computers can lead to a wide range of career opportunities. Here are some positions you can consider:\\n\\n1. **Software Engineer**: Design, develop, and test software applications for various industries, including gaming, finance, healthcare, and more.\\n2. **IT Project Manager**: Oversee the planning, execution, and delivery of IT projects, ensuring they meet deadlines and budget requirements.\\n3. **Network Administrator**: Install, configure, and maintain computer networks, ensuring secure and efficient data transfer.\\n4. **Database Administrator**: Design, implement, and manage databases to store and retrieve data for various organizations.', 'A Bachelor of Business Administration (BBA) degree is a versatile degree that can lead to various career opportunities across different industries. Here are some positions you can apply for with a BBA degree:\\n\\n1. **Management Trainee**: Many companies offer management trainee programs for recent graduates, which provide on-the-job training and development opportunities.\\n2. **Operations Manager**: Oversee daily operations, manage teams, and optimize processes in various sectors like manufacturing, logistics, or services.\\n3. **Financial Analyst**: Analyze financial data, prepare reports, and make recommendations to help organizations make informed business decisions.\\n4. **Marketing Coordinator**: Assist with', \"The entry-level requirements for a claims adjuster typically include:\\n\\n1. **Education:**\\n\\t* A high school diploma or equivalent is usually the minimum educational requirement.\\n\\t* Many employers prefer candidates with a bachelor's degree in a related field, such as business, insurance, or a related field.\\n2. **Licensing and Certification:**\\n\\t* In the United States, most states require claims adjusters to be licensed. Requirements for licensure vary by state, but typically involve passing an exam administered by the National Association of Insurance Commissioners (NAIC) or the International Association of Adjusters (IAA).\\n\\t* Some employers may\", \"With your major in Computer Applications and skills in Data Analysis, Machine Learning, Data Mining, Natural Language Processing, and programming skills like R, Python, MySQL, Excel, SPSS, Tableau, you have a versatile skill set that can be applied to various roles. Here are some job positions that may match your interests and expertise:\\n\\n1. **Data Analyst**: You'll work with data to identify trends, create reports, and visualize insights for businesses or organizations.\\n2. **Business Intelligence Developer**: You'll design and develop data visualization tools and business intelligence solutions using Tableau, Excel, and R.\\n3. **Data Scientist**: In\", 'A Bachelor of Technology (B.Tech) degree is a versatile degree that can lead to various career opportunities in multiple fields. Here are some potential positions you can consider applying for:\\n\\n**Engineering Fields:**\\n\\n1. Software Engineer\\n2. Mechanical Engineer\\n3. Electrical Engineer\\n4. Civil Engineer\\n5. Chemical Engineer\\n6. Aerospace Engineer\\n7. Biomedical Engineer\\n8. Computer Hardware Engineer\\n9. Networking Engineer\\n10. Telecommunications Engineer\\n\\n**IT and Data Science:**\\n\\n1. Data Analyst\\n2. Data Scientist\\n3. IT Project Manager\\n4. Business Analyst\\n5. Cybersecurity Specialist', \"A Claims Adjuster is typically employed in an office or field setting, and their work environment can vary depending on the type of claims they are adjusting. Here's a general overview of what a Claims Adjuster can expect:\\n\\n**Office Environment:**\\n\\n* Typically works in an insurance company's office, either as a full-time employee or as a contractor\\n* May work in a cubicle or private office with computer and phone equipment\\n* Often interacts with colleagues, supervisors, and other stakeholders to discuss claims and resolve issues\\n* May spend time reviewing documents, conducting research, and communicating with policyholders, witnesses, and medical professionals\\n\\n**Field\", 'Business Intelligence (BI) Analysts are in high demand across various industries, and many types of companies hire them. Here are some examples:\\n\\n1. **Financial Institutions**: Banks, investment firms, insurance companies, and other financial institutions need BI analysts to analyze financial data and provide insights that inform business decisions.\\n2. **Consulting Firms**: Management consulting firms, strategy consulting firms, and IT consulting firms often hire BI analysts to help clients improve their business performance.\\n3. **Retail Companies**: Retailers use BI analytics to optimize inventory management, sales forecasting, customer behavior analysis, and supply chain optimization.\\n4. **Healthcare Organizations**:', 'Many types of companies hire AI software engineers, including:\\n\\n1. **Technology and software companies**: Companies like Google, Microsoft, Amazon, Facebook, and Apple often have large AI research and development teams.\\n2. **Finance and banking institutions**: Financial institutions like JPMorgan Chase, Goldman Sachs, and Citigroup invest heavily in AI to improve their trading platforms, risk management systems, and customer service.\\n3. **Healthcare companies**: Companies like IBM, Optum (UnitedHealth Group), and Athenahealth develop AI-powered medical diagnosis tools, patient engagement platforms, and personalized medicine solutions.\\n4. **Automotive companies**: Automakers like General', 'As a B.Tech holder, you have a wide range of career opportunities across various fields. Here are some potential positions you can consider:\\n\\n**Engineering Fields:**\\n\\n1. Software Engineer: You can work on software development, testing, and maintenance for various industries.\\n2. Mechanical Engineer: Design, develop, and test mechanical systems, machines, and devices.\\n3. Electrical Engineer: Work on electrical systems, electronics, and electromagnetism.\\n4. Civil Engineer: Design and oversee construction projects, ensuring safety and functionality.\\n5. Computer Science and IT:\\n\\t* Data Scientist\\n\\t* Artificial Intelligence/Machine Learning Engineer\\n\\t*', 'A Social Media Analyst is a professional responsible for analyzing and interpreting data from social media platforms to help organizations make informed decisions about their online presence, marketing strategies, and overall business performance. Here are some of the daily tasks that a Social Media Analyst may perform:\\n\\n1. **Monitoring social media channels**: They track and monitor social media platforms such as Facebook, Twitter, Instagram, LinkedIn, YouTube, and others to stay up-to-date on brand mentions, customer engagement, and industry trends.\\n2. **Data analysis**: They collect and analyze data from social media metrics tools such as engagement rates, follower growth, sentiment analysis, and click-through rates (', 'A software engineer can expect to work in a variety of environments, depending on their specialization and industry. Here are some common work environments for software engineers:\\n\\n1. **Office setting**: Most software engineers work in an office environment with a computer, internet connection, and other necessary tools.\\n2. **Development teams**: Software engineers often work in teams with other developers, designers, and project managers to collaborate on projects.\\n3. **Remote work**: Many companies now allow remote work, which can provide flexibility and work-life balance for software engineers.\\n4. **Startups**: Startups often have a fast-paced and dynamic environment where software engineers are expected', 'The average salary for a Product Manager can vary widely depending on factors such as location, industry, company size, experience, and specific job requirements. Here are some approximate average salary ranges for Product Managers in the United States:\\n\\n1. Entry-level Product Managers (0-3 years of experience):\\n   - Average salary: $80,000 - $110,000 per year\\n\\n2. Mid-level Product Managers (4-7 years of experience):\\n   - Average salary: $110,000 - $140,000 per year\\n\\n3. Senior Product Managers (8-12 years of experience):\\n   - Average salary: $140,000', 'The salary range for a Junior Digital Marketing Manager can vary depending on factors such as location, industry, company size, experience, and specific job requirements. However, based on national averages in the United States, here are some approximate salary ranges for a Junior Digital Marketing Manager:\\n\\n**National Average Salaries (USA):**\\n\\n* According to Indeed.com: $55,000 - $75,000 per year\\n* According to Glassdoor.com: $50,000 - $70,000 per year\\n* According to Payscale.com: $52,000 - $72,000 per year\\n\\n**Salary Ranges by Industry:**\\n\\n*', 'With a degree in B.Tech. (Electrical Engineering Specialization in Computer Science) and a strong foundation in 12th grade mathematics and science, you have a solid base for exploring various career opportunities. Here are some positions you can consider:\\n\\n**IT and Technology**\\n\\n1. Software Engineer: With your electrical engineering background, you can work on designing and developing software applications, systems, or tools.\\n2. IT Project Manager: You can oversee the planning, execution, and delivery of IT projects, ensuring they meet their goals and timelines.\\n3. Network Administrator: Manage computer networks, including local area networks (LANs), wide area', 'A successful QA Engineer should possess a combination of technical, soft, and business skills. Here are some essential skills for a QA Engineer:\\n\\n**Technical Skills:**\\n\\n1. Programming languages: Knowledge of one or more programming languages such as Java, Python, C#, JavaScript, or Ruby.\\n2. Automated testing frameworks: Familiarity with testing frameworks like JUnit, TestNG, PyUnit, or Jest.\\n3. Testing tools: Experience with testing tools like Selenium, Appium, Postman, or JMeter.\\n4. Agile methodologies: Understanding of agile development methodologies like Scrum, Kanban, or Lean.\\n5. Cloud platforms', \"A typical job description for an Operations Executive typically involves overseeing the day-to-day activities and operations of a company or department. Here's a comprehensive overview:\\n\\n**Key Responsibilities:**\\n\\n1. **Strategic Planning**: Develops and implements operational strategies to achieve business objectives, aligning with the organization's overall mission and vision.\\n2. **Team Management**: Supervises and manages cross-functional teams, including assigning tasks, setting goals, and evaluating performance.\\n3. **Process Improvement**: Analyzes and optimizes business processes, identifying areas for improvement and implementing changes to increase efficiency, productivity, and quality.\\n4. **Risk Management**: Identifies,\", 'A Bachelor of Engineering degree provides a solid foundation in mathematics, science, and engineering principles, making you eligible for various career opportunities. Here are some potential job positions you can apply for with a degree in Engineering:\\n\\n**Traditional Engineering Fields:**\\n\\n1. **Mechanical Engineer**: Designs, develops, and tests mechanical systems, such as engines, machines, and mechanisms.\\n2. **Electrical Engineer**: Develops and implements electrical systems, including electronics, circuits, and electromagnetism.\\n3. **Civil Engineer**: Plans, designs, and constructs infrastructure projects like roads, bridges, buildings, and water treatment plants.\\n4. **Chemical', 'A Bachelor of Business Administration (BBA) degree can lead to a wide range of career opportunities in various fields. Here are some potential positions you can consider:\\n\\n1. Management Trainee: Many companies hire management trainees with BBA degrees, providing on-the-job training and development.\\n2. Marketing Coordinator: You can work in marketing teams, assist in campaign planning, and execute marketing strategies.\\n3. Financial Analyst: Use your analytical skills to analyze financial data, forecast trends, and make informed business decisions.\\n4. Human Resources Generalist: Oversee HR tasks such as recruitment, employee relations, benefits administration, and more.\\n5.', \"A Sustainability Consultant is a professional who helps organizations develop and implement sustainable practices to reduce their environmental impact. The daily tasks of a Sustainability Consultant may vary depending on the organization, industry, and specific project requirements. However, here are some common daily tasks that a Sustainability Consultant may perform:\\n\\n1. **Stakeholder Engagement**: Building relationships with stakeholders, including employees, customers, suppliers, and community members to understand their concerns and expectations related to sustainability.\\n2. **Data Analysis**: Collecting and analyzing data on an organization's environmental impact, energy consumption, water usage, waste management, and other relevant metrics.\\n3. **Conducting Aud\", \"Based on your skills in Statistics and Python, as well as Web Scraping, Power BI, Data Cleaning, Data Preparation, Data Analysis, Predictive Modeling, Data Analytics, Pivot Table, SQL, PostgreSQL, Excel, Machine Learning, and XML, here are some potential career positions that you may be a good fit for:\\n\\n1. **Data Analyst**: As a data analyst, you'll work with various tools like Power BI, Excel, and SQL to analyze and interpret complex data sets, creating reports and visualizations to inform business decisions.\\n2. **Business Intelligence Developer**: In this role, you'll design, develop, and maintain data\", 'With a Bachelor of Science degree, you have a versatile foundation in various fields that can lead to numerous career opportunities. Here are some potential positions you can consider:\\n\\n1. **Research Assistant**: Many industries, such as academia, government, and private companies, hire research assistants to assist with data collection, analysis, and experimentation.\\n2. **Data Analyst**: Your analytical skills can be applied in various fields like business, finance, healthcare, or environmental science, helping organizations make informed decisions with data-driven insights.\\n3. **Environmental Scientist**: Apply your knowledge of natural sciences to work on projects related to conservation, sustainability, and environmental policy.\\n4', 'With a degree in Bachelor of Engineering (B.E.) in Computer Science or related fields, you have a wide range of job opportunities across various industries. Here are some potential positions you can consider:\\n\\n1. **Software Engineer**: Design, develop, test, and maintain software applications, systems, and tools.\\n2. **Web Developer**: Create web applications, websites, and mobile apps using programming languages like HTML, CSS, JavaScript, and frameworks like React or Angular.\\n3. **Data Analyst/Scientist**: Work with data to identify trends, create predictive models, and visualize insights to inform business decisions.\\n4. **IT Project Manager**:', \"The entry-level requirements for a Media Buyer typically include:\\n\\n1. **Education:** A bachelor's degree in Marketing, Communications, Business, or a related field is often preferred.\\n2. **Experience:** 0-2 years of experience in media buying, advertising sales, or a related field can be beneficial.\\n3. **Skills:**\\n\\t* Strong understanding of the media landscape and industry trends\\n\\t* Analytical and problem-solving skills to optimize media campaigns\\n\\t* Excellent communication and negotiation skills to work with clients and vendors\\n\\t* Ability to manage multiple projects and prioritize tasks effectively\\n\\t* Proficiency in media planning and buying\", \"The daily tasks of a web developer can vary depending on the specific job requirements, industry, and company. However, here are some common daily tasks that web developers typically perform:\\n\\n1. **Code Writing**: Web developers spend most of their time writing clean, efficient, and well-structured code in languages like HTML, CSS, JavaScript, PHP, Ruby, Python, or other server-side programming languages.\\n2. **Design and Prototyping**: Developers may work on designing user interfaces (UI), creating wireframes, mockups, and prototypes to visualize the website's layout, navigation, and visual elements.\\n3. **Front-end Development**:\", 'While a degree is not always necessary to become a Customer Relationship Manager (CRM), it can be beneficial in several ways. Here are some points to consider:\\n\\nPros of having a degree for a CRM role:\\n\\n1. **Foundational knowledge**: A degree in a field like business, marketing, or communications can provide a solid foundation in principles such as customer service, market research, and data analysis.\\n2. **Enhanced skills**: A degree program can help you develop essential skills like communication, problem-solving, and leadership, which are valuable for CRM roles.\\n3. **Competitive advantage**: Having a degree from an accredited institution may give you', \"A Junior Market Development Manager typically uses a variety of tools to perform their job responsibilities, including:\\n\\n1. **Market research software**:\\n\\t* Google Trends: to analyze market trends and identify potential opportunities.\\n\\t* Ahrefs: to analyze competitors' websites and online presence.\\n\\t* SEMrush: to track keyword rankings and competitor analysis.\\n2. **Salesforce.com**: a customer relationship management (CRM) platform to manage sales leads, contacts, and accounts.\\n3. **Microsoft Office Suite**:\\n\\t* Excel: for data analysis and spreadsheet management.\\n\\t* PowerPoint: for presentations and pitch decks.\\n\\t* Word: for\", \"Based on your major in Statistics and Data Analysis and Statistical Computation, along with your skills in Data Analysis, Business Analysis, Statistical Analysis, Regression Analysis, Natural Language Processing, Machine Learning, and Numerical Analysis, here are some potential career positions you may be well-suited for:\\n\\n1. **Data Scientist**: As a data scientist, you'll work with large datasets to extract insights and make informed decisions. Your skills in machine learning, regression analysis, and statistical analysis will be valuable assets.\\n2. **Business Analyst (Data-Driven)**: With your analytical mindset and business acumen, you can help organizations make data-driven decisions by\", 'A Franchise Manager typically uses a variety of tools to manage their franchise operations, including:\\n\\n1. **Franchise Disclosure Document (FDD)**: A comprehensive document that outlines the terms and conditions of the franchise agreement.\\n2. **Franchise Agreement**: The contract between the franchisor and franchisee, outlining the terms and obligations of the relationship.\\n3. **Operations Manual**: A guide outlining standard operating procedures for the franchise system, including marketing, sales, and customer service.\\n4. **Financial Management Software**: Tools such as QuickBooks, Xero, or other accounting software to manage financial transactions, track expenses, and prepare tax returns', \"The entry-level requirements for a Legal Assistant, also known as a Paralegal or Legal Secretary, may vary depending on the employer, industry, and location. However, here are some common requirements:\\n\\n**Education:**\\n\\n1. Associate's degree in paralegal studies or a related field (e.g., business, law, or communications) is often preferred.\\n2. Some employers may require a high school diploma or equivalent with relevant work experience.\\n\\n**Skills:**\\n\\n1. Strong computer skills, including proficiency in Microsoft Office Suite (Word, Excel, Outlook, etc.) and other software specific to the industry.\\n2. Organizational and\", \"Starting a career as a robotics engineer can be an exciting and rewarding path. Here's a step-by-step guide to help you get started:\\n\\n**Education**\\n\\n1. **Earn a Bachelor's or Master's degree in Robotics Engineering**: A bachelor's degree in mechanical engineering, electrical engineering, computer science, or mechatronics is typically required for a career as a robotics engineer.\\n2. **Consider online courses and certifications**: Online courses and certifications can help you gain specific skills and knowledge in areas like programming, machine learning, and robotic vision.\\n\\n**Gain Practical Experience**\\n\\n1. **Internships**: Participate in internships to work on robotics\", \"To become a data scientist, you'll typically need a combination of academic qualifications and skills in the following areas:\\n\\n**Academic Qualifications:**\\n\\n1. Bachelor's degree in a quantitative field such as:\\n\\t* Mathematics\\n\\t* Statistics\\n\\t* Computer Science\\n\\t* Engineering (e.g., Electrical, Mechanical)\\n\\t* Economics\\n\\t* Physics\\n2. Master's degree or Ph.D. in Data Science, Machine Learning, or related fields is often preferred for advanced roles.\\n\\n**Key Skills:**\\n\\n1. **Programming skills:**\\n\\t* Python, R, or SQL programming languages\\n\\t* Familiarity with\", 'With a degree in Bachelor of Engineering (B.E.) in Computers, you have a wide range of job opportunities across various industries. Here are some potential positions to consider:\\n\\n1. **Software Engineer**: Design, develop, and test software applications for various platforms, including mobile devices, web applications, and operating systems.\\n2. **IT Project Manager**: Oversee the planning, execution, and delivery of IT projects, ensuring they are completed on time, within budget, and meet customer requirements.\\n3. **Network Administrator**: Install, configure, and maintain computer networks, including local area networks (LANs), wide area networks (WANs', 'Based on your major in N/A (which I\\'ll assume is not a traditional major, but rather an \"N/A\" or null/unknown) and your skills in Business Analyst, Data Analysis, Machine Learning, Tableau, Seaborn, Python, R, AWS, and NodeJS, here are some potential career positions that you may be well-suited for:\\n\\n1. **Data Scientist**: With your technical skills in Python, R, Tableau, and data analysis tools, you could work as a Data Scientist, focusing on developing predictive models, analyzing large datasets, and creating data visualizations.\\n2. **Business Intelligence Analyst', 'Having a degree in both BSc (Bachelor of Science) and MSc (Master of Science) opens up a wide range of career opportunities across various fields. Here are some potential positions you can apply for:\\n\\n**Academia:**\\n\\n1. Research Scientist: Conduct research, collect data, and analyze results in universities, research institutions, or private companies.\\n2. Professor/Lecturer: Teach and conduct research at universities, colleges, or online institutions.\\n3. Science Writer/Editor: Write articles, books, or create content for science publications, websites, or companies.\\n\\n**Industry:**\\n\\n1. Product Development Manager: Oversee', 'A degree in Bachelor of Engineering (B.E.) in Computer Science or related fields can open doors to various job opportunities. Here are some potential positions you can consider:\\n\\n1. **Software Engineer**: Design, develop, and test software programs for a wide range of industries, including gaming, finance, healthcare, and more.\\n2. **Data Analyst/Scientist**: Analyze data to identify trends, create models, and inform business decisions in various sectors such as finance, marketing, or operations.\\n3. **Network Administrator**: Install, configure, and maintain computer networks for organizations, ensuring smooth communication and data transfer between devices.\\n4. **', \"A Social Media Analyst is responsible for monitoring, analyzing, and reporting on social media data to help organizations understand their online presence, engagement, and performance. The main responsibilities of a Social Media Analyst typically include:\\n\\n1. **Content Creation and Curation**: Developing, scheduling, and publishing content on various social media platforms to engage with the target audience.\\n2. **Data Analysis**: Collecting, analyzing, and interpreting data from social media metrics such as engagement rates, follower growth, reach, and conversion rates.\\n3. **Social Media Monitoring**: Tracking brand mentions, trending topics, and keywords related to the organization's industry and competitors.\\n4.\", 'A Business Intelligence (BI) Analyst typically uses a variety of tools to analyze data, create reports, and visualize insights. Here are some common tools used by BI analysts:\\n\\n**Data Analysis and Visualization Tools:**\\n\\n1. **Tableau**: A popular data visualization tool for creating interactive dashboards and reports.\\n2. **Power BI**: A business analytics service by Microsoft that provides interactive visualizations and business intelligence capabilities.\\n3. **QlikView**: An in-memory analytics platform for creating interactive dashboards and reports.\\n4. **Sisense**: A cloud-based business intelligence platform for data visualization, reporting, and analysis.\\n5. **', \"To become a cloud consultant, you'll need a combination of technical, business, and soft skills. Here are some of the key skills required:\\n\\n**Technical Skills:**\\n\\n1. **Cloud Computing Fundamentals**: Understanding of cloud computing models (IaaS, PaaS, SaaS), cloud service providers (AWS, Azure, Google Cloud), and cloud security.\\n2. **Cloud Migration and Deployment**: Knowledge of migration strategies, deployment methods, and tools for moving applications to the cloud.\\n3. **Cloud Architecture**: Understanding of cloud architecture principles, including scalability, availability, and performance.\\n4. **Cloud Security**: Familiarity with cloud\", 'A successful retail manager possesses a combination of skills that enable them to lead, motivate, and manage a team to drive sales growth, improve customer satisfaction, and maintain operational efficiency. Here are some essential skills for a retail manager:\\n\\n1. **Leadership**: The ability to inspire and motivate employees to achieve their full potential.\\n2. **Communication**: Excellent verbal and written communication skills to effectively interact with customers, employees, and stakeholders.\\n3. **Customer Service**: Providing exceptional customer service to ensure high levels of customer satisfaction and loyalty.\\n4. **Sales and Merchandising**: Understanding of retail operations, including sales strategies, inventory management, and', 'As a Junior Advertising Manager, the daily tasks may vary depending on the company, industry, and specific job requirements. However, here are some common daily tasks that a Junior Advertising Manager might be responsible for:\\n\\n1. **Project Management**: Assist in planning, coordinating, and executing advertising campaigns across various channels (e.g., social media, email, print, digital).\\n2. **Campaign Planning**: Help develop campaign concepts, objectives, and strategies in collaboration with the account team.\\n3. **Creative Development**: Work with designers and copywriters to develop ad creative assets (e.g., images, videos, copy) that meet client requirements.\\n4', 'The average salary for a Policy Advisor can vary widely depending on factors such as location, industry, level of experience, and specific job duties. However, based on national averages in the United States, here are some approximate salary ranges for Policy Advisors:\\n\\n1. Entry-level Policy Advisors (0-3 years of experience):\\n   - Median salary: $50,000 - $70,000 per year\\n   - Starting salary: $40,000 - $60,000 per year\\n\\n2. Mid-level Policy Advisors (4-7 years of experience):\\n   - Median salary: $80,000 - $110,000 per year', 'Cloud database engineers typically work in a variety of settings, including:\\n\\n1. Cloud provider offices: Many cloud database engineers work directly for the companies that provide cloud infrastructure, such as Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform (GCP), or IBM Cloud.\\n2. Cloud consulting firms: Companies like Accenture, Deloitte, and Ernst & Young have large teams of cloud database engineers who help clients design, implement, and manage their cloud-based databases.\\n3. IT departments: Many organizations with in-house IT departments employ cloud database engineers to manage their own cloud infrastructure and databases.\\n4. Startups: Cloud database engineers', 'Data Visualization Specialists face several difficulties in their jobs, including:\\n\\n1. **Balancing Creativity and Technicality**: Data visualization requires a combination of artistic skills (creativity) and technical skills (programming languages, data analysis tools). Finding the right balance between these two aspects can be challenging.\\n\\n2. **Interpreting Complex Data**: Data Visualization Specialists need to interpret complex data sets, identify patterns, and communicate insights effectively. This can be difficult when dealing with large amounts of data, ambiguous relationships, or unclear business requirements.\\n\\n3. **Communicating Insights Effectively**: The goal of data visualization is to convey complex information in a clear and', 'Business Analysts can work in a variety of settings, including:\\n\\n1. **Corporations**: Many Business Analysts work for large corporations, such as banks, technology companies, and retail organizations.\\n2. **Consulting firms**: Management consulting firms, IT consulting firms, and strategy consulting firms often employ Business Analysts to help clients improve their operations and solve business problems.\\n3. **Government agencies**: Government agencies, such as federal, state, or local governments, may hire Business Analysts to analyze and improve government programs and services.\\n4. **Non-profit organizations**: Non-profit organizations, such as charities and foundations, also employ Business', \"A typical day for a Legal Assistant, also known as a paralegal or legal secretary, can vary depending on the specific job, work environment, and industry. However, here's an overview of common tasks and responsibilities:\\n\\n**Morning Routine:**\\n\\n* Arrive at the office, check emails and voicemails for new messages\\n* Review daily schedules and prioritize tasks\\n* Check the organization's calendar to confirm appointments and meetings\\n* Respond to any urgent emails or phone calls\\n\\n**Core Responsibilities:**\\n\\n1. **Document Preparation**: Assist attorneys in preparing documents, such as:\\n\\t* Drafting and editing contracts, pleadings,\", 'With a Bachelor of Business Administration (BBA) degree, you have a wide range of career opportunities across various industries. Here are some potential positions you can consider:\\n\\n1. **Management Trainee**: Many companies offer management training programs for recent graduates with a BBA degree.\\n2. **Business Analyst**: Analyze data to help organizations make informed business decisions and improve operations.\\n3. **Marketing Manager**: Develop and implement marketing strategies to promote products or services.\\n4. **Financial Analyst**: Assist in financial planning, budgeting, and forecasting for companies.\\n5. **Operations Manager**: Oversee daily operations, including managing staff, inventory,', 'With a Bachelor of Science (BSc) degree, you have a versatile foundation in various fields. Here are some potential job positions across different industries:\\n\\n**STEM Fields:**\\n\\n1. Research Assistant\\n2. Data Analyst\\n3. Laboratory Technician\\n4. Quality Control Specialist\\n5. Environmental Scientist\\n6. Biotechnologist\\n7. Computer Science Graduate (with additional certifications or experience)\\n8. IT Project Coordinator\\n\\n**Business and Finance:**\\n\\n1. Business Analyst\\n2. Operations Manager\\n3. Marketing Assistant\\n4. Financial Analyst\\n5. Management Trainee\\n6. Human Resources Generalist\\n7. Supply Chain', \"A typical day for an Automation Engineer can vary depending on the industry, company, and specific job role. However, here's a general idea of what a typical day might look like:\\n\\n**Morning Routine**\\n\\n* Arrival at work, check emails and respond to any urgent messages\\n* Review the day's schedule and prioritize tasks based on urgency and importance\\n* Attend a morning meeting with team members or stakeholders to discuss ongoing projects and plan for the day\\n\\n**Design and Development**\\n\\n* Spend most of the day designing, developing, and testing automation scripts, programs, or systems\\n* Work with various tools such as programming languages (e.g.,\", \"A typical day for an Operations Executive can vary depending on the industry, company size, and specific responsibilities. However, here's a general idea of what a typical day might look like:\\n\\n**Morning Routine (8:00 am - 9:00 am)**\\n\\n* Check emails and respond to any urgent messages\\n* Review daily schedules, meetings, and deadlines for the day\\n* Review key performance indicators (KPIs) and metrics related to operations\\n* Plan out tasks and prioritize them based on urgency and importance\\n\\n**Operational Tasks (9:00 am - 12:00 pm)**\\n\\n* Manage and coordinate with various\", \"A Claims Adjuster is a professional responsible for evaluating, investigating, and settling insurance claims for individuals or organizations. Here's a comprehensive job description:\\n\\n**Key Responsibilities:**\\n\\n1. **Claims Investigation**: Conduct thorough investigations into insurance claims to determine the validity and extent of damages or losses.\\n2. **Policy Review**: Analyze policies, contracts, and other relevant documents to understand coverage terms, exclusions, and limitations.\\n3. **Interviews and Reporting**: Interview policyholders, witnesses, and other parties involved in the claim, gather information, and document findings.\\n4. **Damage Assessment**: Assess damage or loss, determine its cause,\"], 'references': ['The possible positions for B.E. (Computers) are: Mechanical Designer with an experience requirement of At least 5 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', \"The possible positions for Bachelor of Business Administration are: Site Engineer with an experience requirement of 1 to 2 years. The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router\", 'Entry-level requirements typically include a high school diploma, some college education or relevant certifications, and a state-issued license. Experience in customer service or insurance is a plus.', 'The possible positions for Computer Applications and Computer Applications are: Senior Software Engineer. Key responsibilities include: Technical Support, Troubleshooting, Collaboration, Documentation, System Monitoring, Software Deployment, Training & Mentorship, Industry Trends, Field Visits', 'The possible positions for B.Tech are: Asst. Manager/ Manger (Administrative) with an experience requirement of At least 5 years. The related skills are Testing, Debugging and Parameter Tuning', 'Claims Adjusters usually work in office environments but may also spend time in the field conducting investigations, meeting with claimants, or inspecting damaged properties. Some positions may offer remote work options.', 'Companies that rely heavily on data-driven decision-making, such as tech companies, financial institutions, retail businesses, and healthcare organizations, hire Business Intelligence Analysts.', 'Tech companies, AI startups, large corporations with AI needs, financial institutions, healthcare organizations, and research labs commonly hire AI Software Engineers.', 'The possible positions for B.Tech are: Data Engineer with an experience requirement of 5 to 8 years. The related skills are NLP and Data Analysis', 'On a daily basis, a Social Media Analyst monitors social media platforms, tracks key performance indicators (KPIs), compiles data into reports, engages with social media teams to optimize strategies, and analyzes trends to guide future campaigns.', 'Software Engineers often work in collaborative environments with other developers, product managers, and designers, with opportunities for remote or in-office work depending on the company.', 'The average salary for an entry-level Product Manager ranges from $60,000 to $90,000 per year, depending on experience and location.', 'The salary range for a Junior Digital Marketing Manager typically falls between $45,000 and $65,000 annually, with senior roles or positions in larger companies offering higher salaries.', 'The possible positions for B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X are: System Administrator (Operation & Maintenance of Server, Storage & Service Desk System) with an experience requirement of 4 to 5 years. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, OCR, Pytesseract and NER Text Classification', 'Essential skills include expertise in manual and automated testing, proficiency with testing tools (like Selenium, QTP, JUnit), understanding of bug-tracking systems, and strong analytical and debugging skills.', \"An Operations Executive is responsible for ensuring that the company's day-to-day activities run efficiently. They monitor operational performance, optimize processes, and assist in resource management and problem-solving.\", 'The possible positions for Bachelor of Engineering are: Sr.Officer / Executive - Internal Audit with an experience requirement of 2 to 4 years. The related skills are Software Development and Application Programming', 'The possible positions for BBA are: Business Development Executive with an experience requirement of 1 to 3 years. The related skills are Data Analysis and Business Analysis', 'Daily tasks include reviewing environmental impact data, assessing energy usage and waste management practices, meeting with clients to discuss sustainability goals, preparing reports, and developing recommendations for improving sustainability efforts.', 'The possible positions for Statistics are: Network Support Engineer. Key responsibilities include: Mikrotik Router Configuration, OLT Device Setup & Management, Integration with Billing Software, Network Monitoring Tools Integration, Connectivity Troubleshooting, Technical Support & Escalation, Installation & Configuration, GPON/EPON Expertise, Cisco, OLT, MikroTik Knowledge', 'The possible positions for Bachelor of Science are: Senior Software Engineer with an experience requirement of At least 1 year. The related skills are Creating dashboards for sales and profits', 'The possible positions for B.E. (Computers) are: DevOps Engineer with an experience requirement of At least 3 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'Entry-level requirements typically include a Bachelor’s degree in Marketing, Advertising, or Communications, along with an understanding of media buying and advertising principles. Internships or hands-on experience in digital marketing can also be helpful.', 'Daily tasks include coding, testing new features, troubleshooting bugs, attending team meetings, reviewing code, and ensuring that websites and web applications are performing well.', 'While a degree in Business, Marketing, or a related field is often preferred, experience in customer service or sales, along with hands-on experience with CRM tools, can also provide an entry point into this role.', 'Tools typically used include market research platforms like Nielsen, Google Analytics for website data, CRM software like Salesforce, and project management tools like Asana or Trello.', 'The possible positions for Statistics and Data Analysis and Statistical Computation are: Database Administrator (DBA). Key responsibilities include: Database Design & Development, SQL Query Optimization, Data Integrity & Security, BI Solutions Development, ETL Process Implementation, Database Maintenance, Backup & Restore Management, Index Rebuilding & Performance Tuning, SQL Server Clustering & High Availability, SQL Server Replication, High Availability Group Management, Database Monitoring & Troubleshooting', 'Franchise Managers typically use franchise management software, scheduling tools, POS systems, customer relationship management (CRM) systems, and business reporting tools like Excel or Google Sheets.', 'Entry-level requirements typically include a Bachelor’s degree or completion of a legal assistant certification program. Some positions may accept candidates with relevant experience or internships in the legal field.', 'To start, focus on obtaining a relevant degree (e.g., Robotics, Mechanical Engineering, Electrical Engineering) and gain hands-on experience with robotic systems, programming, and hardware design through internships or personal projects.', \"A bachelor's or master's degree in fields like Computer Science, Statistics, Mathematics, or Data Science is typically required.\", 'The possible positions for B.E. (Computers) are: Asst. Manager/ Manger (Administrative) with an experience requirement of At least 5 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'The possible positions for N/A are: Manager- Human Resource Management (HRM)\\n. Key responsibilities include: Recruitment Coordination, Appointment Management, Selection Criteria, Employee Orientation, Performance Evaluation, HR Database Management, Report Compilation, Documentation, Event Coordination, Task Execution', 'The possible positions for BSc and MSc are: Senior iOS Engineer with an experience requirement of At least 4 years. The related skills are NLP, ML and Amazon Comprehend Medical API', 'The possible positions for B.E. (Computers) are: Senior Software Engineer with an experience requirement of At least 1 year. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'The main responsibilities include analyzing social media data, tracking engagement metrics, developing reports, identifying trends and insights, monitoring online conversations, managing social media campaigns, and helping to optimize social media strategies.', 'Business Intelligence Analysts typically use BI tools like Power BI, Tableau, and QlikView for data visualization and reporting. They also use SQL-based tools for data querying and may use Excel for data manipulation.', 'Skills include a strong understanding of cloud platforms (AWS, Azure, Google Cloud), knowledge of cloud migration processes, familiarity with security practices, and problem-solving skills in the context of cloud infrastructure.', 'Essential skills include effective leadership, customer service, inventory management, staff training, sales strategies, and proficiency with point-of-sale (POS) systems.', 'Daily tasks include reviewing ad performance, working with the creative team on ad design, preparing reports, managing budgets for campaigns, and ensuring all ads are properly placed on the chosen platforms.', 'The average salary for a Policy Advisor typically ranges from $50,000 to $75,000 annually, depending on experience, location, and the specific employer.', 'Cloud Database Engineers work for tech companies, cloud service providers, consulting firms, and large enterprises that rely on cloud-based database solutions. Many work remotely or in hybrid environments.', 'Data Visualization Specialists often face challenges related to data quality, such as incomplete or messy data, and ensuring that visualizations are intuitive, meaningful, and aligned with business goals.', 'Business Analysts work in a variety of industries, including finance, healthcare, IT, manufacturing, and consulting. They can be employed in both large corporations and smaller companies.', 'A typical day involves preparing and filing legal documents, conducting legal research, organizing case files, assisting lawyers with trial preparation, and communicating with clients or witnesses. They may also attend meetings and hearings.', \"The possible positions for Bachelor of Business Administration are: Project Coordinator (Civil) with an experience requirement of 5 to 10 years. The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router\", 'The possible positions for Bachelor of Science are: Data Science Engineer with an experience requirement of At least 2 years. The related skills are Creating dashboards for sales and profits', 'A typical day involves designing automation processes, writing and testing scripts, debugging automation systems, collaborating with developers, and monitoring automated workflows to ensure they run efficiently.', 'A typical day includes overseeing operations, managing resources, tracking performance metrics, analyzing processes for efficiency, coordinating between departments, and handling any operational issues that arise.', 'A Claims Adjuster reviews and processes insurance claims by assessing the damages, interviewing claimants and witnesses, conducting investigations, and determining the payout based on the insurance policy terms and the extent of the loss.'], 'precision': 0.49165579676628113, 'recall': 0.6417734026908875, 'f1': 0.5558791160583496}\n"
     ]
    }
   ],
   "source": [
    "# fp16 model - instruct base model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "results = evaluate_llama_bertscore_withChatTemplate(model_path=\"./quantized_models/fp16-ft-base.gguf\", dataset=small_test, tokenizer=tokenizer)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (1024) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "Generating responses: 100%|██████████| 50/50 [18:16<00:00, 21.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': ['The possible positions for B.E. (Computers) are: Marketing Manager - E-commerce/ Retail. The related skills are: NLP, Machine Learning, Deep learning, Python, R, TensorFlow, Keras, PyTorch, Scikit-learn. The related tools are: Keras, TensorFlow, PyTorch, Scikit-learn, NLTK, spaCy, pandas, NumPy, Matplotlib. The related technologies are: NLP, Machine Learning, Deep learning, Python, R, TensorFlow, Keras, PyTorch, Scikit-learn. The related software are: Jupyter Notebook, Google', 'The possible positions for Bachelor of Business Administration are: Sales Consultant. The related skills are Customer Relationship Building, Lead Generation & Execution, Client Communication, Market Research and Data Analysis. The likely responsibilities include Sales Strategy Development, Business Planning, Performance Tracking, Collaboration with Teams, Stakeholder Management, Team Leadership, Strategic Decision Making, Risk Assessment, Budgeting, Marketing Coordination, Operations Oversight, Inventory Management, Order Fulfillment, Customer Support, Employee Supervision, Inventory Control, Logistics, Supply Chain Management and Performance Review. The required skills are Communication Skills, Problem Solving, Time Management, Team Collaboration, Leadership, Business Planning, Decision Making', 'The entry-level requirements typically include a high school diploma or equivalent, completion of an apprenticeship program in insurance adjusting or related fields, and obtaining certifications such as the Certified Adjuster (CA) designation. Additionally, having some experience working in customer service, claims processing, or other related roles can be beneficial for new hires.', 'The possible positions for Computer Applications and Computer Applications are: Business Intelligence Analyst. Key responsibilities include: ETL Process, Data Mining, Reporting, Predictive Modeling, SQL Queries, Data Visualization with Tableau or Power BI. The required skills are: Knowledge of SQL, Python, R, Excel, Data Analysis, Machine Learning Algorithms, Data Visualization Tools, Database Management, ETL Processes, Statistical and Mathematical Techniques, Knowledge of Statistical Packages such as SPSS. Key responsibilities include: Business Analysis, Requirements Gathering, Data Analysis, Report Writing, Designing Database Models, Staying Updated with New Technologies and Tools, Troubleshooting Database Issues, Creating', 'The possible positions for B.Tech are: Junior Software Engineer with an experience requirement of 1 to 3 years. The related skills are: Business Intelligence, Cloud, Data Analysis, Data Science, Machine Learning, NLP, Python, R, SQL. Junior Software Engineer (Entry level) with an experience requirement of 1 to 3 years. The related skills are: Business Intelligence, Cloud, Data Analysis, Data Science, Machine Learning, NLP, Python, R, SQL. Executive with an experience requirement of At least 5 years. The related skills are: Business Analytics, Business Development, Business Strategy, Leadership, Market', 'A Claims Adjuster can expect to work in an office setting, often on-site at accident or property damage scenes. They may also spend time reviewing files, assessing damages, and communicating with clients and other parties involved in the claim process. Additionally, some positions may require travel for inspections or meetings.', 'Companies in various sectors, including retail, finance, healthcare, and technology, often hire Business Intelligence Analysts. These include: \\n\\n1. Retail companies to analyze customer data and sales trends.\\n2. Financial institutions for risk management and performance analysis.\\n3. Healthcare organizations for patient treatment outcomes and health metrics analysis.\\n4. Technology firms for product development based on market research insights.\\n5. Consulting firms that provide BI services to clients across different industries.', 'Companies in various industries, including tech startups and large corporations, hire AI Software Engineers. Some examples include: Google, Amazon, Microsoft, IBM, Apple, Facebook, Tesla, NVIDIA, and data analytics firms. These companies often require expertise in machine learning algorithms and deep learning for developing AI-powered applications.', 'The possible positions for B.Tech are: NLP Engineer with an experience requirement of 2 to 5 years. The related skills are Cloud Computing, AI/ML, Data Analysis and Machine Learning. NLP Engineer with an experience requirement of 1 to 3 years. The related skills are Data Analysis, Machine Learning and Data Mining. SEO Specialist with an experience requirement of 1 to 3 years. The related skills are Content Creation, Social Media Marketing and SEO Tools. E-learning Developer with an experience requirement of 2 to 5 years. The related skills are E-Learning Platforms, Course Development, Responsive Design and JavaScript', \"A Social Media Analyst's daily tasks include monitoring social media accounts, tracking engagement metrics, creating content calendars, responding to comments and messages, analyzing campaign performance, and providing insights for optimization. They also analyze trends and adjust the strategy accordingly.\", 'A Software Engineer typically works in an office setting with a team of colleagues, managers, and other stakeholders. They also spend time at client sites or on project meetings to discuss progress or resolve issues. The work environment can be fast-paced, with deadlines to meet, and collaboration required with designers, product managers, and QA engineers.', 'The average salary for a Product Manager varies based on factors like location, experience level, and industry. However, the average annual salary range for a Product Manager is typically between $100,000 and $150,000. Entry-level positions may start at around $60,000, while senior roles can exceed $160,000 annually.', 'The salary range for a Junior Digital Marketing Manager typically starts around $45,000 to $55,000 annually, depending on the company size and location. However, it can go up to $65,000 or more with experience.', 'The possible positions for B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X are: Assistant/ Associate Engineer - E&M ( Electrical & Mechanical) with an experience requirement of 2 to 4 years. The related skills are Business Development, Client Management, Project Coordination, Team Leadership, Technical Design, Operations Support, Process Improvement, Risk Management, Compliance, Regulatory Knowledge, Quality Control, Supply Chain Management, Inventory Control, Cost Accounting, Budgeting, Financial Planning, Procurement, Sourcing, Logistics, Warehouse Management, Inventory Tracking, Work Order Management, Equipment Maintenance, Troubleshooting, Repair, Replacement', 'The essential skills for a successful QA Engineer include strong analytical skills, attention to detail, excellent communication and problem-solving abilities. They must also be familiar with testing methodologies such as regression testing, unit testing, integration testing, system testing, performance testing, security testing, exploratory testing, black box testing, white box testing, gray box testing, acceptance testing, automated testing tools, and manual testing tools. Knowledge of cloud-based technologies is beneficial for working in cloud-based applications. Continuous learning to keep up with new technologies and methodologies is also important.', 'The job description for an Operations Executive typically involves overseeing the day-to-day operations of a company, managing logistics, ensuring efficient use of resources, and maintaining high levels of customer satisfaction. Key responsibilities include monitoring production schedules, inventory management, staff supervision, and implementing cost-saving initiatives. The role also requires effective communication with teams and stakeholders to ensure seamless execution of business strategies.', 'The possible positions for Bachelor of Engineering are: Civil Engineer. Key responsibilities include: Designing and planning infrastructure projects, conducting site inspections, overseeing construction processes, and managing budgets. The related skills are: Civil engineering principles, project management, design software, safety protocols, communication skills, and problem-solving abilities. Key tools used are: Autodesk Revit, AutoCAD, Microsoft Office, project management software, and safety equipment. The typical experience required is at least 5 years. The typical salary range for this role is $60,000 to $100,000 annually. Key accomplishments include: Successfully managed large-scale construction projects, reduced costs by', 'The possible positions for BBA are: Team Lead - Sales Operations. The related skills are Business Development, Customer Support, Data Management, Communication, Leadership, Time Management, Research, Problem Solving, Teamwork, Marketing, Event Planning, Project Coordination, Budgeting, Financial Analysis, Risk Assessment and Compliance, Human Resource Management, Performance Metrics and Monitoring, Inventory Management, Cost Control, Leadership, Supervision, Recruitment, Training, Employee Retention, Conflict Resolution, Strategic Planning, Quality Assurance, Operations Management, Sales Strategy, Customer Service, Business Development, Marketing Strategy, Event Coordination, Project Management, Budgeting, Financial Analysis,', 'The daily tasks of a Sustainability Consultant include conducting site assessments, developing sustainability reports and strategies, providing training on sustainable practices, analyzing environmental impacts, identifying opportunities for improvement, coordinating with stakeholders, and implementing projects to achieve sustainability goals.', 'The possible positions for Statistics are: IT Consultant. Key responsibilities include: Network Architecture Design, Network Troubleshooting, Network Performance Optimization, Network Security, Network Implementation, Network Migration, Network Monitoring, Network Maintenance, Network Configuration, Network Documentation, Network Testing, Network Integration, Network Support, Network Analysis, Network Scanning, Network Mapping, Network Topology, Network Security Testing, Network Penetration Testing, Network Vulnerability Assessment, Network Compliance, Network Policy Development, Network Change Management, Network Documentation, Network Troubleshooting, Network Performance Monitoring, Network Optimization, Network Configuration Management, Network Inventory, Network Backup and Recovery, Network Upgrade Planning, Network', 'The possible positions for Bachelor of Science are: Business Analyst with an experience requirement of At least 2 years. The related skills are Project Management, Data Analysis and Machine Learning. The possible salary range for Business Analyst is Rs 15 LPA to Rs 22 LPA.', 'The possible positions for B.E. (Computers) are: Junior Executive-Technical Support. The related skills are: Customer Service, Data Analysis, Business Operations, Technical Guidance, Team Management, Leadership, Marketing, Sales, Inventory Control, Product Knowledge, Compliance, Risk Assessment, Policy Development, Compliance Audits, Security Protocols, Network Administration, Cybersecurity, Disaster Recovery, System Maintenance, IT Infrastructure, Cloud Services, Database Management, Server Administration, Software Implementation, Troubleshooting, Performance Monitoring, Hardware Maintenance, Technical Support, System Integration, Cloud Migration, Data Backup, Data Recovery, System Configuration, Database Design, SQL Queries,', \"The entry-level requirements for a Media Buyer typically include: A bachelor's degree in marketing or a related field. Experience with media planning and buying software (e.g., Google Analytics, Adobe Creative Cloud). Familiarity with digital advertising platforms (e.g., Google Ads, Facebook Ads). Understanding of SEO principles. Knowledge of basic data analysis techniques. Strong communication and negotiation skills. Ability to work well under pressure. A strong understanding of market trends and industry standards. Some experience with media planning tools like Excel or media buying software is also beneficial.\", 'The daily tasks of a Web Developer typically include: writing and testing code, debugging issues, collaborating with designers and project managers to ensure that the website meets design requirements, optimizing website performance for better user experience, maintaining up-to-date knowledge of web technologies, ensuring cross-browser compatibility, resolving security issues, creating responsive designs for various devices, and troubleshooting issues related to databases or third-party APIs.', 'While a degree is not strictly necessary, having one in business administration, marketing, or communications can be beneficial. Relevant experience, certifications, and strong communication skills are also essential for success as a Customer Relationship Manager.', 'A Market Development Manager (Junior level) typically uses tools such as Google Analytics, Excel for data analysis, market research reports and tools like Ahrefs or SEMrush for SEO tracking. They also use CRM software to manage customer relationships and sales pipeline insights. Additionally, they utilize marketing automation platforms, social media analytics, and project management tools like Trello or Asana for task organization.', 'The possible positions for Statistics and Data Analysis and Statistical Computation are: Marketing Analyst. Key responsibilities include: Developing and analyzing marketing strategies, Creating data visualizations to present findings to clients or stakeholders, Conducting market research to determine the feasibility of new products or services, Analyzing customer behavior, Identifying trends in sales or website traffic, Collaborating with cross-functional teams to implement marketing initiatives, Managing databases and ensuring accuracy of market research data. The related skills are: Data Analysis, Business Strategy, Marketing Research, Customer Behavior, Sales Analysis, Database Management and Market Research.', 'A Franchise Manager typically uses a variety of tools to manage franchise operations, track performance, and communicate with franchisees. Some common tools include: franchise management software (e.g., FRANdata or FranMatch), sales software for tracking applications and candidate evaluations, online learning platforms for training, business planning tools, customer relationship management (CRM) systems, social media and email marketing platforms, market research reports, financial analysis software, and performance metrics tracking dashboards.', \"The entry-level requirements typically include a high school diploma or equivalent, some college credits (usually an associate's degree), and relevant work experience in law firms or related fields. Additionally, proficiency in word processing software, Microsoft Office, and familiarity with legal terminology are often required. Some positions may also require certification as a Legal Assistant (CLA) or Certified Paralegal (CP).\", 'To start a career as a Robotics Engineer, you should begin by gaining knowledge of robotics and automation technologies. You can pursue a degree in engineering or computer science to learn about the fundamentals of robotics, machine learning, and computer vision. Gain hands-on experience through internships, personal projects, or volunteer work with robotics teams. Consider earning certifications in areas such as robotic assembly or autonomous systems to enhance your skills. Networking with professionals in the field is also crucial for finding job opportunities. Staying up-to-date with industry trends and advancements in robotics will help you stay competitive in this dynamic field.', 'The qualifications typically include a degree in Computer Science, Statistics, Mathematics, or related fields. Experience with data analysis and machine learning algorithms is also essential. Certifications like Certified Data Scientist can be beneficial for career advancement. Continuous learning and professional development are key to staying up-to-date with the latest advancements in the field.', 'The possible positions for B.E. (Computers) are: Senior Software Engineer with an experience requirement of At least 5 years. The related skills are Data Management, Database, Network, System Integration, Cloud Computing, API Integration and Microservices Architecture. The possible salary range for Senior Software Engineer is Rs. 4lakhs to Rs. 8lakhs per annum (depending on the company size, location, experience, and performance). The related job tasks are Data Migration, Business Requirements Gathering, Technical Review, System Testing, Project Planning and Code Optimization.', 'The possible positions for N/A are: Executive-IT. The related skills are: Business Analysis, Project Management, Data Analysis, IT Infrastructure, Network Architecture, System Administration, Cloud Computing, Database Design, Server Management, Troubleshooting, Help Desk, Customer Support, Technical Writing, Network Security, Compliance, Risk Assessment, Audit, Policy Development, Incident Response, Disaster Recovery, Cybersecurity Awareness, Data Backup, Business Continuity Planning, Cloud Security, Identity Access, Data Encryption, Cloud Backup, Cloud Security Architecture, Disaster Recovery Planning and Cloud Infrastructure. The required skills are: Business Analysis, Project Management, Data Analysis, IT Infrastructure,', 'The possible positions for BSc and MSc are: Project Manager (Junior/Entry level) - The role involves managing project timelines, resources, and budgets. Requirements include strong communication skills, attention to detail, and ability to work under pressure. The salary range is between $60,000 and $80,000 annually. Executive Assistant (Executive-level) - This role requires experience as an administrative assistant or executive secretary. Key responsibilities include coordinating events, managing calendars, and handling correspondence. Salary ranges from $50,000 to $70,000 per year. Research Associate (Research team support) - The role involves assisting researchers in data collection', 'The possible positions for B.E. (Computers) are: Sr. Associate/Associate Engineer-IT, Associate Engineer, Assistant Engineer-IT, Junior Engineer, IT Consultant, Sr. IT Consultant, Business Analyst, Quality Control Executive and Network Administrator. The related job post requirements are: 8 years of experience, Bachelor of Engineering in Computer Science or B.Tech with specialization in CSE/EEE/ECE. Key skills include Python, Java, SQL, Angular JS, React JS and Node.JS. The job pays between $45,000 and $80,000 annually.', 'The main responsibilities include analyzing social media trends, creating engaging content, tracking brand mentions and conversations, monitoring analytics to optimize performance, managing online reputation, and reporting on key metrics.', 'A Business Intelligence Analyst typically uses a range of tools, including data visualization software (e.g., Tableau, Power BI), reporting tools (e.g., SQL Server Reporting Services, Crystal Reports), and business intelligence platforms (e.g., QlikView, SAP BusinessObjects). They may also use statistical analysis software (e.g., R, Python) to analyze large datasets. Additionally, collaboration and project management tools like Asana or Trello are useful for coordinating with stakeholders and team members. The choice of tools depends on the specific needs of the organization and the type of projects being worked on.', 'To become a successful Cloud Consultant, you should have skills in cloud computing technologies such as AWS or Azure. You should also be familiar with cloud security practices and migration strategies. Additionally, knowledge of cloud-related tools like CloudFormation, Terraform, and Ansible is important. Experience with container orchestration tools like Kubernetes and familiarity with cloud architecture principles are also necessary.', 'The essential skills for a successful Retail Manager include: leadership, communication, inventory management, customer service, sales performance analysis, store operations, employee supervision, training, and adaptability. They should also be knowledgeable about retail trends and technology to make informed decisions.', 'The daily tasks of an Advertising Manager (Junior level) include: Creating and writing ad copy for campaigns, Managing social media advertising accounts, Reviewing and approving ad content, Conducting research to determine target audiences and metrics for success.', \"The average salary for a Policy Advisor can vary based on factors like location, experience, and industry. However, the general range for an entry-level Policy Advisor is around $40,000 to $50,000 annually. Experienced Policy Advisors can earn upwards of $70,000 per year. It's also worth noting that salaries may be higher in urban areas or government institutions.\", 'Cloud Database Engineers typically work for companies that operate in a variety of industries, including cloud computing firms, e-commerce platforms, social media services, and large enterprises. They often find positions at well-established tech companies or startups that focus on cloud-based solutions. The job can also be found within the broader tech industry, with opportunities to work across different departments and teams.', 'Data Visualization Specialists face difficulties in ensuring data accuracy, managing large datasets, meeting user expectations for visual clarity and storytelling, dealing with complex data sources, balancing aesthetics with functionality, and maintaining the integrity of the visualization over time.', 'Business Analysts typically work in various industries, including but not limited to: Finance and Banking, Healthcare, Technology, Manufacturing, Retail, Government, and Consulting firms. They may also work in-house for a specific company or as freelancers/contractors.', 'A typical day for a Legal Assistant involves supporting lawyers by preparing documents, answering phone calls, conducting research, and organizing files. It may also involve attending court hearings, reviewing contracts, and drafting correspondence on behalf of clients. The role requires strong organizational skills, attention to detail, and the ability to maintain confidentiality.', 'The possible positions for Bachelor of Business Administration are: Senior Manager (Retail Operations). The related skills are: Marketing strategy, Leadership, Team management, Time management, Communication, Budgeting. The likely tasks include: Analyzing sales trends to improve customer satisfaction, Developing marketing strategies to increase brand visibility, Collaborating with teams to achieve business goals, Managing inventory levels and ensuring efficient operations, Maintaining accurate records of sales performance, Conducting market research to identify new opportunities for growth. The likely tools used are: Salesforce.com, CRM software, Excel, PowerPoint, Google Analytics. The typical qualifications required are: A degree in Marketing or Business Administration.', 'The possible positions for Bachelor of Science are: Senior Business Analyst with an experience requirement of 2 to 4 years. The related skills are Python, Java, C++. The possible salary range is $55,000 - $80,000 annually. Senior Business Analyst positions involve analyzing business requirements and developing data-driven solutions for organizations. Key responsibilities include designing databases, creating reports, and implementing data models. Skills required include proficiency in programming languages like Python or Java, experience with database management systems, knowledge of SQL queries, and ability to work with large datasets. The typical salary range for Senior Business Analyst is $55,000 to $80,', \"A typical day for an Automation Engineer may involve: Reviewing system logs to identify issues, Writing and testing automation scripts or codes, Collaborating with developers to implement automated processes, Troubleshooting automation scripts, Optimizing existing automation workflows, Creating documentation for new automation tools. The specific tasks can vary depending on the project requirements and the team's focus areas.\", 'A typical day for an Operations Executive involves managing daily operations, coordinating with team members, monitoring performance metrics, and ensuring that processes run smoothly. This may include tasks such as scheduling, inventory management, quality control, customer service, and problem-solving. The specific duties can vary depending on the industry, company size, and job requirements.', \"The job description for a Claims Adjuster typically involves handling and resolving insurance claims, assessing damages or losses, communicating with policyholders, and negotiating settlements. They must also have strong analytical skills to determine the extent of damage and ensure fair payouts. Key responsibilities include reviewing claim files, conducting site visits, investigating accidents or damages, calculating payments, and ensuring compliance with company policies and regulations. A bachelor's degree in a related field is often preferred, although some employers may consider relevant work experience sufficient. Continuous learning is also important to stay up-to-date on industry developments and regulatory changes.\"], 'references': ['The possible positions for B.E. (Computers) are: Mechanical Designer with an experience requirement of At least 5 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', \"The possible positions for Bachelor of Business Administration are: Site Engineer with an experience requirement of 1 to 2 years. The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router\", 'Entry-level requirements typically include a high school diploma, some college education or relevant certifications, and a state-issued license. Experience in customer service or insurance is a plus.', 'The possible positions for Computer Applications and Computer Applications are: Senior Software Engineer. Key responsibilities include: Technical Support, Troubleshooting, Collaboration, Documentation, System Monitoring, Software Deployment, Training & Mentorship, Industry Trends, Field Visits', 'The possible positions for B.Tech are: Asst. Manager/ Manger (Administrative) with an experience requirement of At least 5 years. The related skills are Testing, Debugging and Parameter Tuning', 'Claims Adjusters usually work in office environments but may also spend time in the field conducting investigations, meeting with claimants, or inspecting damaged properties. Some positions may offer remote work options.', 'Companies that rely heavily on data-driven decision-making, such as tech companies, financial institutions, retail businesses, and healthcare organizations, hire Business Intelligence Analysts.', 'Tech companies, AI startups, large corporations with AI needs, financial institutions, healthcare organizations, and research labs commonly hire AI Software Engineers.', 'The possible positions for B.Tech are: Data Engineer with an experience requirement of 5 to 8 years. The related skills are NLP and Data Analysis', 'On a daily basis, a Social Media Analyst monitors social media platforms, tracks key performance indicators (KPIs), compiles data into reports, engages with social media teams to optimize strategies, and analyzes trends to guide future campaigns.', 'Software Engineers often work in collaborative environments with other developers, product managers, and designers, with opportunities for remote or in-office work depending on the company.', 'The average salary for an entry-level Product Manager ranges from $60,000 to $90,000 per year, depending on experience and location.', 'The salary range for a Junior Digital Marketing Manager typically falls between $45,000 and $65,000 annually, with senior roles or positions in larger companies offering higher salaries.', 'The possible positions for B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X are: System Administrator (Operation & Maintenance of Server, Storage & Service Desk System) with an experience requirement of 4 to 5 years. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, OCR, Pytesseract and NER Text Classification', 'Essential skills include expertise in manual and automated testing, proficiency with testing tools (like Selenium, QTP, JUnit), understanding of bug-tracking systems, and strong analytical and debugging skills.', \"An Operations Executive is responsible for ensuring that the company's day-to-day activities run efficiently. They monitor operational performance, optimize processes, and assist in resource management and problem-solving.\", 'The possible positions for Bachelor of Engineering are: Sr.Officer / Executive - Internal Audit with an experience requirement of 2 to 4 years. The related skills are Software Development and Application Programming', 'The possible positions for BBA are: Business Development Executive with an experience requirement of 1 to 3 years. The related skills are Data Analysis and Business Analysis', 'Daily tasks include reviewing environmental impact data, assessing energy usage and waste management practices, meeting with clients to discuss sustainability goals, preparing reports, and developing recommendations for improving sustainability efforts.', 'The possible positions for Statistics are: Network Support Engineer. Key responsibilities include: Mikrotik Router Configuration, OLT Device Setup & Management, Integration with Billing Software, Network Monitoring Tools Integration, Connectivity Troubleshooting, Technical Support & Escalation, Installation & Configuration, GPON/EPON Expertise, Cisco, OLT, MikroTik Knowledge', 'The possible positions for Bachelor of Science are: Senior Software Engineer with an experience requirement of At least 1 year. The related skills are Creating dashboards for sales and profits', 'The possible positions for B.E. (Computers) are: DevOps Engineer with an experience requirement of At least 3 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'Entry-level requirements typically include a Bachelor’s degree in Marketing, Advertising, or Communications, along with an understanding of media buying and advertising principles. Internships or hands-on experience in digital marketing can also be helpful.', 'Daily tasks include coding, testing new features, troubleshooting bugs, attending team meetings, reviewing code, and ensuring that websites and web applications are performing well.', 'While a degree in Business, Marketing, or a related field is often preferred, experience in customer service or sales, along with hands-on experience with CRM tools, can also provide an entry point into this role.', 'Tools typically used include market research platforms like Nielsen, Google Analytics for website data, CRM software like Salesforce, and project management tools like Asana or Trello.', 'The possible positions for Statistics and Data Analysis and Statistical Computation are: Database Administrator (DBA). Key responsibilities include: Database Design & Development, SQL Query Optimization, Data Integrity & Security, BI Solutions Development, ETL Process Implementation, Database Maintenance, Backup & Restore Management, Index Rebuilding & Performance Tuning, SQL Server Clustering & High Availability, SQL Server Replication, High Availability Group Management, Database Monitoring & Troubleshooting', 'Franchise Managers typically use franchise management software, scheduling tools, POS systems, customer relationship management (CRM) systems, and business reporting tools like Excel or Google Sheets.', 'Entry-level requirements typically include a Bachelor’s degree or completion of a legal assistant certification program. Some positions may accept candidates with relevant experience or internships in the legal field.', 'To start, focus on obtaining a relevant degree (e.g., Robotics, Mechanical Engineering, Electrical Engineering) and gain hands-on experience with robotic systems, programming, and hardware design through internships or personal projects.', \"A bachelor's or master's degree in fields like Computer Science, Statistics, Mathematics, or Data Science is typically required.\", 'The possible positions for B.E. (Computers) are: Asst. Manager/ Manger (Administrative) with an experience requirement of At least 5 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'The possible positions for N/A are: Manager- Human Resource Management (HRM)\\n. Key responsibilities include: Recruitment Coordination, Appointment Management, Selection Criteria, Employee Orientation, Performance Evaluation, HR Database Management, Report Compilation, Documentation, Event Coordination, Task Execution', 'The possible positions for BSc and MSc are: Senior iOS Engineer with an experience requirement of At least 4 years. The related skills are NLP, ML and Amazon Comprehend Medical API', 'The possible positions for B.E. (Computers) are: Senior Software Engineer with an experience requirement of At least 1 year. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'The main responsibilities include analyzing social media data, tracking engagement metrics, developing reports, identifying trends and insights, monitoring online conversations, managing social media campaigns, and helping to optimize social media strategies.', 'Business Intelligence Analysts typically use BI tools like Power BI, Tableau, and QlikView for data visualization and reporting. They also use SQL-based tools for data querying and may use Excel for data manipulation.', 'Skills include a strong understanding of cloud platforms (AWS, Azure, Google Cloud), knowledge of cloud migration processes, familiarity with security practices, and problem-solving skills in the context of cloud infrastructure.', 'Essential skills include effective leadership, customer service, inventory management, staff training, sales strategies, and proficiency with point-of-sale (POS) systems.', 'Daily tasks include reviewing ad performance, working with the creative team on ad design, preparing reports, managing budgets for campaigns, and ensuring all ads are properly placed on the chosen platforms.', 'The average salary for a Policy Advisor typically ranges from $50,000 to $75,000 annually, depending on experience, location, and the specific employer.', 'Cloud Database Engineers work for tech companies, cloud service providers, consulting firms, and large enterprises that rely on cloud-based database solutions. Many work remotely or in hybrid environments.', 'Data Visualization Specialists often face challenges related to data quality, such as incomplete or messy data, and ensuring that visualizations are intuitive, meaningful, and aligned with business goals.', 'Business Analysts work in a variety of industries, including finance, healthcare, IT, manufacturing, and consulting. They can be employed in both large corporations and smaller companies.', 'A typical day involves preparing and filing legal documents, conducting legal research, organizing case files, assisting lawyers with trial preparation, and communicating with clients or witnesses. They may also attend meetings and hearings.', \"The possible positions for Bachelor of Business Administration are: Project Coordinator (Civil) with an experience requirement of 5 to 10 years. The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router\", 'The possible positions for Bachelor of Science are: Data Science Engineer with an experience requirement of At least 2 years. The related skills are Creating dashboards for sales and profits', 'A typical day involves designing automation processes, writing and testing scripts, debugging automation systems, collaborating with developers, and monitoring automated workflows to ensure they run efficiently.', 'A typical day includes overseeing operations, managing resources, tracking performance metrics, analyzing processes for efficiency, coordinating between departments, and handling any operational issues that arise.', 'A Claims Adjuster reviews and processes insurance claims by assessing the damages, interviewing claimants and witnesses, conducting investigations, and determining the payout based on the insurance policy terms and the extent of the loss.'], 'precision': 0.6467505693435669, 'recall': 0.736612856388092, 'f1': 0.6870530843734741}\n"
     ]
    }
   ],
   "source": [
    "# QLoRA Q4_K_M gguf model bertscore\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "results = evaluate_llama_bertscore_withChatTemplate(model_path=\"./quantized_models/ft-qlora-q4_k_m.gguf\", dataset=small_test, tokenizer=tokenizer)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (1024) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "Generating responses: 100%|██████████| 50/50 [23:07<00:00, 27.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [\"The possible positions for B.E. (Computers) are: Manager- Human Resource Management (HRM)\\n with an experience requirement of 5 to 6 years. The related skills are Market Research and Data Analysis. The related qualifications are Bachelor's Degree in Business Administration. The possible positions for Bachelor's Degree in Business Administration are: Senior Software Engineer. The experience requirement is 4 to 5 years. The related skills are Software Development, System Analysis, Requirement Gathering, Designing Database Schemes, Developing SQL Queries, Performance Monitoring, Troubleshooting, Document Preparation, Code Translation, Communication, Team Collaboration, Task Management, Innovation,\", 'The possible positions for Bachelor of Business Administration are: Project Coordinator (Civil) with an experience requirement of 5 to 10 years. The related skills are NLP and Data Analysis. The possible positions for NLP and Data Analysis are: Machine Learning (ML) Engineer with an experience requirement of 3 to 6 years. The related skills are Software Development, Application Programming, Designing Systems, Developing APIs, Creating Database Models, System Analysis, User Management, Performance Monitoring, Task Assignment, Documentation, Collaboration, Innovation, Problem-Solving, Code Review, Translating Requirements into Code, Developing Functional Tests, Integrating with Existing Systems', 'Entry-level requirements typically include a high school diploma, some college credit in insurance or a related field, and passing the National Claims Adjusters Examination (NCAE). Some employers may also require a background check.', 'The possible positions for Computer Applications and Computer Applications are: Executive/ Sr. Executive -IT. Key responsibilities include: Hardware & Software Installation, System Monitoring, IT Support, Networking Expertise, Mail Server Administration, Security Management, Troubleshooting & Repair, Operations Support, Technical Documentation, Data Protection & Disaster Recovery, Storage & Database Management, Server Management, Client Assistance, Power User & Task Manager, OHS Policy Development, Safety Advice, Risk Assessment, Policy Review, Testing & Validation, Compliance, Safety Training, Incident Investigation, Report Preparation, Safety Escalation, Miscellaneous Tasks, Employee Safety, Field Visits, Record Keeping, Data', \"The possible positions for B.Tech are: Sr.Officer / Executive - Internal Audit with an experience requirement of 3 to 5 years. The related skills are NLP and Data Analysis and Machine learning. The related qualifications are Bachelor's Degree in B.Tech. The related technologies are Python, ReactJS and NodeJS for front-end and back-end development. The career advice is: If you have a degree in B.Tech, you can pursue a career as a Sr.Officer / Executive - Internal Audit with an experience requirement of 3 to 5 years. The related skills are NLP and Data Analysis and Machine\", \"A Claims Adjuster can expect to work in an office setting, with occasional visits to clients' homes or workplaces. The environment is typically fast-paced and stressful during peak claims periods. Many companies offer flexible working arrangements, including remote work options. The work requires strong communication skills, attention to detail, and the ability to handle complex situations.\", 'Business Intelligence Analysts are commonly hired by companies in the finance, retail, healthcare, technology, and consulting industries. They also work for organizations with large databases or complex reporting requirements. Government agencies, research institutions, and startups may hire Business Intelligence Analysts as well. Additionally, many companies engage external consultants to provide BI services on an ad-hoc basis.', 'Companies in industries such as technology, healthcare, finance, retail, and research hire AI Software Engineers. Many startups and tech giants also employ AI engineers to develop innovative solutions using machine learning models. Additionally, companies in the automotive, manufacturing, and logistics sectors are increasingly adopting AI to improve operational efficiency. Research institutions, universities, and government organizations may also require AI software engineers for their projects.', \"The possible positions for B.Tech are: Head of Internal Control & Compliance (ICC) - SEVP/DMD with an experience requirement of At least 15 years. The related skills are NLP, ML and Amazon Comprehend Medical API. The related qualifications are Bachelor's degree in Electrical Engineering. The related tools are AWS, EC2, S3, RDS, IAM, Docker, Terraform, Python, bash, Amazon Web Services (AWS) CLI and AWS Architecture. The related positions are Systems Administrator with an experience requirement of At least 15 years. The related skills are NLP, ML and Amazon Comprehend\", 'On a daily basis, a Social Media Analyst monitors and analyzes social media platforms for brand mentions, customer engagement, content performance, and competitor activity. They also work on creating engaging content, tracking metrics, responding to comments, and collaborating with other teams for campaigns or events. The role requires staying up-to-date with the latest trends in digital marketing and analyzing data to inform business decisions.', 'Software Engineers typically work in office environments, although some roles may be remote or hybrid. The environment is often collaborative and fast-paced, with a focus on solving complex technical problems. A typical day involves coding, testing software, and collaborating with other teams. Some roles may also require travel to client sites or industry conferences.', 'The average salary for a Product Manager is between $80,000 and $120,000 annually. However, salaries can vary depending on factors such as experience, location, and the size of the company. Senior or executive-level product managers may earn higher salaries.', 'The salary range for a Digital Marketing Manager (Junior level) is typically between $45,000 and $60,000 annually, depending on experience, location, and company size. Senior-level positions may earn more.', 'The possible positions for B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X are: Mechanical Designer with an experience requirement of At least 5 years. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, OCR, Pytesseract and NER Text Classification. The possible positions for B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X are: System Administrator with an experience requirement of At least 3 years. The related skills are Python, Chaco Plotting Library (Chaco), Matplotlib, NumPy, SciKit Learn and Traits', 'Essential skills include attention to detail, analytical thinking, proficiency in testing tools, knowledge of software development processes, effective communication with developers and product managers, and ability to identify and report defects. Strong problem-solving skills are also crucial.', 'The Operations Executive is responsible for overseeing the day-to-day operations of a company or department. This involves managing workflows, coordinating tasks with other teams, ensuring efficiency in production processes, and maintaining quality standards. They work closely with other executives to implement strategies that improve operational performance. The role also requires strong communication skills to manage cross-functional teams and stakeholders.', 'The possible positions for Bachelor of Engineering are: Civil Engineer with an experience requirement of 3 to 5 years. The related skills are Software Development and Application Programming. The possible positions for Software Development are: Senior Software Engineer with an experience requirement of 4 to 6 years. The related skills are Application Lifecycle Management, software development and design, team collaboration, requirements gathering, bug fixing, feature development, testing, system analysis, documentation, deployment, operations support, customer communication, task management, project coordination, technical support, issue resolution, code review, specification writing, deployment planning, project tracking, professional networking, industry trends, technical knowledge', 'The possible positions for BBA are: Full Stack Developer (Python,React js) with an experience requirement of 3 to 7 years. The related skills are NLP and Data Analysis. The possible positions for NLP are: Machine Learning Engineer with an experience requirement of 5 to 10 years. The related skills are Software Development and Application Programming. The possible position for Software Development is: Mechanical Engineer with an experience requirement of 2 to 5 years. The related skills are CAD, CAM, CAE and CAPP. The possible position for Electrical Engineering is: System Administrator (Windows, Linux) with an experience requirement of', 'Daily tasks include conducting environmental impact assessments, reviewing sustainability reports, collaborating with clients or teams to develop sustainable strategies, analyzing data on energy and resource usage, and implementing measures to reduce waste and improve efficiency. They may also participate in stakeholder engagement and communication efforts.', 'The possible positions for Statistics are: Head of Internal Control & Compliance (ICC) - SEVP/DMD. Key responsibilities include: 15+ Years Banking Experience, Audit/Inspection/ICC Leadership, Internal Audit & Compliance, Risk-Based Operational Reviews, System-Based Audit Expertise, Knowledge of Bangladeshi Laws and Regulations, Investigation & Reporting, Compliance Monitoring, Capacity Building, Audit Execution, Voucher Management, Client Coordination, Documentation, Verification, Appointment Selection, Policy Development, System Administration, Data Protection & Security, Team Management, Software Selection, System Maintenance, Data Translation, Report Generation, Task Execution, User Support, Field', 'The possible positions for Bachelor of Science are: Executive/ Senior Executive- Trade Marketing, Hygiene Products with an experience requirement of At least 3 years. The related skills are Market Research and Data Analysis. The related qualifications are Bachelor of Engineering. The possible positions for Bachelor of Engineering are: Mechanical Designer with an experience requirement of At least 2 years. The related skills are CAD Software, Project Management and Manufacturing Processes. The related qualifications are High School Diploma or Equivalent. The possible positions for High School Diploma or Equivalent are: Database Administrator (DBA) with an experience requirement of At least 1 year. The related skills are Software Installation', 'The possible positions for B.E. (Computers) are: Data Engineer with an experience requirement of At least 2 years. The related skills are Neural Networks, Machine Learning and Image recognition. The related qualifications are Bachelor of Engineering. The job description includes Designing database systems, Developing SQL queries, Ensuring data consistency, Providing database support, Collaborating with developers, Ensuring data integrity, Developing tools for data analysis, Creating ETL processes, Performing data modeling, Ensuring data availability, Developing database indexes, Optimizing query performance, Backing up databases, Restoring databases, Performing routine maintenance, Troubleshooting database issues, Optim', 'Entry-level requirements typically include a degree in marketing, advertising, or communications, and relevant experience with media planning tools like Google Ads or Facebook Ads Manager. A strong understanding of the media landscape and digital advertising platforms is also important. Many companies will provide training on their specific systems.', 'Daily tasks include coding, debugging code, maintaining websites or web applications, collaborating with designers and project managers, and ensuring that the website is optimized for performance, accessibility, and user experience.', 'A degree in Business, Marketing, or a related field is often helpful but not always required. Many successful CRM professionals learn through experience, training programs, and certifications. Relevant skills like customer service, communication, and problem-solving are important.', 'A Market Development Manager (Junior level) typically uses tools like CRM software for sales tracking, market research reports, online analytics tools (Google Analytics), social media platforms for customer engagement, and Excel or other spreadsheet tools for data analysis. They also use tools like HubSpot, Salesforce, or other marketing automation tools to manage marketing campaigns.', 'The possible positions for Statistics and Data Analysis and Statistical Computation are: Civil Engineer. Key responsibilities include: Design Review, Coordination, Proposal Preparation, Feasibility Analysis, Software Utilization, Supervision, Technical Support, Submission Review, Progress Reporting, Compliance, Site Visits, Calculation, Documentation, Testing, Material Selection, Construction Monitoring, Innovation, Research, Publication, Teaching, Service, Industry Collaboration, International Collaboration, Position Description, Responsibilities, Requirements, Tools, Market Trends, Problem-Solving, Data Analysis, Business Analytics, Statistical Analysis, Regression Analysis, Natural Language Processing, Machine Learning and Numerical Analysis. The estimated salary range', 'A Franchise Manager typically uses tools like franchise management software, CRM systems (e.g., HubSpot), inventory management systems, payroll processing tools, and training platforms. They also rely on Microsoft Office Suite and Google Workspace for communication and document preparation. Some franchises may use proprietary management software as well.', \"Entry-level requirements typically include a Bachelor's degree in Legal Studies, Paralegal Studies, or a related field. Certification through the National Association of Legal Assistants (NALA) or the American Bar Association (ABA) can be beneficial for career advancement. Practical experience through internships or entry-level positions is also crucial.\", 'To start a career as a Robotics Engineer, focus on gaining education in robotics, gaining practical experience through internships or projects, and developing skills in programming, mechanical engineering, and AI. Networking with professionals in the field is also essential.', \"To become a Data Scientist, you typically need a Bachelor's degree in Computer Science or a related field. A Master's degree can be beneficial for advanced roles. Knowledge of programming languages (Python, R), machine learning algorithms, data structures, and statistical analysis is essential. Experience with big data tools like Hadoop and Spark also helps. Certifications like Certified Data Scientist (CDS) or Google Cloud Data Engineer can enhance qualifications.\", 'The possible positions for B.E. (Computers) are: Mechanical Engineer with an experience requirement of At least 5 years. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, OCR, Pytesseract and NER Text Classification in Python. The possible positions for Mechanical Enginee... are: System Administrator (Operation & Maintenance of Server, Storage & Service Desk System) with an experience requirement of At least 3 years. The related skills are Python, Chaco Plotting Library (Chaco), Matplotlib, NumPy, SciKit Learn and Cupy. The possible positions for System Administrator', 'The possible positions for N/A are: Sr.Officer / Executive - Internal Audit. Key responsibilities include: Internal Audit Assistance, Voucher & Bill Verification, Cost Sheet Analysis, L/C Voucher Verification, Expense Verification, Salary & Wages Verification, Market Rate Verification, Headquarter Voucher Verification, Other Expenses Verification, Field Visit Assistance, Account Statements Verification, Bank List Verification, Client Introduction & Visitation, Documentation & Data Entry, Leadership Development, Team Management and Selection, Appointment Coordination, Report Compilation, Inventory Management, Logistics Coordination, Field Operations, Technical Support, Application Assistance, Hardware & Software Support, Troubleshooting &', 'The possible positions for BSc and MSc are: Site Engineer with an experience requirement of At least 5 years. The related skills are NLP, ML and Amazon Comprehend Medical API for medical text analysis. The related qualifications are Bachelor of Engineering. The job description includes Data Analysis, Business Intelligence, Report Preparation, Database Management, Insights Provision, Task Execution, Communication, Skill Development, Innovation, Research, Collaboration, Task Management, Data Visualization, Statistical Analysis, Machine Learning and Algorithmic Thinking. The average salary range for Site Engineer is between Rs. 12 lakhs and Rs. 15 lakhs.', 'The possible positions for B.E. (Computers) are: Machine Learning (ML) Engineer with an experience requirement of At least 3 years. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, OCR, Pytesseract and NER Text Classification. The related tools are Google Cloud Platform, Amazon Web Services, Microsoft Azure, Google Kubernetes Engine, Datadog, Tensorflow, Keras, OpenCV, Scikit-Learn and Python. The position describes the main responsibilities as: Design Database Systems, Develop SQL Queries, Analyze Database Performance, Optimize SQL Queries, Create Database Index', 'The main responsibilities include analyzing social media data to understand audience behavior, creating reports based on that analysis, monitoring and managing social media campaigns, optimizing content strategy, identifying opportunities for engagement, and ensuring consistency across all platforms.', 'Business Intelligence Analysts typically use tools such as Excel, Tableau, Power BI, SQL Server Reporting Services (SSRS), data visualization tools like D3.js, and programming languages like Python or R for advanced analysis. They also use ETL tools for data integration and reporting.', 'Skills required include knowledge of cloud platforms (AWS, Azure), experience with cloud architecture, cloud security, scalability expertise, and strong communication skills for collaborating with clients. Familiarity with DevOps practices is also important. Cloud certifications like AWS Certified Solutions Architect or Microsoft Azure Developer are often beneficial.', 'Essential skills include strong communication and interpersonal skills, problem-solving abilities, attention to detail, the ability to manage time effectively, leadership qualities, customer service expertise, knowledge of retail operations, and analytical skills for sales performance.', 'Daily tasks include managing ad campaigns, creating and scheduling ads, reviewing performance data, collaborating with designers to create creative assets, optimizing ad spend based on results, and ensuring all campaigns are aligned with overall marketing goals. Additionally, the person must be proactive in seeking opportunities for growth within their role or organization.', 'The average salary for a Policy Advisor typically ranges from $45,000 to $60,000 annually, depending on experience, location, and the specific industry. Senior or executive-level positions may command higher salaries.', 'Cloud Database Engineers typically work at cloud service providers like AWS, Google Cloud, Microsoft Azure, cloud consulting firms, IT companies, and large enterprises that adopt cloud-based infrastructure. They often collaborate with DevOps teams to ensure seamless integration of databases into cloud environments.', 'Difficulties include dealing with complex, messy data, ensuring that visualizations are clear and concise, handling large datasets, making sure the visualization aligns with business goals, and overcoming limitations in tools or technology.', 'Business Analysts typically work in corporate environments, such as financial institutions, technology companies, healthcare organizations, consulting firms, and government agencies. They may also work remotely or in freelance capacities.', 'A typical day involves preparing and reviewing legal documents, conducting research, assisting attorneys with court filings, drafting correspondence, managing client files, and providing administrative support to the law firm. The role also requires staying organized, meeting deadlines, and maintaining confidentiality of client information.', \"The possible positions for Bachelor of Business Administration are: Mechanical Engineer with an experience requirement of At least 3 years. The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router files, Test assembled products, Take photos and write descriptions for website, Test all products against\", 'The possible positions for Bachelor of Science are: Mechanical Engineer with an experience requirement of At least 5 years. The related skills are NLP, ML and Amazon Comprehend Medical API for medical claim validation, Amazon Comprehend Text API for text analysis, Amazon Translate API for translation and Amazon ImageClassifier API for image classification. The possible positions for NLP, ML are: Sr.Officer / Executive - Internal Audit with an experience requirement of At least 5 years. The related skills are Python, Chaco Plotting Library and Traits UI Library for creating interactive plots, NumPy for numerical computations, SciKit Learn for machine learning', 'A typical day involves reviewing code, analyzing automation workflows, making adjustments to scripts or tools, debugging automated processes, and collaborating with other teams (such as QA or DevOps) to ensure seamless integration. Automation Engineers also work on optimizing and refining existing automations to improve efficiency and reliability.', 'A typical day involves monitoring and managing business operations, resolving any issues that arise, coordinating with teams to ensure smooth workflow, preparing reports on operational performance, and working closely with other departments to optimize processes. The role also requires problem-solving and communication skills.', 'A Claims Adjuster is responsible for evaluating the damage or loss, assessing liability, negotiating settlements with policyholders and claimants, and ensuring that claims are processed efficiently. They work to determine the extent of damages or losses and help settle claims in accordance with insurance policies.'], 'references': ['The possible positions for B.E. (Computers) are: Mechanical Designer with an experience requirement of At least 5 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', \"The possible positions for Bachelor of Business Administration are: Site Engineer with an experience requirement of 1 to 2 years. The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router\", 'Entry-level requirements typically include a high school diploma, some college education or relevant certifications, and a state-issued license. Experience in customer service or insurance is a plus.', 'The possible positions for Computer Applications and Computer Applications are: Senior Software Engineer. Key responsibilities include: Technical Support, Troubleshooting, Collaboration, Documentation, System Monitoring, Software Deployment, Training & Mentorship, Industry Trends, Field Visits', 'The possible positions for B.Tech are: Asst. Manager/ Manger (Administrative) with an experience requirement of At least 5 years. The related skills are Testing, Debugging and Parameter Tuning', 'Claims Adjusters usually work in office environments but may also spend time in the field conducting investigations, meeting with claimants, or inspecting damaged properties. Some positions may offer remote work options.', 'Companies that rely heavily on data-driven decision-making, such as tech companies, financial institutions, retail businesses, and healthcare organizations, hire Business Intelligence Analysts.', 'Tech companies, AI startups, large corporations with AI needs, financial institutions, healthcare organizations, and research labs commonly hire AI Software Engineers.', 'The possible positions for B.Tech are: Data Engineer with an experience requirement of 5 to 8 years. The related skills are NLP and Data Analysis', 'On a daily basis, a Social Media Analyst monitors social media platforms, tracks key performance indicators (KPIs), compiles data into reports, engages with social media teams to optimize strategies, and analyzes trends to guide future campaigns.', 'Software Engineers often work in collaborative environments with other developers, product managers, and designers, with opportunities for remote or in-office work depending on the company.', 'The average salary for an entry-level Product Manager ranges from $60,000 to $90,000 per year, depending on experience and location.', 'The salary range for a Junior Digital Marketing Manager typically falls between $45,000 and $65,000 annually, with senior roles or positions in larger companies offering higher salaries.', 'The possible positions for B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X are: System Administrator (Operation & Maintenance of Server, Storage & Service Desk System) with an experience requirement of 4 to 5 years. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, OCR, Pytesseract and NER Text Classification', 'Essential skills include expertise in manual and automated testing, proficiency with testing tools (like Selenium, QTP, JUnit), understanding of bug-tracking systems, and strong analytical and debugging skills.', \"An Operations Executive is responsible for ensuring that the company's day-to-day activities run efficiently. They monitor operational performance, optimize processes, and assist in resource management and problem-solving.\", 'The possible positions for Bachelor of Engineering are: Sr.Officer / Executive - Internal Audit with an experience requirement of 2 to 4 years. The related skills are Software Development and Application Programming', 'The possible positions for BBA are: Business Development Executive with an experience requirement of 1 to 3 years. The related skills are Data Analysis and Business Analysis', 'Daily tasks include reviewing environmental impact data, assessing energy usage and waste management practices, meeting with clients to discuss sustainability goals, preparing reports, and developing recommendations for improving sustainability efforts.', 'The possible positions for Statistics are: Network Support Engineer. Key responsibilities include: Mikrotik Router Configuration, OLT Device Setup & Management, Integration with Billing Software, Network Monitoring Tools Integration, Connectivity Troubleshooting, Technical Support & Escalation, Installation & Configuration, GPON/EPON Expertise, Cisco, OLT, MikroTik Knowledge', 'The possible positions for Bachelor of Science are: Senior Software Engineer with an experience requirement of At least 1 year. The related skills are Creating dashboards for sales and profits', 'The possible positions for B.E. (Computers) are: DevOps Engineer with an experience requirement of At least 3 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'Entry-level requirements typically include a Bachelor’s degree in Marketing, Advertising, or Communications, along with an understanding of media buying and advertising principles. Internships or hands-on experience in digital marketing can also be helpful.', 'Daily tasks include coding, testing new features, troubleshooting bugs, attending team meetings, reviewing code, and ensuring that websites and web applications are performing well.', 'While a degree in Business, Marketing, or a related field is often preferred, experience in customer service or sales, along with hands-on experience with CRM tools, can also provide an entry point into this role.', 'Tools typically used include market research platforms like Nielsen, Google Analytics for website data, CRM software like Salesforce, and project management tools like Asana or Trello.', 'The possible positions for Statistics and Data Analysis and Statistical Computation are: Database Administrator (DBA). Key responsibilities include: Database Design & Development, SQL Query Optimization, Data Integrity & Security, BI Solutions Development, ETL Process Implementation, Database Maintenance, Backup & Restore Management, Index Rebuilding & Performance Tuning, SQL Server Clustering & High Availability, SQL Server Replication, High Availability Group Management, Database Monitoring & Troubleshooting', 'Franchise Managers typically use franchise management software, scheduling tools, POS systems, customer relationship management (CRM) systems, and business reporting tools like Excel or Google Sheets.', 'Entry-level requirements typically include a Bachelor’s degree or completion of a legal assistant certification program. Some positions may accept candidates with relevant experience or internships in the legal field.', 'To start, focus on obtaining a relevant degree (e.g., Robotics, Mechanical Engineering, Electrical Engineering) and gain hands-on experience with robotic systems, programming, and hardware design through internships or personal projects.', \"A bachelor's or master's degree in fields like Computer Science, Statistics, Mathematics, or Data Science is typically required.\", 'The possible positions for B.E. (Computers) are: Asst. Manager/ Manger (Administrative) with an experience requirement of At least 5 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'The possible positions for N/A are: Manager- Human Resource Management (HRM)\\n. Key responsibilities include: Recruitment Coordination, Appointment Management, Selection Criteria, Employee Orientation, Performance Evaluation, HR Database Management, Report Compilation, Documentation, Event Coordination, Task Execution', 'The possible positions for BSc and MSc are: Senior iOS Engineer with an experience requirement of At least 4 years. The related skills are NLP, ML and Amazon Comprehend Medical API', 'The possible positions for B.E. (Computers) are: Senior Software Engineer with an experience requirement of At least 1 year. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development', 'The main responsibilities include analyzing social media data, tracking engagement metrics, developing reports, identifying trends and insights, monitoring online conversations, managing social media campaigns, and helping to optimize social media strategies.', 'Business Intelligence Analysts typically use BI tools like Power BI, Tableau, and QlikView for data visualization and reporting. They also use SQL-based tools for data querying and may use Excel for data manipulation.', 'Skills include a strong understanding of cloud platforms (AWS, Azure, Google Cloud), knowledge of cloud migration processes, familiarity with security practices, and problem-solving skills in the context of cloud infrastructure.', 'Essential skills include effective leadership, customer service, inventory management, staff training, sales strategies, and proficiency with point-of-sale (POS) systems.', 'Daily tasks include reviewing ad performance, working with the creative team on ad design, preparing reports, managing budgets for campaigns, and ensuring all ads are properly placed on the chosen platforms.', 'The average salary for a Policy Advisor typically ranges from $50,000 to $75,000 annually, depending on experience, location, and the specific employer.', 'Cloud Database Engineers work for tech companies, cloud service providers, consulting firms, and large enterprises that rely on cloud-based database solutions. Many work remotely or in hybrid environments.', 'Data Visualization Specialists often face challenges related to data quality, such as incomplete or messy data, and ensuring that visualizations are intuitive, meaningful, and aligned with business goals.', 'Business Analysts work in a variety of industries, including finance, healthcare, IT, manufacturing, and consulting. They can be employed in both large corporations and smaller companies.', 'A typical day involves preparing and filing legal documents, conducting legal research, organizing case files, assisting lawyers with trial preparation, and communicating with clients or witnesses. They may also attend meetings and hearings.', \"The possible positions for Bachelor of Business Administration are: Project Coordinator (Civil) with an experience requirement of 5 to 10 years. The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router\", 'The possible positions for Bachelor of Science are: Data Science Engineer with an experience requirement of At least 2 years. The related skills are Creating dashboards for sales and profits', 'A typical day involves designing automation processes, writing and testing scripts, debugging automation systems, collaborating with developers, and monitoring automated workflows to ensure they run efficiently.', 'A typical day includes overseeing operations, managing resources, tracking performance metrics, analyzing processes for efficiency, coordinating between departments, and handling any operational issues that arise.', 'A Claims Adjuster reviews and processes insurance claims by assessing the damages, interviewing claimants and witnesses, conducting investigations, and determining the payout based on the insurance policy terms and the extent of the loss.'], 'precision': 0.6890683174133301, 'recall': 0.7716236710548401, 'f1': 0.7267628312110901}\n"
     ]
    }
   ],
   "source": [
    "# LoRA Q8_0 gguf model bertscore\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "results = evaluate_llama_bertscore_withChatTemplate(model_path=\"./quantized_models/ft-q8_0-lora.gguf\", dataset=small_test, tokenizer=tokenizer)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dk6otO4HgOjM",
    "outputId": "a0e33644-620a-4887-93eb-0e62980fe836",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 14 12:42:03 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           Off |   00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   34C    P0             35W /  250W |       0MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MnOFWwOuAZ5U"
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "import platform\n",
    "import os\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cWC36hBx1gIL",
    "outputId": "b65bc82a-0348-42f5-fa92-0902447aa84c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: Tesla T4, compute capability 7.5, VMM: yes\n",
      "Available devices:\n",
      "  CUDA0: Tesla T4 (15095 MiB, 14992 MiB free)\n"
     ]
    }
   ],
   "source": [
    "!llama.cpp/build/bin/llama-cli --list-devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### llama-bench results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GQK1__X16m9G",
    "outputId": "df0b9463-8f24-4b06-c485-405bb56610ab",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| model                          |       size |     params | backend    | threads | fa |            test |                  t/s |\n",
      "| ------------------------------ | ---------: | ---------: | ---------- | ------: | -: | --------------: | -------------------: |\n",
      "| llama 3B Q4_K - Medium         |   1.87 GiB |     3.21 B | CPU        |      36 |  1 |           pp512 |          4.38 ± 0.02 |\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!llama.cpp/build/bin/llama-bench --flash-attn 1 --model ./quantized_models/ft-q4_k_m-lora.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FkwFSoInBYAS",
    "outputId": "be58afb9-50d7-434d-aef8-239bfd54f0d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| model                          |       size |     params | backend    | threads | fa |            test |                  t/s |\n",
      "| ------------------------------ | ---------: | ---------: | ---------- | ------: | -: | --------------: | -------------------: |\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!llama.cpp/build/bin/llama-bench --flash-attn 1 --model ./quantized_models/ft-q5_k_m-lora.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDF995AwBab8",
    "outputId": "17ce4321-91fc-42dd-a93a-43e32c67ea07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| model                          |       size |     params | backend    | threads | fa |            test |                  t/s |\n",
      "| ------------------------------ | ---------: | ---------: | ---------- | ------: | -: | --------------: | -------------------: |\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!llama.cpp/build/bin/llama-bench --flash-attn 1 --model ./quantized_models/fp16-ft-base.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDF995AwBab8",
    "outputId": "17ce4321-91fc-42dd-a93a-43e32c67ea07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| model                          |       size |     params | backend    | threads | fa |            test |                  t/s |\n",
      "| ------------------------------ | ---------: | ---------: | ---------- | ------: | -: | --------------: | -------------------: |\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!llama.cpp/build/bin/llama-bench --flash-attn 1 --model ./quantized_models/ft-q8_0-lora.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDF995AwBab8",
    "outputId": "17ce4321-91fc-42dd-a93a-43e32c67ea07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| model                          |       size |     params | backend    | threads | fa |            test |                  t/s |\n",
      "| ------------------------------ | ---------: | ---------: | ---------- | ------: | -: | --------------: | -------------------: |\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!llama.cpp/build/bin/llama-bench --flash-attn 1 --model ./quantized_models/ft-qlora-q4_k_m.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eJZLKOVSI0im",
    "outputId": "fd30c3f0-1ebf-497e-a762-b53856edc0f1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "0% [Working]\r\n",
      "            \r\n",
      "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
      "\r\n",
      "            \r\n",
      "Get:2 https://cli.github.com/packages stable InRelease [3,917 B]\n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
      "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,931 kB]\n",
      "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
      "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,209 kB]\n",
      "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Hit:13 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,575 kB]\n",
      "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,270 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,520 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [36.8 kB]\n",
      "Fetched 11.9 MB in 3s (3,541 kB/s)\n",
      "Reading package lists... Done\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "build-essential is already the newest version (12.9ubuntu3).\n",
      "libopenblas-dev is already the newest version (0.3.20+ds-1).\n",
      "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
      "git is already the newest version (1:2.34.1-1ubuntu1.15).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y build-essential cmake git libopenblas-dev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "ad689c5d773949ad9c62d720ea904aa7",
      "8644664fc98c4635b8f518b8619149a5",
      "d88d8bfdb4ec4bd8b002c018fc5c0a66",
      "1eff09b5ad1d495fb26d9284a5c52640",
      "2b3cdea42e8e44fca2ff7be2f87407f4",
      "672547640d344161b51ad763aefbcf77",
      "bee908ff03e6405dbfda496f244143b2",
      "803fc165e3164175927cf4afb72f2c12",
      "fcfb477f396d4d1e812a0a631f31362f",
      "ecbd6647c0dc4516a733dd419d7c734d",
      "1cf39698f3744e9593101c7e6f1b521b"
     ]
    },
    "id": "PWgCtnVKPvgw",
    "outputId": "827f081a-65b9-4bf7-c41a-d82eb01cdbad"
   },
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "split_dataset = load_from_disk(\"dataset/split_combined_dataset_withoutjd\")\n",
    "\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "test_dataset = split_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp16-ft-base.gguf  fp16-ft-qlora.gguf\tft-q8_0-lora.gguf\n",
      "fp16-ft.gguf\t   ft-q4_k_m-lora.gguf\tft-qlora-q4_k_m.gguf\n",
      "fp16-ft-lora.gguf  ft-q5_k_m-lora.gguf\n"
     ]
    }
   ],
   "source": [
    "! ls ./quantized_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    f\"User: {inp}\\nAssistant: {tgt}\"\n",
    "    for inp, tgt in zip(test_dataset[\"input_text\"], test_dataset[\"target_text\"])\n",
    "]\n",
    "\n",
    "# Save to text file\n",
    "with open(\"test_dataset.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\\n\".join(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What are the entry-level requirements for a Legal Assistant?\n",
      "Assistant: Entry-level requirements typically include a Bachelor’s degree or completion of a legal assistant certification program. Some positions may accept candidates with relevant experience or internships in the legal field.\n",
      "\n",
      "User: What is the career growth path for an Automation Engineer?\n",
      "Assistant: The career growth path typically starts with an entry-level position as an Automation Engineer, progressing to Senior Automation Engineer, Automation Architect, and eventually to roles like DevOps Engineer or Automation Manager.\n",
      "\n",
      "User: What are the entry-level requirements for a Web Developer?\n",
      "Assistant: Entry-level requirements typically include knowledge of HTML, CSS, JavaScript, and basic understanding of web development frameworks. Building a portfolio of projects can also help you get started.\n",
      "\n",
      "User: What skills are required to become a Legal Assistant?\n",
      "Assistant: Skills required include strong organizational abilities, attention to detail, proficiency in legal research tools, excellent communication skills, knowledge of legal terminology, and the ability to maintain confidentiality.\n",
      "\n",
      "User: What difficulties do Advertising Managers (Junior level) face in their jobs?\n",
      "Assistant: Advertising Managers may face difficulties such as managing tight deadlines, handling underperforming ads, adjusting strategies based on performance metrics, and ensuring the team works within a limited budget.\n",
      "\n",
      "User: Do I need a degree to pursue a career as an SEM Specialist?\n",
      "Assistant: While a degree in Marketing or Business can be advantageous, it is not always necessary. Certifications in paid search advertising platforms like Google Ads and hands-on experience managing campaigns can also lead to a career in SEM.\n",
      "\n",
      "User: How do I progress in a career as a Fundraising Manager?\n",
      "Assistant: To progress, focus on gaining experience with various fundraising campaigns, building strong donor relationships, improving your communication and event planning skills, and seeking opportunities for leadership roles.\n",
      "\n",
      "User: What does a Cloud Database Engineer do?\n",
      "Assistant: A Cloud Database Engineer designs, deploys, and manages databases in the cloud. They ensure that databases are optimized for performance, scalable, secure, and available on cloud platforms like AWS, Azure, or Google Cloud.\n",
      "\n",
      "User: What qualifications do I need to become a Travel Coordinator?\n",
      "Assistant: Qualifications typically include a Bachelor’s degree in Hospitality Management, Tourism, Business, or a related field. Experience in travel coordination or a customer service-related role is also valuable.\n",
      "\n",
      "User: What does a typical day look like for a Cloud Consultant?\n",
      "Assistant: A typical day involves meeting with clients to discuss cloud strategies, working on cloud migrations, troubleshooting issues with cloud infrastructure, and ensuring the performance and security of cloud services.\n",
      "\n",
      "User: How can I begin working as a Technical Support Engineer?\n",
      "Assistant: Begin by gaining experience with IT systems, networking, and customer service. Pursue certifications like CompTIA A+ and Network+, and apply for junior or entry-level support positions.\n",
      "\n",
      "User: What is the average salary for a Web Developer?\n",
      "Assistant: The average salary for a Web Developer typically ranges from $50,000 to $85,000 annually, depending on experience, location, and company size.\n",
      "\n",
      "User: What are the essential skills for a successful Web Developer?\n",
      "Assistant: Essential skills include strong knowledge of HTML, CSS, JavaScript, experience with web development frameworks, version control tools like Git, familiarity with databases (SQL, NoSQL), and problem-solving skills.\n",
      "\n",
      "User: What skills are required to become a Data Visualization Specialist?\n",
      "Assistant: Skills required include proficiency in data visualization tools (e.g., Tableau, Power BI), strong knowledge of data analysis, data manipulation skills, understanding of design principles, and experience with programming languages such as Python or R.\n",
      "\n",
      "User: What is the average salary for a Sustainability Consultant?\n",
      "Assistant: The average salary for a Sustainability Consultant typically ranges from $50,000 to $70,000 annually, depending on location, experience, and industry.\n",
      "\n",
      "User: How much do Insurance Underwriters earn annually?\n",
      "Assistant: Insurance Underwriters generally earn between $50,000 and $70,000 annually, with senior underwriters or those in specialized roles potentially earning more.\n",
      "\n",
      "User: What difficulties do Claims Adjusters face in their jobs?\n",
      "Assistant: Difficulties include handling complex or disputed claims, managing multiple claims with tight deadlines, dealing with angry claimants, and staying updated with changing insurance laws and regulations.\n",
      "\n",
      "User: What are the daily tasks of an Account Manager?\n",
      "Assistant: Daily tasks include client meetings, managing and monitoring client accounts, tracking progress on deliverables, resolving client issues, preparing and sending reports, and maintaining communication with both clients and internal teams.\n",
      "\n",
      "User: What skills are required to become a Procurement Manager?\n",
      "Assistant: Skills required include strong negotiation abilities, knowledge of supply chain management, communication skills, analytical skills, problem-solving, and an understanding of procurement software and tools.\n",
      "\n",
      "User: What are the biggest challenges in being a Sustainability Consultant?\n",
      "Assistant: Challenges include convincing organizations to adopt sustainability practices, measuring the impact of sustainability efforts, managing client expectations, and staying up to date with ever-evolving environmental regulations.\n",
      "\n",
      "User: What does a typical day look like for an Operations Executive?\n",
      "Assistant: A typical day includes overseeing operations, managing resources, tracking performance metrics, analyzing processes for efficiency, coordinating between departments, and handling any operational issues that arise.\n",
      "\n",
      "User: Which programming languages are important for a Franchise Manager?\n",
      "Assistant: Programming languages are not typically necessary for a Franchise Manager. However, familiarity with franchise management software, POS systems, and business tools like Excel is useful.\n",
      "\n",
      "User: What are the biggest challenges in being a Cloud Database Engineer?\n",
      "Assistant: Challenges include managing large-scale databases, ensuring data security and compliance in cloud environments, optimizing performance across different cloud platforms, and handling the complexity of database migrations to the cloud.\n",
      "\n",
      "User: What difficulties do Cloud Consultants face in their jobs?\n",
      "Assistant: Difficulties include dealing with the complexity of cloud migration, managing clients' cloud budgets, ensuring the security of cloud infrastructure, and troubleshooting cloud performance issues.\n",
      "\n",
      "User: What are the daily tasks of a Market Development Manager (Junior level)?\n",
      "Assistant: Daily tasks include analyzing market trends, conducting research on industry competitors, working on go-to-market strategies, supporting the sales team with new market data, and assisting with marketing campaigns for new market segments.\n",
      "\n",
      "User: What problems does a Fundraising Manager typically encounter?\n",
      "Assistant: Problems include managing tight budgets, ensuring the success of fundraising events, dealing with donor concerns, and maintaining donor engagement over time.\n",
      "\n",
      "User: What work environment can a Web Developer expect?\n",
      "Assistant: Web Developers typically work in an office environment but can also work remotely. The work environment is often collaborative, with developers working closely with designers and other team members.\n",
      "\n",
      "User: What are the main responsibilities of a Travel Coordinator?\n",
      "Assistant: The main responsibilities include booking and managing travel arrangements, coordinating itineraries, handling travel-related paperwork, liaising with clients and travel service providers, and managing travel budgets and expenses.\n",
      "\n",
      "User: What does a typical day look like for an Affiliate Marketing Manager (Junior level)?\n",
      "Assistant: A typical day involves managing relationships with affiliates, tracking campaign performance, analyzing sales data, making recommendations for optimization, and collaborating with other marketing teams to align affiliate efforts with overall marketing goals.\n",
      "\n",
      "User: How can I begin working as an SEO Specialist?\n",
      "Assistant: Begin by learning the fundamentals of SEO through online courses, gaining hands-on experience by optimizing your own website or blog, and getting certified in SEO tools like Google Analytics or SEMrush. Internships or freelance opportunities can also help you gain practical experience.\n",
      "\n",
      "User: What work environment can a Fundraising Manager expect?\n",
      "Assistant: A Fundraising Manager typically works in an office environment, but the role may require attending events or meeting with donors outside of the office. Some travel may be required for events or donor meetings.\n",
      "\n",
      "User: What are the essential skills for a successful Insurance Underwriter?\n",
      "Assistant: Essential skills include attention to detail, the ability to assess and analyze risks, strong decision-making and communication abilities, knowledge of the insurance industry, and proficiency in using underwriting software.\n",
      "\n",
      "User: What tools does a Claims Adjuster typically use?\n",
      "Assistant: A Claims Adjuster typically uses claims management software, customer relationship management (CRM) tools, data analysis tools, and document management systems to track claims, assess damages, and communicate with clients.\n",
      "\n",
      "User: What does a typical day look like for a Legal Assistant?\n",
      "Assistant: A typical day involves preparing and filing legal documents, conducting legal research, organizing case files, assisting lawyers with trial preparation, and communicating with clients or witnesses. They may also attend meetings and hearings.\n",
      "\n",
      "User: Which programming languages are important for a Sustainability Consultant?\n",
      "Assistant: Programming languages are not typically required for a Sustainability Consultant. However, familiarity with data analysis tools like Excel, Power BI, and software for environmental impact modeling may be beneficial.\n",
      "\n",
      "User: What is the career growth path for an AI Researcher?\n",
      "Assistant: An AI Researcher can progress from junior research roles to senior researcher, research lead, and ultimately become a principal investigator or research director leading AI projects.\n",
      "\n",
      "User: What work environment can a Junior Scrum Master expect?\n",
      "Assistant: Junior Scrum Masters typically work in office environments, although remote or hybrid work is common in tech-related companies. They may work in a collaborative team setting with regular meetings and cross-functional team interactions.\n",
      "\n",
      "User: Which programming languages are important for a CSR Manager?\n",
      "Assistant: Programming languages are not typically required for a CSR Manager. However, familiarity with data analysis tools and software like Excel, Power BI, or CSR-specific platforms can help in measuring and reporting on CSR activities.\n",
      "\n",
      "User: What does a Data Analyst do on a daily basis?\n",
      "Assistant: A Data Analyst works on data extraction, data preparation, and using tools to create insightful reports or dashboards for decision-making.\n",
      "\n",
      "User: What is the job description for a Quality Control Manager?\n",
      "Assistant: A Quality Control Manager supervises the quality control processes within a production or manufacturing environment. They ensure that products meet quality standards, perform inspections, and maintain testing records.\n",
      "\n",
      "User: What is the typical career trajectory for a Customer Relationship Manager?\n",
      "Assistant: The typical trajectory begins with an entry-level position such as Junior Customer Relationship Manager, then advances to Senior Customer Relationship Manager, followed by roles like Customer Success Manager or Head of Customer Relations.\n",
      "\n",
      "User: What does a typical day look like for a Systems Administrator?\n",
      "Assistant: A typical day includes monitoring system performance, responding to support tickets, troubleshooting hardware and software issues, updating systems, managing backups, and ensuring network security.\n",
      "\n",
      "User: What problems does a Machine Learning Engineer typically encounter?\n",
      "Assistant: Common problems include overfitting or underfitting models, handling imbalanced data, and ensuring model interpretability and fairness in decision-making.\n",
      "\n",
      "User: What work environment can a UX/UI Designer expect?\n",
      "Assistant: UX/UI Designers typically work in office settings, but remote work options are common. They work in collaborative environments, closely interacting with developers, product managers, and marketing teams.\n",
      "\n",
      "User: What does a typical day look like for an Automation Engineer?\n",
      "Assistant: A typical day involves designing automation processes, writing and testing scripts, debugging automation systems, collaborating with developers, and monitoring automated workflows to ensure they run efficiently.\n",
      "\n",
      "User: What are the daily tasks of an Advertising Manager (Junior level)?\n",
      "Assistant: Daily tasks include reviewing ad performance, working with the creative team on ad design, preparing reports, managing budgets for campaigns, and ensuring all ads are properly placed on the chosen platforms.\n",
      "\n",
      "User: How much do Operations Executives earn annually?\n",
      "Assistant: Operations Executives generally earn between $45,000 and $60,000 annually, with variations based on experience, location, and the industry they work in.\n",
      "\n",
      "User: What is the typical career trajectory for a Game Developer?\n",
      "Assistant: The typical career trajectory starts with an entry-level Game Developer role, progresses to Senior Game Developer, Lead Game Developer, and may advance to roles like Game Director, Technical Director, or Studio Head.\n",
      "\n",
      "User: What does a Policy Advisor do?\n",
      "Assistant: A Policy Advisor provides expertise on public policies, assisting in their development, evaluation, and implementation. They analyze issues, recommend solutions, and work with stakeholders to create effective policy strategies.\n",
      "\n",
      "User: What work environment can a Sustainability Consultant expect?\n",
      "Assistant: Sustainability Consultants can expect to work in an office environment, though some travel to client sites may be required. Remote or hybrid work options are available in some organizations, especially for those working in consulting firms.\n",
      "\n",
      "User: What is the salary range for a Claims Adjuster?\n",
      "Assistant: The salary range for a Claims Adjuster typically falls between $45,000 and $60,000 per year, with potential increases based on experience, location, and level of responsibility.\n",
      "\n",
      "User: What work environment can a Claims Adjuster expect?\n",
      "Assistant: Claims Adjusters usually work in office environments but may also spend time in the field conducting investigations, meeting with claimants, or inspecting damaged properties. Some positions may offer remote work options.\n",
      "\n",
      "User: What technologies are commonly used in the Fundraising Manager role?\n",
      "Assistant: Technologies include CRM systems (e.g., Salesforce, DonorPerfect), event management software, email marketing platforms, and social media tools to engage with potential donors and promote fundraising campaigns.\n",
      "\n",
      "User: Which programming languages are important for a Product Owner?\n",
      "Assistant: Programming languages are not a core requirement for a Product Owner, but understanding the technical aspects of product development and being familiar with tools like JIRA or Confluence is important.\n",
      "\n",
      "User: What are the main responsibilities of a Fundraising Manager?\n",
      "Assistant: Main responsibilities include creating fundraising campaigns, managing donor relationships, organizing events, setting fundraising goals, researching potential donors, and tracking donations to ensure financial targets are met.\n",
      "\n",
      "User: What kind of companies hire Software Engineers?\n",
      "Assistant: Companies in the tech industry, e-commerce, finance, healthcare, and even non-tech industries hire Software Engineers to develop software systems and solutions.\n",
      "\n",
      "User: What work environment can an SEM Specialist expect?\n",
      "Assistant: SEM Specialists typically work in office environments within marketing teams, but remote work opportunities are increasingly common. The work environment is dynamic and fast-paced, with a focus on achieving measurable campaign goals.\n",
      "\n",
      "User: What work environment can a Customer Relationship Manager expect?\n",
      "Assistant: A Customer Relationship Manager typically works in an office environment, collaborating with other teams like sales, marketing, and product development. Some roles may offer remote or hybrid work arrangements.\n",
      "\n",
      "User: What are the main responsibilities of a Game Developer?\n",
      "Assistant: The main responsibilities include designing game mechanics, writing code to implement features, collaborating with artists and designers, testing and debugging games, and optimizing performance for different platforms.\n",
      "\n",
      "User: How do I progress in a career as a Technical Support Engineer?\n",
      "Assistant: To progress, gain experience with a variety of technical issues, develop expertise in specific software or hardware, and pursue certifications such as CompTIA A+, Network+, or ITIL.\n",
      "\n",
      "User: What is the salary range for a Web Developer?\n",
      "Assistant: The salary range for a Web Developer typically falls between $50,000 and $85,000 annually, with senior-level developers earning up to $100,000 or more in some regions.\n",
      "\n",
      "User: What skills are required to become a Cloud Consultant?\n",
      "Assistant: Skills include a strong understanding of cloud platforms (AWS, Azure, Google Cloud), knowledge of cloud migration processes, familiarity with security practices, and problem-solving skills in the context of cloud infrastructure.\n",
      "\n",
      "User: Which programming languages are important for an AI Researcher?\n",
      "Assistant: Important programming languages include Python, C++, and sometimes R for implementing machine learning algorithms and conducting research.\n",
      "\n",
      "User: What is the job description for a Business Analyst?\n",
      "Assistant: A Business Analyst is responsible for analyzing business processes, identifying challenges, and working with stakeholders to implement data-driven solutions. They also play a crucial role in project management and ensuring that business requirements are met.\n",
      "\n",
      "User: What difficulties do E-commerce Specialists face in their jobs?\n",
      "Assistant: Difficulties include managing high competition in the online market, ensuring smooth operations during high-traffic times (like holidays), handling inventory and shipping issues, and maintaining customer satisfaction.\n",
      "\n",
      "User: What are the biggest challenges in being a Quality Control Manager?\n",
      "Assistant: Challenges include ensuring product quality in high-volume environments, managing quality control teams, maintaining standards under pressure, and dealing with product defects or non-compliance.\n",
      "\n",
      "User: What kind of companies hire Application Support Analysts?\n",
      "Assistant: Companies that provide software services, enterprise-level IT departments, tech firms, and cloud service providers commonly hire Application Support Analysts.\n",
      "\n",
      "User: Which programming languages are important for a Data Visualization Specialist?\n",
      "Assistant: Important programming languages include Python and R, especially for creating custom visualizations and using libraries like Matplotlib, Seaborn, or Plotly. SQL is also important for data extraction.\n",
      "\n",
      "User: How much do Game Developers earn annually?\n",
      "Assistant: Game Developers typically earn between $50,000 and $100,000 annually, depending on their level of experience, expertise, and location. Senior or specialized roles can earn more.\n",
      "\n",
      "User: What are the daily tasks of a Product Owner?\n",
      "Assistant: Daily tasks include managing the product backlog, communicating with stakeholders, ensuring the development team understands the product requirements, making decisions to prioritize features, and keeping track of the product's progress.\n",
      "\n",
      "User: What is the salary range for a Data Scientist?\n",
      "Assistant: The salary range for a Data Scientist is approximately $70,000 to $180,000 annually, depending on expertise and the industry.\n",
      "\n",
      "User: How can I begin working as a Knowledge Manager?\n",
      "Assistant: Begin by gaining experience in roles related to information management, content management, or project management. Developing familiarity with knowledge management systems and tools can be helpful. Look for internships or junior-level positions to start building your career.\n",
      "\n",
      "User: Where do Business Analysts typically work?\n",
      "Assistant: Business Analysts work in a variety of industries, including finance, healthcare, IT, manufacturing, and consulting. They can be employed in both large corporations and smaller companies.\n",
      "\n",
      "User: Where do Technical Support Engineers typically work?\n",
      "Assistant: Technical Support Engineers work in various industries, including IT services, tech companies, financial institutions, healthcare, and telecommunications. They can work in-house or for managed service providers (MSPs).\n",
      "\n",
      "User: What work environment can an AI Researcher expect?\n",
      "Assistant: AI Researchers typically work in academic or corporate research labs, often in collaborative settings with other researchers, data scientists, and engineers. The work may involve a mix of lab-based, remote, and collaborative work.\n",
      "\n",
      "User: Do I need a degree to pursue a career as a Digital Marketing Analyst?\n",
      "Assistant: While a degree in Marketing or a related field is beneficial, it is not always necessary. Many successful Digital Marketing Analysts have gained skills through certifications, bootcamps, or hands-on experience.\n",
      "\n",
      "User: What is the salary range for an SEO Specialist?\n",
      "Assistant: The salary range for an SEO Specialist typically falls between $45,000 and $70,000 annually. Senior roles or positions at larger companies may offer higher salaries.\n",
      "\n",
      "User: What is the salary range for an AI Software Engineer?\n",
      "Assistant: The salary range for an AI Software Engineer is generally between $95,000 and $150,000 annually, but salaries can vary depending on experience, industry, and the complexity of the AI systems being developed.\n",
      "\n",
      "User: What are the educational requirements for a Retail Manager?\n",
      "Assistant: Educational requirements generally include a high school diploma, though a bachelor's degree in business, retail management, or a similar field can help advance one's career.\n",
      "\n",
      "User: What skills are required to become a Knowledge Manager?\n",
      "Assistant: Skills required include excellent communication and organizational skills, a strong understanding of information management systems, problem-solving abilities, and the ability to collaborate across different departments to collect and share knowledge.\n",
      "\n",
      "User: Which software should a Systems Administrator be proficient in?\n",
      "Assistant: A Systems Administrator should be proficient in system administration software like VMware, Hyper-V, and backup tools. They should also know network monitoring tools like Nagios and security software like firewalls and antivirus programs.\n",
      "\n",
      "User: What are the main responsibilities of a Franchise Manager?\n",
      "Assistant: Main responsibilities include supporting franchisees, ensuring compliance with franchise standards, assisting with marketing and sales efforts, managing operational processes, and overseeing staff training and development.\n",
      "\n",
      "User: What qualifications do I need to become a Junior Scrum Master?\n",
      "Assistant: A Bachelor's degree in a relevant field (like Computer Science or Business) is useful. A Scrum Master certification, like the Certified ScrumMaster (CSM), is highly recommended for entry-level positions.\n",
      "\n",
      "User: What are the daily tasks of a Web Developer?\n",
      "Assistant: Daily tasks include coding, testing new features, troubleshooting bugs, attending team meetings, reviewing code, and ensuring that websites and web applications are performing well.\n",
      "\n",
      "User: What are the educational requirements for an Insurance Underwriter?\n",
      "Assistant: The educational requirements generally include a high school diploma, with a preference for a bachelor's degree in business, finance, or insurance. Many employers also require or prefer certification in underwriting.\n",
      "\n",
      "User: What are the educational requirements for a Franchise Manager?\n",
      "Assistant: Typically, a high school diploma is required, although a bachelor's degree in business, management, or related fields may be preferred. Experience in retail or franchise environments is highly valued.\n",
      "\n",
      "User: What is the salary range for a Media Buyer?\n",
      "Assistant: The salary range for a Media Buyer typically falls between $50,000 and $70,000 annually, depending on factors such as experience, location, and company size.\n",
      "\n",
      "User: What difficulties do Business Analysts face in their jobs?\n",
      "Assistant: Business Analysts often face difficulties in gathering clear requirements, dealing with unclear project goals, balancing priorities, and ensuring that the proposed solutions are feasible within the given budget and timeframe.\n",
      "\n",
      "User: What is the salary range for a Cloud Consultant?\n",
      "Assistant: The salary range for a Cloud Consultant typically falls between $60,000 and $100,000 annually, with senior roles or those with advanced certifications earning more.\n",
      "\n",
      "User: What does a Business Analyst do?\n",
      "Assistant: A Business Analyst evaluates business processes, identifies areas for improvement, and recommends solutions to enhance efficiency. They gather requirements from stakeholders and help bridge the gap between business needs and technology solutions.\n",
      "\n",
      "User: What is the salary range for a Knowledge Manager?\n",
      "Assistant: The salary range for a Knowledge Manager generally falls between $50,000 and $80,000 annually, but this can vary depending on experience, location, and industry.\n",
      "\n",
      "User: What is the average salary for a Cloud Database Engineer?\n",
      "Assistant: The average salary for a Cloud Database Engineer typically ranges from $80,000 to $120,000 annually, depending on experience, location, and certifications.\n",
      "\n",
      "User: What are the daily tasks of a Policy Advisor?\n",
      "Assistant: Daily tasks include gathering and analyzing data on policy issues, writing policy briefs, drafting reports, meeting with stakeholders, and helping to develop strategies for policy implementation.\n",
      "\n",
      "User: What are the daily tasks of a Data Visualization Specialist?\n",
      "Assistant: Daily tasks include data extraction, cleaning, and preparation, creating and refining visualizations, collaborating with teams to ensure the visualizations meet business needs, and presenting findings in meetings or reports.\n",
      "\n",
      "User: What problems does a Procurement Manager typically encounter?\n",
      "Assistant: Procurement Managers often encounter issues related to supply chain disruptions, supplier performance, inventory management, negotiation challenges, and ensuring that procurement processes are cost-effective.\n",
      "\n",
      "User: What are the entry-level requirements for a Travel Coordinator?\n",
      "Assistant: Entry-level requirements typically include a Bachelor’s degree in a related field like Tourism, Business, or Hospitality, and some experience in customer service or travel-related roles.\n",
      "\n",
      "User: What are the essential skills for a successful QA Engineer?\n",
      "Assistant: Essential skills include expertise in manual and automated testing, proficiency with testing tools (like Selenium, QTP, JUnit), understanding of bug-tracking systems, and strong analytical and debugging skills.\n",
      "\n",
      "User: What is the job description for a Franchise Manager?\n",
      "Assistant: A Franchise Manager is responsible for ensuring franchise locations follow brand guidelines, monitoring franchisee performance, providing support, assisting with the recruitment of franchisees, and helping to expand the business.\n",
      "\n",
      "User: What difficulties do Product Owners face in their jobs?\n",
      "Assistant: Difficulties include dealing with conflicting feedback from stakeholders, prioritizing tasks with limited resources, maintaining the product roadmap, and ensuring that the development team delivers features as expected.\n",
      "\n",
      "User: What technologies are commonly used in the Junior Scrum Master role?\n",
      "Assistant: Technologies often used include project management software (Jira, Trello), collaboration tools (Slack, Microsoft Teams), and documentation tools (Confluence). Familiarity with Agile development tools is key.\n",
      "\n",
      "User: What are the essential skills for a successful Affiliate Marketing Manager (Junior level)?\n",
      "Assistant: Essential skills include proficiency in affiliate marketing platforms, strong analytical and reporting skills, creativity in developing marketing strategies, and effective relationship management with affiliate partners.\n",
      "\n",
      "User: Where do Franchise Managers typically work?\n",
      "Assistant: Franchise Managers typically work for companies that operate franchises, including food chains, retail brands, fitness centers, and other businesses that use the franchise model.\n",
      "\n",
      "User: How much do Retail Managers earn annually?\n",
      "Assistant: Retail Managers generally earn between $40,000 and $50,000 annually, with variations based on the store's size, location, and the individual’s experience.\n",
      "\n",
      "User: What are the educational requirements for a Web Developer?\n",
      "Assistant: The educational requirements usually include a Bachelor's degree in Computer Science or a related field, but many developers also gain experience through coding boot camps or self-taught skills.\n",
      "\n",
      "User: What are the entry-level requirements for a Data Scientist?\n",
      "Assistant: Entry-level roles typically require knowledge of Python, SQL, basic machine learning concepts, and experience with data analysis tools.\n",
      "\n",
      "User: What are the essential skills for a successful Automation Engineer?\n",
      "Assistant: Essential skills include proficiency in programming languages like Python or Java, experience with automation frameworks such as Selenium and Jenkins, strong knowledge of CI/CD pipelines, and an understanding of testing and system integration.\n",
      "\n",
      "User: How much do Media Buyers earn annually?\n",
      "Assistant: The salary for a Media Buyer usually ranges from $50,000 to $70,000 per year, but this can vary depending on experience, industry, and geographic location.\n",
      "\n",
      "User: What is the average salary for a Data Analyst?\n",
      "Assistant: The average salary for a Data Analyst ranges from $50,000 to $85,000 annually in the United States, depending on experience and location.\n",
      "\n",
      "User: What are the entry-level requirements for an SEO Specialist?\n",
      "Assistant: Entry-level requirements typically include a basic understanding of SEO, keyword research, and content optimization. Some employers may require a degree in marketing or communications, but hands-on experience and SEO certifications can also help.\n",
      "\n",
      "User: What is the job description for a Web Developer?\n",
      "Assistant: A Web Developer creates, tests, and maintains websites and web applications. They work with HTML, CSS, JavaScript, and various web technologies to ensure that websites are functional, visually appealing, and easy to use.\n",
      "\n",
      "User: Which programming languages are important for a Game Developer?\n",
      "Assistant: Important programming languages for a Game Developer include C++, C#, Java, Python, and scripting languages like Lua. Proficiency in languages supported by game engines (e.g., Unity’s C# or Unreal’s C++) is essential.\n",
      "\n",
      "User: What problems does a Cloud Consultant typically encounter?\n",
      "Assistant: Typical problems include data migration challenges, maintaining security compliance, optimizing cloud resources to reduce costs, and integrating on-premise systems with the cloud.\n",
      "\n",
      "User: What difficulties do Data Scientists face in their jobs?\n",
      "Assistant: Difficulties include integrating data from various sources, ensuring data quality, and staying updated with rapidly evolving tools and techniques.\n",
      "\n",
      "User: What are the educational requirements for an AI Researcher?\n",
      "Assistant: AI Researchers typically hold a PhD in AI, machine learning, or computer science. A strong academic background in mathematics and algorithmic principles is also crucial.\n",
      "\n",
      "User: Which software should a Franchise Manager be proficient in?\n",
      "Assistant: A Franchise Manager should be proficient in franchise management software, POS systems, scheduling and employee management software, and business reporting tools such as Excel.\n",
      "\n",
      "User: What is the career growth path for a Technical Support Engineer?\n",
      "Assistant: The career path can lead to roles like Senior Technical Support Engineer, IT Support Manager, Systems Administrator, or even specialized roles like Network Engineer or IT Consultant.\n",
      "\n",
      "User: What is the career growth path for a CSR Manager?\n",
      "Assistant: The career path generally begins with an entry-level CSR Manager role, moving to a Senior CSR Manager or CSR Lead. With experience, one may progress to roles like CSR Director or Vice President of CSR.\n",
      "\n",
      "User: What tools does an SEO Specialist typically use?\n",
      "Assistant: An SEO Specialist typically uses tools like Google Analytics, Google Search Console, SEMrush, Ahrefs, Moz, Screaming Frog, and keyword research tools like Ubersuggest to optimize and monitor websites.\n",
      "\n",
      "User: What is the salary range for a Business Intelligence Analyst?\n",
      "Assistant: The salary range for a Business Intelligence Analyst is usually between $70,000 and $100,000 annually. Senior roles or those with specialized skills can earn higher salaries, reaching up to $120,000 or more.\n",
      "\n",
      "User: What is the average salary for a CSR Manager?\n",
      "Assistant: The average salary for a CSR Manager typically ranges from $50,000 to $75,000 annually, depending on location, experience, and industry.\n",
      "\n",
      "User: What does an AI Software Engineer do on a daily basis?\n",
      "Assistant: On a daily basis, an AI Software Engineer designs AI models, tests their performance, fine-tunes algorithms, and collaborates with other engineers and data scientists to ensure the integration and optimization of AI systems in production.\n",
      "\n",
      "User: What does an Insurance Underwriter do?\n",
      "Assistant: An Insurance Underwriter evaluates and assesses the risks of insuring clients. They analyze applications for insurance coverage, determine appropriate premiums, and decide whether to approve or deny coverage based on the client's risk profile.\n",
      "\n",
      "User: Do I need a degree to pursue a career as a Machine Learning Engineer?\n",
      "Assistant: While a degree is helpful, many Machine Learning Engineers enter the field through self-study, online courses, and hands-on experience with machine learning projects.\n",
      "\n",
      "User: What does a typical day look like for a Data Analyst?\n",
      "Assistant: A typical day involves querying databases, analyzing datasets, creating visualizations, and meeting with teams to discuss insights and recommendations.\n",
      "\n",
      "User: What problems does an AI Researcher typically encounter?\n",
      "Assistant: Common problems include dealing with overfitting in models, lack of sufficient labeled data, high computational resource requirements, and the need to balance theory and practical applications.\n",
      "\n",
      "User: What is the salary range for a QA Engineer?\n",
      "Assistant: The salary range for a QA Engineer is between $50,000 and $80,000 annually for entry-level to mid-career roles. Senior or specialized roles can command higher salaries.\n",
      "\n",
      "User: What are the main responsibilities of a Policy Advisor?\n",
      "Assistant: The main responsibilities include researching and analyzing policy issues, drafting policy briefs, advising government officials or organizations, collaborating with stakeholders, and helping to shape public policy strategies.\n",
      "\n",
      "User: What difficulties do QA Engineers face in their jobs?\n",
      "Assistant: QA Engineers often face challenges such as managing high volumes of tests, ensuring that software is free of defects within short timelines, and coordinating with multiple teams to resolve issues quickly.\n",
      "\n",
      "User: What are the educational requirements for a Cloud Database Engineer?\n",
      "Assistant: The typical educational requirement is a Bachelor's degree in Computer Science, Information Technology, or Engineering, with additional cloud certifications (e.g., AWS Certified Database) to strengthen your expertise.\n",
      "\n",
      "User: What skills are required to become a Sustainability Consultant?\n",
      "Assistant: Skills required include knowledge of environmental regulations, data analysis, project management, communication, and problem-solving. A strong understanding of sustainability practices, climate change, and resource management is essential.\n",
      "\n",
      "User: What skills are required to become a Franchise Manager?\n",
      "Assistant: Skills required include leadership, communication, project management, problem-solving, sales, customer service, and knowledge of franchise operations and business management.\n",
      "\n",
      "User: Which software should a Social Media Analyst be proficient in?\n",
      "Assistant: A Social Media Analyst should be proficient in social media management tools (Hootsuite, Buffer), analytics software (Google Analytics, Sprout Social), and data visualization tools (Tableau, Power BI) for reporting and tracking social media performance.\n",
      "\n",
      "User: What kind of companies hire AI Software Engineers?\n",
      "Assistant: Tech companies, AI startups, large corporations with AI needs, financial institutions, healthcare organizations, and research labs commonly hire AI Software Engineers.\n",
      "\n",
      "User: What difficulties do Content Strategists face in their jobs?\n",
      "Assistant: Content Strategists face challenges such as maintaining consistency across multiple content channels, dealing with changing algorithms, managing large amounts of content, and ensuring content is both creative and measurable in terms of performance.\n",
      "\n",
      "User: What is the job description for a Legal Assistant?\n",
      "Assistant: A Legal Assistant supports attorneys by preparing documents for court filings, conducting legal research, organizing case files, drafting correspondence, and assisting in trial preparations. They ensure that all legal documentation is accurate and filed on time.\n",
      "\n",
      "User: What does a Product Manager do?\n",
      "Assistant: A Product Manager is responsible for the strategy, roadmap, and feature definition of a product. They act as the bridge between the development team, stakeholders, and customers to ensure the product aligns with business goals.\n",
      "\n",
      "User: How can I begin working as a Product Manager?\n",
      "Assistant: You can begin by seeking entry-level PM roles, gaining relevant certifications (e.g., Certified Scrum Product Owner), and learning key product management concepts. Internships or assistant PM roles can provide valuable experience.\n",
      "\n",
      "User: What difficulties do Technical Support Engineers face in their jobs?\n",
      "Assistant: Difficulties include diagnosing difficult technical issues, balancing multiple service requests, managing customer expectations, and staying up-to-date with evolving technologies.\n",
      "\n",
      "User: Where do Affiliate Marketing Managers (Junior level) typically work?\n",
      "Assistant: Affiliate Marketing Managers typically work in digital marketing agencies, e-commerce companies, and businesses that rely heavily on affiliate marketing to drive sales.\n",
      "\n",
      "User: What are the daily tasks of an Application Support Analyst?\n",
      "Assistant: Daily tasks include reviewing application performance, managing incident tickets, providing support to users, analyzing logs for errors, coordinating with developers for bug fixes, and performing routine maintenance to ensure optimal application functionality.\n",
      "\n",
      "User: Which software should an E-commerce Specialist be proficient in?\n",
      "Assistant: An E-commerce Specialist should be proficient in e-commerce platforms (Shopify, WooCommerce), email marketing software (Mailchimp), SEO tools (SEMrush, Ahrefs), and analytics tools (Google Analytics, Excel).\n",
      "\n",
      "User: What tools does an Automation Engineer typically use?\n",
      "Assistant: Automation Engineers typically use tools such as Selenium, Jenkins, Ansible, Puppet, Chef, Docker, and various testing frameworks like JUnit, TestNG, and LoadRunner for automating processes and tasks.\n",
      "\n",
      "User: What work environment can a Knowledge Manager expect?\n",
      "Assistant: A Knowledge Manager can expect to work in an office environment, collaborating with teams across departments. Many companies offer remote or hybrid work opportunities, especially in the technology sector.\n",
      "\n",
      "User: What problems does a Data Scientist typically encounter?\n",
      "Assistant: Common problems include data inconsistencies, unclear project objectives, and balancing the need for speed with accuracy in model development.\n",
      "\n",
      "User: What is the typical career trajectory for an SEM Specialist?\n",
      "Assistant: The career trajectory typically starts with a Junior SEM Specialist or SEM Assistant role. With experience, you can move into Senior SEM Specialist, SEM Manager, and eventually take on roles like Digital Marketing Manager or Paid Search Director.\n",
      "\n",
      "User: What problems does a Software Engineer typically encounter?\n",
      "Assistant: Common problems include dealing with unstructured requirements, handling bugs, optimizing performance, and ensuring that software integrates well with other systems.\n",
      "\n",
      "User: What problems does a Content Strategist typically encounter?\n",
      "Assistant: Typical problems include staying on top of SEO trends, ensuring timely content production, managing multiple content campaigns, optimizing content for different channels, and measuring content effectiveness.\n",
      "\n",
      "User: What does a Fundraising Manager do on a daily basis?\n",
      "Assistant: On a daily basis, a Fundraising Manager may research prospective donors, update donor databases, respond to donor inquiries, prepare promotional materials, plan events, and track fundraising efforts to meet goals.\n",
      "\n",
      "User: What are the main responsibilities of a Technical Support Engineer?\n",
      "Assistant: The main responsibilities include troubleshooting and resolving technical issues, providing customer support via phone, email, or chat, maintaining documentation of issues and resolutions, and ensuring customer satisfaction.\n",
      "\n",
      "User: What is the typical career trajectory for a Claims Adjuster?\n",
      "Assistant: The typical trajectory starts with an entry-level Claims Adjuster position, progressing to Senior Claims Adjuster, then to Claims Supervisor or Manager, and possibly advancing to Claims Director or other leadership roles in insurance companies.\n",
      "\n",
      "User: What are the entry-level requirements for a Media Buyer?\n",
      "Assistant: Entry-level requirements typically include a Bachelor’s degree in Marketing, Advertising, or Communications, along with an understanding of media buying and advertising principles. Internships or hands-on experience in digital marketing can also be helpful.\n",
      "\n",
      "User: What is the salary range for an AI Researcher?\n",
      "Assistant: The salary range for an AI Researcher typically varies from $80,000 to $160,000 annually, depending on experience and job location.\n",
      "\n",
      "User: What are the daily tasks of a Sustainability Consultant?\n",
      "Assistant: Daily tasks include reviewing environmental impact data, assessing energy usage and waste management practices, meeting with clients to discuss sustainability goals, preparing reports, and developing recommendations for improving sustainability efforts.\n",
      "\n",
      "User: What are the essential skills for a successful Legal Assistant?\n",
      "Assistant: Essential skills include excellent organizational and time management abilities, attention to detail, strong written and verbal communication skills, familiarity with legal terminology, and the ability to handle sensitive information with discretion.\n",
      "\n",
      "User: What are the essential skills for a successful Knowledge Manager?\n",
      "Assistant: Essential skills include communication, information management, data analysis, project management, collaboration, and proficiency in knowledge management tools and software like SharePoint or Confluence.\n",
      "\n",
      "User: What qualifications do I need to become a Digital Marketing Analyst?\n",
      "Assistant: Qualifications typically include a Bachelor's degree in Marketing, Business, or a related field. Additional certifications in digital marketing tools and platforms (Google Analytics, Google Ads, etc.) are also beneficial.\n",
      "\n",
      "User: What is the career growth path for a Social Media Analyst?\n",
      "Assistant: The career growth path for a Social Media Analyst can include advancing to roles like Senior Social Media Analyst, Social Media Manager, Digital Marketing Manager, or even Digital Marketing Director. With experience, one may also transition to strategic roles like Brand Manager.\n",
      "\n",
      "User: What are the biggest challenges in being an SEM Specialist?\n",
      "Assistant: Challenges include keeping up with constant changes to search engine algorithms, managing large advertising budgets, dealing with competition in paid search auctions, and ensuring a high return on investment (ROI) for campaigns.\n",
      "\n",
      "User: What technologies are commonly used in the SEO Specialist role?\n",
      "Assistant: Common technologies include Google Analytics, Google Search Console, SEO tools (SEMrush, Ahrefs, Moz), CMS platforms like WordPress, website auditing tools, and page speed analysis tools.\n",
      "\n",
      "User: What is the salary range for a Software Engineer?\n",
      "Assistant: The salary range for a Software Engineer is typically $60,000 to $150,000 annually, depending on skill level and experience.\n",
      "\n",
      "User: How do I progress in a career as an SEO Specialist?\n",
      "Assistant: To progress, focus on gaining in-depth knowledge of SEO tools, search engine algorithms, and analytics. Continuously refine your skills, build a strong portfolio, and take on leadership roles in SEO campaigns to advance your career.\n",
      "\n",
      "User: Which software should a Data Analyst be proficient in?\n",
      "Assistant: Proficiency in Excel, SQL, Tableau, Power BI, and scripting languages like Python or R is highly recommended.\n",
      "\n",
      "User: How can I begin working as a Digital Marketing Manager (Junior level)?\n",
      "Assistant: Begin by gaining practical experience through internships or junior roles in digital marketing. Pursue certifications from Google and other platforms, and build a strong understanding of SEO, content creation, and digital advertising.\n",
      "\n",
      "User: How do I start a career as an Operations Executive?\n",
      "Assistant: Start by gaining experience in entry-level operations or administrative roles, pursue a degree in business administration or management, and consider certifications in project management or process optimization.\n",
      "\n",
      "User: What does a typical day look like for an SEO Specialist?\n",
      "Assistant: A typical day involves conducting keyword research, analyzing website performance, optimizing content, tracking SEO metrics, collaborating with content creators, fixing technical SEO issues, and staying updated with search engine algorithm changes.\n",
      "\n",
      "User: What are the main responsibilities of a Data Scientist?\n",
      "Assistant: Responsibilities include data cleaning, analyzing large datasets, building predictive models, creating data visualizations, and communicating insights to stakeholders.\n",
      "\n",
      "User: What kind of companies hire Quality Control Managers?\n",
      "Assistant: Companies in manufacturing, pharmaceuticals, food production, automotive, and electronics typically hire Quality Control Managers to ensure product quality meets standards.\n",
      "\n",
      "User: What are the educational requirements for an SEO Specialist?\n",
      "Assistant: Educational requirements typically include a Bachelor's degree in Marketing, Communications, or a related field. Some employers may also look for candidates with specific certifications in SEO and web analytics.\n",
      "\n",
      "User: Do I need a degree to pursue a career as a Junior Scrum Master?\n",
      "Assistant: While a degree is not always mandatory, a degree in a related field (such as Computer Science, Business, or Management) can be beneficial. Scrum Master certifications are essential for getting started.\n",
      "\n",
      "User: Where do Data Analysts typically work?\n",
      "Assistant: Data Analysts work in industries like finance, healthcare, e-commerce, retail, and technology, often employed by corporations, startups, or consulting firms.\n",
      "\n",
      "User: What technologies are commonly used in the Software Engineer role?\n",
      "Assistant: Common technologies include web frameworks (e.g., React, Angular), backend frameworks (e.g., Node.js, Django), databases (e.g., SQL, MongoDB), and cloud platforms (e.g., AWS, Azure).\n",
      "\n",
      "User: What tools does a Business Intelligence Analyst typically use?\n",
      "Assistant: Business Intelligence Analysts typically use BI tools like Power BI, Tableau, and QlikView for data visualization and reporting. They also use SQL-based tools for data querying and may use Excel for data manipulation.\n",
      "\n",
      "User: What technologies are commonly used in the Insurance Underwriter role?\n",
      "Assistant: Technologies used include underwriting software, data analysis tools, customer relationship management (CRM) systems, and document management tools to process applications and determine policy terms.\n",
      "\n",
      "User: What is the career growth path for a Salesforce Administrator?\n",
      "Assistant: The career growth path for a Salesforce Administrator typically starts with the administrator role, progressing to Senior Salesforce Administrator, Salesforce Developer, Salesforce Architect, and potentially Salesforce Consultant or Manager roles.\n",
      "\n",
      "User: How do I start a career as a Robotics Engineer?\n",
      "Assistant: To start, focus on obtaining a relevant degree (e.g., Robotics, Mechanical Engineering, Electrical Engineering) and gain hands-on experience with robotic systems, programming, and hardware design through internships or personal projects.\n",
      "\n",
      "User: How do I progress in a career as a Knowledge Manager?\n",
      "Assistant: To progress, build expertise in knowledge management systems and practices, gain experience in managing teams or projects, and seek opportunities to demonstrate leadership and contribute to strategic knowledge-sharing initiatives.\n",
      "\n",
      "User: What does a typical day look like for a Policy Advisor?\n",
      "Assistant: A typical day involves researching policy issues, preparing reports or policy briefs, attending meetings with stakeholders, analyzing data, and advising senior officials or organizations on policy decisions.\n",
      "\n",
      "User: What technologies are commonly used in the Robotics Engineer role?\n",
      "Assistant: Common technologies include automation systems, robotics programming languages (C++, Python, ROS), embedded systems, AI and machine learning for robotics, sensors, actuators, and control systems.\n",
      "\n",
      "User: What kind of companies hire Business Intelligence Analysts?\n",
      "Assistant: Companies that rely heavily on data-driven decision-making, such as tech companies, financial institutions, retail businesses, and healthcare organizations, hire Business Intelligence Analysts.\n",
      "\n",
      "User: What skills are required to become an Operations Executive?\n",
      "Assistant: Skills required include strong organizational abilities, time management, problem-solving, attention to detail, excellent communication, multitasking, and the ability to analyze and improve operational processes.\n",
      "\n",
      "User: What are the biggest challenges in being a Business Analyst?\n",
      "Assistant: Challenges include managing stakeholder expectations, balancing business needs with technical constraints, ensuring effective communication between departments, and dealing with ambiguous requirements.\n",
      "\n",
      "User: What are the essential skills for a successful AI Software Engineer?\n",
      "Assistant: Essential skills include strong coding abilities in Python, proficiency in AI/ML frameworks (TensorFlow, PyTorch), experience with algorithms and data structures, familiarity with cloud platforms, and a solid understanding of neural networks and machine learning models.\n",
      "\n",
      "User: What tools does a Cloud Consultant typically use?\n",
      "Assistant: Tools include cloud platforms (AWS, Azure, Google Cloud), infrastructure management tools (Terraform, CloudFormation), and monitoring tools (CloudWatch, Stackdriver).\n",
      "\n",
      "User: How do I start a career as a Business Intelligence Analyst?\n",
      "Assistant: To start, learn key BI tools (e.g., Power BI, Tableau), become proficient in SQL and data analysis, and pursue a degree in a relevant field. An internship or entry-level position in a data-related role can provide practical experience.\n",
      "\n",
      "User: What qualifications do I need to become a Media Buyer?\n",
      "Assistant: Qualifications typically include a Bachelor’s degree in Marketing, Advertising, Communications, or a related field. Experience in media buying, advertising, or digital marketing is also valuable.\n",
      "\n",
      "User: What is the salary range for a Policy Advisor?\n",
      "Assistant: The salary range for a Policy Advisor typically falls between $50,000 and $75,000 annually, with variation depending on location, experience, and the size of the employer.\n",
      "\n",
      "User: What is the career growth path for an Account Manager?\n",
      "Assistant: The career growth path can start as a Junior Account Manager, progressing to a Senior Account Manager, then to an Account Director or Manager, and eventually into leadership roles such as Client Services Manager or Head of Accounts.\n",
      "\n",
      "User: What does a typical day look like for a Sustainability Consultant?\n",
      "Assistant: A typical day for a Sustainability Consultant involves analyzing an organization’s environmental practices, preparing sustainability reports, advising on reducing energy consumption, waste management, and improving overall environmental performance.\n",
      "\n",
      "User: What is the career growth path for an Insurance Underwriter?\n",
      "Assistant: The career growth path typically starts with an entry-level Insurance Underwriter position, progressing to senior underwriting roles. With experience, one can advance to positions such as Senior Underwriter, Underwriting Manager, or even Head of Underwriting.\n",
      "\n",
      "User: What is the job description for a Fundraising Manager?\n",
      "Assistant: The job involves developing fundraising strategies, identifying fundraising opportunities, building relationships with donors, managing campaigns, preparing materials, and reporting on fundraising results. It also involves event planning and coordination.\n",
      "\n",
      "User: How do I start a career as an SEM Specialist?\n",
      "Assistant: Start by learning the basics of SEM through online courses or certifications in Google Ads and Google Analytics. Practice by running your own PPC campaigns, build a portfolio, and look for internships or entry-level roles to gain hands-on experience.\n",
      "\n",
      "User: Where do Cloud Database Engineers typically work?\n",
      "Assistant: Cloud Database Engineers work for tech companies, cloud service providers, consulting firms, and large enterprises that rely on cloud-based database solutions. Many work remotely or in hybrid environments.\n",
      "\n",
      "User: What does a Social Media Analyst do on a daily basis?\n",
      "Assistant: On a daily basis, a Social Media Analyst monitors social media platforms, tracks key performance indicators (KPIs), compiles data into reports, engages with social media teams to optimize strategies, and analyzes trends to guide future campaigns.\n",
      "\n",
      "User: What work environment can an Insurance Underwriter expect?\n",
      "Assistant: Insurance Underwriters typically work in office environments but may also have occasional fieldwork to meet with agents, brokers, or clients. Many positions offer flexible work options, including remote work.\n",
      "\n",
      "User: What does a typical day look like for an E-commerce Specialist?\n",
      "Assistant: A typical day includes managing product listings, analyzing sales data, optimizing marketing campaigns, troubleshooting website issues, and working with other departments to improve the user experience and sales performance.\n",
      "\n",
      "User: Where do E-commerce Specialists typically work?\n",
      "Assistant: E-commerce Specialists can work in a variety of industries, including retail, tech, and consumer goods. They may be employed by online retailers, e-commerce platforms, or digital marketing agencies.\n",
      "\n",
      "User: What qualifications do I need to become a Knowledge Manager?\n",
      "Assistant: Typically, a Bachelor's degree in Business Administration, Information Management, or a related field is required. Some positions may also require certifications in knowledge management or project management.\n",
      "\n",
      "User: What work environment can a Software Engineer expect?\n",
      "Assistant: Software Engineers often work in collaborative environments with other developers, product managers, and designers, with opportunities for remote or in-office work depending on the company.\n",
      "\n",
      "User: How do I start a career as a Legal Assistant?\n",
      "Assistant: To start, seek entry-level positions in law firms or corporate legal departments. Obtain relevant certifications or complete a legal assistant program to improve job prospects.\n",
      "\n",
      "User: Which programming languages are important for an Insurance Underwriter?\n",
      "Assistant: Programming languages are typically not necessary for an Insurance Underwriter role. However, familiarity with data analysis tools and insurance-related software is beneficial.\n",
      "\n",
      "User: What does a Software Engineer do?\n",
      "Assistant: A Software Engineer designs, develops, tests, and maintains software applications, ensuring that they meet functional and non-functional requirements.\n",
      "\n",
      "User: What is the job description for a Social Media Analyst?\n",
      "Assistant: A Social Media Analyst collects and analyzes data from social media platforms to help businesses understand audience behavior. They monitor social media trends, generate reports, track KPIs, and provide recommendations to improve social media marketing strategies.\n",
      "\n",
      "User: What tools does a Franchise Manager typically use?\n",
      "Assistant: Franchise Managers typically use franchise management software, scheduling tools, POS systems, customer relationship management (CRM) systems, and business reporting tools like Excel or Google Sheets.\n",
      "\n",
      "User: Which software should a Content Strategist be proficient in?\n",
      "Assistant: A Content Strategist should be proficient in content management systems (WordPress, HubSpot), SEO tools (SEMrush, Moz, Ahrefs), analytics platforms (Google Analytics, Social Media Insights), and project management tools (Trello, Asana).\n",
      "\n",
      "User: What is the salary range for a Fundraising Manager?\n",
      "Assistant: The salary range for a Fundraising Manager typically falls between $45,000 and $55,000 annually, with variations depending on experience, location, and the organization’s size.\n",
      "\n",
      "User: What qualifications do I need to become a Salesforce Administrator?\n",
      "Assistant: A Bachelor's degree in Computer Science or a related field is common, along with hands-on experience with Salesforce. Salesforce Administrator certification is highly recommended.\n",
      "\n",
      "User: What is the salary range for a Site Reliability Engineer (SRE)?\n",
      "Assistant: The salary range for a Site Reliability Engineer typically falls between $90,000 and $150,000 annually, with senior professionals earning above $160,000.\n",
      "\n",
      "User: How can I begin working as a Salesforce Administrator?\n",
      "Assistant: To begin, obtain Salesforce Administrator certification, gain hands-on experience with Salesforce by taking on internships or freelance projects, and join Salesforce communities to network with professionals.\n",
      "\n",
      "User: Do I need a degree to pursue a career as a Technical Support Engineer?\n",
      "Assistant: While a degree can be helpful, it is not always necessary. Many Technical Support Engineers start with certifications like CompTIA A+ or Network+ and gain experience through entry-level roles.\n",
      "\n",
      "User: What kind of companies hire QA Engineers?\n",
      "Assistant: QA Engineers are hired by software development companies, tech startups, e-commerce platforms, financial institutions, and companies that develop or maintain software products.\n",
      "\n",
      "User: What does a CSR Manager do on a daily basis?\n",
      "Assistant: On a daily basis, a CSR Manager engages with internal teams to implement CSR initiatives, monitors the progress of CSR projects, manages relationships with external stakeholders, and ensures all CSR activities align with company objectives.\n",
      "\n",
      "User: What is the salary range for a Digital Marketing Manager (Junior level)?\n",
      "Assistant: The salary range for a Junior Digital Marketing Manager typically falls between $45,000 and $65,000 annually, with senior roles or positions in larger companies offering higher salaries.\n",
      "\n",
      "User: Which software should a Business Analyst be proficient in?\n",
      "Assistant: A Business Analyst should be proficient in Microsoft Excel, SQL, Tableau, Power BI, and process mapping tools like Visio. They should also be familiar with project management tools like JIRA or Trello.\n",
      "\n",
      "User: What qualifications do I need to become an Operations Executive?\n",
      "Assistant: Qualifications typically include a bachelor's degree in business administration, management, or a related field. Some employers may also value certifications in project management or process improvement methodologies.\n",
      "\n",
      "User: How do I progress in a career as a Business Intelligence Analyst?\n",
      "Assistant: To progress, enhance your skills in data visualization tools, SQL, and analytics. Pursue advanced certifications, and gain experience in managing BI projects and working with large datasets.\n",
      "\n",
      "User: Which programming languages are important for a Retail Manager?\n",
      "Assistant: Programming languages are generally not required for a Retail Manager. However, knowledge of retail management software, POS systems, and inventory management tools is useful.\n",
      "\n",
      "User: Which software should a Robotics Engineer be proficient in?\n",
      "Assistant: A Robotics Engineer should be proficient in CAD software (e.g., SolidWorks), robotics programming environments (e.g., ROS), simulation tools (e.g., Gazebo), and control system design software (e.g., MATLAB, Simulink).\n",
      "\n",
      "User: What work environment can a Procurement Manager expect?\n",
      "Assistant: A Procurement Manager can expect to work in an office environment, but may also visit suppliers' facilities, warehouses, or production sites. They work closely with various departments like finance, logistics, and operations.\n",
      "\n",
      "User: What tools does a Junior Scrum Master typically use?\n",
      "Assistant: Tools commonly used include project management software like Jira or Trello, communication tools like Slack or Microsoft Teams, and documentation tools for meeting notes, like Confluence.\n",
      "\n",
      "User: What skills are required to become a Content Strategist?\n",
      "Assistant: Skills required include content creation and editing, understanding SEO and digital marketing, project management, strong writing and communication skills, proficiency in analytics tools (like Google Analytics), and an understanding of brand voice and messaging.\n",
      "\n",
      "User: Which programming languages are important for an AI Software Engineer?\n",
      "Assistant: Programming languages important for an AI Software Engineer include Python (for machine learning and deep learning), Java, C++, and sometimes R. Familiarity with scripting languages and tools for data processing is also helpful.\n",
      "\n",
      "User: What are the main responsibilities of a Knowledge Manager?\n",
      "Assistant: The main responsibilities include overseeing knowledge-sharing processes, managing information systems, collaborating with other departments to ensure knowledge is captured, and creating and maintaining documentation and training materials.\n",
      "\n",
      "User: What does a Data Scientist do on a daily basis?\n",
      "Assistant: A Data Scientist works on cleaning data, creating predictive models, analyzing data trends, and preparing reports to drive data-driven decisions.\n",
      "\n",
      "User: Where do Site Reliability Engineers typically work?\n",
      "Assistant: Site Reliability Engineers typically work in large tech companies, cloud service providers, or companies with large-scale infrastructure needs. They may work in industries like e-commerce, finance, and healthcare.\n",
      "\n",
      "User: What difficulties do Sustainability Consultants face in their jobs?\n",
      "Assistant: Sustainability Consultants often face challenges such as overcoming resistance to change from organizations, measuring the effectiveness of sustainability initiatives, ensuring compliance with diverse environmental regulations, and managing client expectations.\n",
      "\n",
      "User: What is the job description for a Claims Adjuster?\n",
      "Assistant: A Claims Adjuster reviews and processes insurance claims by assessing the damages, interviewing claimants and witnesses, conducting investigations, and determining the payout based on the insurance policy terms and the extent of the loss.\n",
      "\n",
      "User: How do I progress in a career as an Insurance Underwriter?\n",
      "Assistant: To progress, gain experience in evaluating a wide range of risks, develop a deep understanding of insurance products and regulations, and seek certification in underwriting. Pursuing leadership roles in underwriting management is also possible.\n",
      "\n",
      "User: What technologies are commonly used in the Product Manager role?\n",
      "Assistant: Product Managers use technologies like JIRA, Confluence, A/B testing platforms, CRM tools, analytics tools like Google Analytics, and collaboration platforms like Slack or Microsoft Teams.\n",
      "\n",
      "User: What is the typical career trajectory for an Insurance Underwriter?\n",
      "Assistant: The typical trajectory starts with an entry-level position as a Junior Underwriter, progressing to a Senior Underwriter role. Over time, one can move into supervisory or managerial positions, such as Underwriting Manager or Underwriting Director.\n",
      "\n",
      "User: Which programming languages are important for an Advertising Manager (Junior level)?\n",
      "Assistant: Programming languages are not typically required for an Advertising Manager (Junior level), but knowledge of HTML and CSS can be useful when working on digital ads or email campaigns.\n",
      "\n",
      "User: Which programming languages are important for a Product Manager?\n",
      "Assistant: While Product Managers do not typically need programming skills, knowledge of technologies like HTML, CSS, and SQL can be helpful for understanding product development and communicating with technical teams.\n",
      "\n",
      "User: What tools does a Market Development Manager (Junior level) typically use?\n",
      "Assistant: Tools typically used include market research platforms like Nielsen, Google Analytics for website data, CRM software like Salesforce, and project management tools like Asana or Trello.\n",
      "\n",
      "User: What technologies are commonly used in the Game Developer role?\n",
      "Assistant: Technologies commonly used include game engines (Unity, Unreal Engine), graphics and rendering technologies, physics engines, AI for games, networking for multiplayer features, and tools for testing and debugging.\n",
      "\n",
      "User: What is the job description for an Operations Executive?\n",
      "Assistant: An Operations Executive is responsible for ensuring that the company's day-to-day activities run efficiently. They monitor operational performance, optimize processes, and assist in resource management and problem-solving.\n",
      "\n",
      "User: What are the entry-level requirements for a Digital Marketing Analyst?\n",
      "Assistant: Entry-level requirements typically include knowledge of digital marketing tools, familiarity with SEO and SEM, strong analytical skills, and a Bachelor’s degree in marketing or a related field.\n",
      "\n",
      "User: What are the essential skills for a successful Cloud Consultant?\n",
      "Assistant: Essential skills include knowledge of cloud platforms (AWS, Azure, Google Cloud), networking, cloud security, ability to analyze and optimize cloud costs, and strong communication skills for client interaction.\n",
      "\n",
      "User: What is the career growth path for a Junior Scrum Master?\n",
      "Assistant: A Junior Scrum Master typically progresses to a Scrum Master, then a Senior Scrum Master or Agile Coach. With experience, they may take on leadership roles such as Agile Transformation Manager or Scrum Program Manager.\n",
      "\n",
      "User: What is the career growth path for a Market Development Manager (Junior level)?\n",
      "Assistant: The career growth path typically starts with an entry-level position such as Market Development Manager, progressing to Senior Market Development Manager, and then to leadership roles such as Director of Market Development or Vice President of Business Development.\n",
      "\n",
      "User: What difficulties do Data Visualization Specialists face in their jobs?\n",
      "Assistant: Data Visualization Specialists often face challenges related to data quality, such as incomplete or messy data, and ensuring that visualizations are intuitive, meaningful, and aligned with business goals.\n",
      "\n",
      "User: What is the salary range for a Data Analyst?\n",
      "Assistant: The salary range for a Data Analyst is approximately $45,000 to $110,000 annually, depending on expertise and the industry.\n",
      "\n",
      "User: How can I begin working as a Fundraising Manager?\n",
      "Assistant: Begin by applying for entry-level roles like Fundraising Assistant, Fundraising Coordinator, or Event Coordinator. Gain experience in fundraising, event planning, and donor relations to move into a Fundraising Manager role.\n",
      "\n",
      "User: What is the salary range for a Game Developer?\n",
      "Assistant: The salary range for a Game Developer typically falls between $50,000 and $100,000 annually, with experienced developers or those in specialized roles earning upwards of $120,000.\n",
      "\n",
      "User: Do I need a degree to pursue a career as a Robotics Engineer?\n",
      "Assistant: Yes, a Bachelor's degree in a related field like Robotics, Mechanical Engineering, or Electrical Engineering is typically required. A Master's degree or Ph.D. can help with advanced roles or specialized areas of robotics.\n",
      "\n",
      "User: What are the daily tasks of an AI Researcher?\n",
      "Assistant: Daily tasks include literature review, designing and running experiments, analyzing data, debugging code, and writing research papers or reports for publication.\n",
      "\n",
      "User: What work environment can a CSR Manager expect?\n",
      "Assistant: CSR Managers can expect to work in an office environment, often in a corporate setting. Many companies offer remote or hybrid work opportunities, particularly for roles focused on project management and reporting.\n",
      "\n",
      "User: Where do Game Developers typically work?\n",
      "Assistant: Game Developers typically work at game development studios, software companies, tech firms, or as independent contractors. They may also work at mobile development companies or companies specializing in VR/AR development.\n",
      "\n",
      "User: What technologies are commonly used in the Advertising Manager (Junior level) role?\n",
      "Assistant: Common technologies include Google Ads, Facebook Ads, programmatic advertising platforms, Google Analytics, and email marketing tools. Basic knowledge of content management systems (CMS) can also be helpful.\n",
      "\n",
      "User: What kind of companies hire Robotics Engineers?\n",
      "Assistant: Companies in industries such as automotive, aerospace, healthcare, manufacturing, and technology hire Robotics Engineers. This includes large corporations, research institutions, and startups in the robotics field.\n",
      "\n",
      "User: What is the average salary for an AI Researcher?\n",
      "Assistant: The average salary for an AI Researcher ranges from $90,000 to $150,000 annually, depending on experience, location, and the organization.\n",
      "\n",
      "User: What qualifications do I need to become a QA Engineer?\n",
      "Assistant: Qualifications typically include a Bachelor's degree in Computer Science or a related field, and experience with testing methodologies. Certifications such as ISTQB (International Software Testing Qualifications Board) can be beneficial.\n",
      "\n",
      "User: What is the job description for a Content Strategist?\n",
      "Assistant: A Content Strategist works to develop and execute content strategies across digital and traditional media. They research target audiences, create content plans, collaborate with content creators, and measure the effectiveness of content to ensure it contributes to business goals.\n",
      "\n",
      "User: What are the entry-level requirements for a Procurement Manager?\n",
      "Assistant: Entry-level requirements typically include a bachelor's degree in business, supply chain management, or a related field, along with some experience in procurement or administrative roles.\n",
      "\n",
      "User: What technologies are commonly used in the Digital Marketing Manager (Junior level) role?\n",
      "Assistant: Common technologies include Google Analytics for tracking, SEO tools like SEMrush, social media management platforms like Hootsuite or Buffer, email marketing tools like Mailchimp, and basic CMS platforms like WordPress.\n",
      "\n",
      "User: What skills are required to become a Game Developer?\n",
      "Assistant: Skills required include proficiency in programming languages such as C++, C#, and Java, knowledge of game engines like Unity or Unreal Engine, problem-solving skills, creativity, and experience in game design and development.\n",
      "\n",
      "User: What are the biggest challenges in being an AI Researcher?\n",
      "Assistant: Challenges include the need to stay updated with the rapid pace of technological advancements, ensuring reproducibility of experiments, managing the computational cost of experiments, and publishing high-impact research.\n",
      "\n",
      "User: What are the essential skills for a successful Product Manager?\n",
      "Assistant: Essential skills include leadership, collaboration, understanding of business and user needs, data-driven decision-making, prioritization, and knowledge of product management tools like JIRA, Trello, and Asana.\n",
      "\n",
      "User: How can I begin working as a Legal Assistant?\n",
      "Assistant: Start by applying for internships or entry-level positions in law firms or legal departments. Obtain certifications or complete a legal assistant training program to gain specialized skills.\n",
      "\n",
      "User: What does a Data Analyst do?\n",
      "Assistant: A Data Analyst collects, processes, and performs statistical analyses on large datasets to identify trends, patterns, and insights that inform business decisions.\n",
      "\n",
      "User: Do I need a degree to pursue a career as a Customer Relationship Manager?\n",
      "Assistant: While a degree in Business, Marketing, or a related field is often preferred, experience in customer service or sales, along with hands-on experience with CRM tools, can also provide an entry point into this role.\n",
      "\n",
      "User: What are the biggest challenges in being a Content Strategist?\n",
      "Assistant: Challenges include balancing creativity with data-driven strategies, keeping up with changing SEO and digital marketing trends, managing tight deadlines, and ensuring content aligns with brand voice while being effective in achieving business goals.\n",
      "\n",
      "User: What tools does a Data Analyst typically use?\n",
      "Assistant: Data Analysts use tools like SQL for querying databases, Excel for basic analysis, Python or R for advanced analysis, and Tableau or Power BI for visualization.\n",
      "\n",
      "User: What is the average salary for a Product Manager?\n",
      "Assistant: The average salary for an entry-level Product Manager ranges from $60,000 to $90,000 per year, depending on experience and location.\n",
      "\n",
      "User: What are the essential skills for a successful Retail Manager?\n",
      "Assistant: Essential skills include effective leadership, customer service, inventory management, staff training, sales strategies, and proficiency with point-of-sale (POS) systems.\n",
      "\n",
      "User: What technologies are commonly used in the Travel Coordinator role?\n",
      "Assistant: Technologies include travel booking platforms like Sabre or Amadeus, travel expense management systems, cloud-based tools for itinerary sharing, and communication tools like email and messaging apps.\n",
      "\n",
      "User: What does a typical day look like for a Digital Marketing Manager (Junior level)?\n",
      "Assistant: A typical day involves assisting in executing marketing strategies, managing social media platforms, creating content, analyzing marketing performance, optimizing campaigns, and working closely with the marketing team to align on digital initiatives.\n",
      "\n",
      "User: What work environment can a Travel Coordinator expect?\n",
      "Assistant: Travel Coordinators can expect to work in office environments, either in-house for a corporation or in travel agencies. Remote work is becoming more common, especially for smaller companies or agencies.\n",
      "\n",
      "User: What does a Retail Manager do on a daily basis?\n",
      "Assistant: On a daily basis, a Retail Manager ensures staff is performing well, deals with customer complaints, checks inventory levels, manages the store's visual display, and ensures sales goals are met.\n",
      "\n",
      "User: How much do Fundraising Managers earn annually?\n",
      "Assistant: Fundraising Managers earn between $45,000 and $55,000 annually on average, though this can vary based on experience, location, and the type of organization.\n",
      "\n",
      "User: How can I begin working as a UX Researcher?\n",
      "Assistant: Begin by gaining experience in user-centered design or research, building a portfolio of research studies, and learning about different UX research methods. Internships, workshops, and certifications can also be helpful.\n",
      "\n",
      "User: What are the essential skills for a successful Advertising Manager (Junior level)?\n",
      "Assistant: Essential skills include media buying, budget management, creative thinking, market research, familiarity with digital advertising platforms like Google Ads and Facebook Ads, and the ability to work in a collaborative team environment.\n",
      "\n",
      "User: What are the main responsibilities of an Operations Executive?\n",
      "Assistant: Main responsibilities include overseeing operational processes, managing resources, optimizing workflows, implementing company policies, tracking performance metrics, and ensuring smooth business operations.\n",
      "\n",
      "User: What is the typical career trajectory for a Mobile App Developer?\n",
      "Assistant: The typical career trajectory starts with Junior Mobile App Developer, progressing to Senior Developer, and eventually to leadership roles like Mobile Development Manager or Director of Engineering.\n",
      "\n",
      "User: What does a typical day look like for an AI Software Engineer?\n",
      "Assistant: A typical day involves coding and developing AI models, running experiments to improve algorithms, working with data scientists and researchers to enhance the model performance, testing the AI solutions, and integrating them into applications or products.\n",
      "\n",
      "User: What kind of companies hire Business Analysts?\n",
      "Assistant: Companies across various sectors, including tech, finance, healthcare, retail, and consulting firms, hire Business Analysts to optimize business processes and improve performance.\n",
      "\n",
      "User: How do I progress in a career as a Robotics Engineer?\n",
      "Assistant: To progress, you can specialize in areas like AI in robotics, robotic systems design, or automation. Building experience with complex robotic systems, leadership skills, and obtaining advanced degrees or certifications can help advance your career.\n",
      "\n",
      "User: What are the essential skills for a successful Data Visualization Specialist?\n",
      "Assistant: Essential skills include proficiency in data visualization tools (Tableau, Power BI), ability to analyze and interpret complex datasets, knowledge of design principles, and familiarity with programming languages (Python, R) for advanced visualizations.\n",
      "\n",
      "User: What tools does a Technical Support Engineer typically use?\n",
      "Assistant: Tools include remote desktop software (TeamViewer, AnyDesk), customer support platforms (Zendesk, Freshdesk), ticketing systems, diagnostic tools, and network monitoring tools.\n",
      "\n",
      "User: What technologies are commonly used in the AI Researcher role?\n",
      "Assistant: Technologies used include deep learning libraries (TensorFlow, PyTorch), reinforcement learning frameworks, neural networks, and other cutting-edge technologies such as AI ethics and quantum computing.\n",
      "\n",
      "User: What qualifications do I need to become a Product Manager?\n",
      "Assistant: Qualifications typically include a Bachelor's degree in business, engineering, computer science, or a related field. Some PMs may also pursue certifications like the Certified Scrum Product Owner (CSPO).\n",
      "\n",
      "User: What are the main responsibilities of a Systems Administrator?\n",
      "Assistant: The main responsibilities include installing, configuring, and maintaining hardware and software systems, managing networks, ensuring data security, troubleshooting issues, and supporting users.\n",
      "\n",
      "User: What skills are required to become an E-commerce Specialist?\n",
      "Assistant: Skills required include proficiency in e-commerce platforms (like Shopify or WooCommerce), digital marketing (SEO, PPC), data analysis, customer service, and a good understanding of e-commerce strategies.\n",
      "\n",
      "User: Where do Data Scientists typically work?\n",
      "Assistant: Data Scientists work in industries like finance, healthcare, technology, e-commerce, and government, often employed by corporations, startups, or research institutions.\n",
      "\n",
      "User: How can I begin working as a Data Visualization Specialist?\n",
      "Assistant: To begin, focus on learning data visualization tools and programming languages like Python or R. Build a portfolio of visualization projects, participate in data-related communities, and apply for entry-level positions to gain hands-on experience.\n",
      "\n",
      "User: What are the biggest challenges in being a Mobile App Developer?\n",
      "Assistant: The biggest challenges include ensuring the app is optimized for different devices, managing app performance, debugging issues across multiple platforms, and meeting tight project deadlines.\n",
      "\n",
      "User: What are the entry-level requirements for a Claims Adjuster?\n",
      "Assistant: Entry-level requirements typically include a high school diploma, some college education or relevant certifications, and a state-issued license. Experience in customer service or insurance is a plus.\n",
      "\n",
      "User: Where do Machine Learning Engineers typically work?\n",
      "Assistant: Machine Learning Engineers typically work in tech companies, financial institutions, healthcare, automotive, and any organization that deals with big data and AI solutions.\n",
      "\n",
      "User: What does a Sustainability Consultant do?\n",
      "Assistant: A Sustainability Consultant helps organizations develop and implement strategies that reduce environmental impact and promote sustainability. Their role involves assessing current practices, recommending improvements, and ensuring compliance with environmental regulations.\n",
      "\n",
      "User: How do I start a career as a Technical Support Engineer?\n",
      "Assistant: Start by learning about different operating systems, networks, and troubleshooting techniques. Gain hands-on experience through internships, certifications like CompTIA A+, and entry-level support roles.\n",
      "\n",
      "User: What qualifications do I need to become a Data Scientist?\n",
      "Assistant: A bachelor's or master's degree in fields like Computer Science, Statistics, Mathematics, or Data Science is typically required.\n",
      "\n",
      "User: How can I begin working as a Cloud Consultant?\n",
      "Assistant: To begin working as a Cloud Consultant, start by learning cloud technologies, gaining cloud certifications, and applying for junior cloud consultant roles or internships to gain experience.\n",
      "\n",
      "User: How do I progress in a career as an AI Researcher?\n",
      "Assistant: Progress involves gaining expertise in a specialized AI field, publishing research papers, collaborating with industry leaders, and contributing to the academic community.\n",
      "\n",
      "User: What skills are required to become a Site Reliability Engineer (SRE)?\n",
      "Assistant: Skills required include expertise in cloud infrastructure, systems administration, automation scripting (Python, Bash), familiarity with containerization (Docker, Kubernetes), monitoring tools (Prometheus, Grafana), and strong problem-solving abilities.\n",
      "\n",
      "User: Do I need a degree to pursue a career as a Fundraising Manager?\n",
      "Assistant: While a degree is not always mandatory, a bachelor’s degree in nonprofit management, marketing, or business is often preferred. Practical experience in fundraising or event planning is also important.\n",
      "\n",
      "User: What is the average salary for a Policy Advisor?\n",
      "Assistant: The average salary for a Policy Advisor typically ranges from $50,000 to $75,000 annually, depending on experience, location, and the specific employer.\n",
      "\n",
      "User: Which software should a Product Owner be proficient in?\n",
      "Assistant: A Product Owner should be proficient in project management software such as JIRA, Trello, or Asana, and tools for documentation like Confluence. Familiarity with Microsoft Office and communication tools like Slack is also valuable.\n",
      "\n",
      "User: What does a Knowledge Manager do?\n",
      "Assistant: A Knowledge Manager is responsible for organizing, managing, and sharing an organization's knowledge and information. They work to create systems for collecting, storing, and disseminating knowledge to improve efficiency and decision-making.\n",
      "\n",
      "User: What are the entry-level requirements for a Digital Marketing Manager (Junior level)?\n",
      "Assistant: Entry-level requirements typically include a basic understanding of digital marketing, proficiency with social media platforms, and experience with tools like Google Analytics, Google Ads, and SEO. Internships or part-time roles are helpful for gaining hands-on experience.\n",
      "\n",
      "User: What problems does a Policy Advisor typically encounter?\n",
      "Assistant: A Policy Advisor may encounter challenges in drafting policies that balance diverse stakeholder interests, ensuring policy recommendations are feasible, navigating political tensions, and managing public scrutiny.\n",
      "\n",
      "User: How do I progress in a career as an E-commerce Specialist?\n",
      "Assistant: To progress, gain experience in managing e-commerce platforms, work on improving digital marketing and sales strategies, and stay updated with the latest trends in e-commerce and online marketing. Certifications in digital marketing can help.\n",
      "\n",
      "User: What are the main responsibilities of a Social Media Analyst?\n",
      "Assistant: The main responsibilities include analyzing social media data, tracking engagement metrics, developing reports, identifying trends and insights, monitoring online conversations, managing social media campaigns, and helping to optimize social media strategies.\n",
      "\n",
      "User: What is the typical career trajectory for an E-commerce Specialist?\n",
      "Assistant: The typical career trajectory begins as an E-commerce Specialist, progresses to roles like E-commerce Manager or Digital Marketing Manager, and can eventually lead to senior leadership positions like E-commerce Director or VP of E-commerce.\n",
      "\n",
      "User: How do I start a career as a QA Engineer?\n",
      "Assistant: To start as a QA Engineer, you should gain a degree in Computer Science or a related field, learn about software testing methodologies, and practice testing with tools like Selenium. Internships or entry-level testing positions are good starting points.\n",
      "\n",
      "User: What is the average salary for a Game Developer?\n",
      "Assistant: The average salary for a Game Developer typically ranges from $50,000 to $100,000 annually, depending on experience, location, and the complexity of the projects they work on.\n",
      "\n",
      "User: What kind of companies hire Franchise Managers?\n",
      "Assistant: Companies that operate franchise models, such as fast food chains, retail brands, gyms, and hospitality businesses, commonly hire Franchise Managers to oversee franchise locations.\n",
      "\n",
      "User: What does an Insurance Underwriter do on a daily basis?\n",
      "Assistant: On a daily basis, an Insurance Underwriter reviews applications, assesses risk factors, calculates premiums, makes coverage decisions, and communicates with agents or clients to gather additional information.\n",
      "\n",
      "User: What work environment can a Data Scientist expect?\n",
      "Assistant: Data Scientists often work in office settings or remotely, collaborating with cross-functional teams to provide data-driven solutions.\n",
      "\n",
      "User: What is the career growth path for a Software Engineer?\n",
      "Assistant: A Software Engineer can progress from Junior Developer to Senior Software Engineer, Lead Developer, Software Engineering Manager, and eventually into executive roles like CTO.\n",
      "\n",
      "User: What kind of companies hire Site Reliability Engineers?\n",
      "Assistant: Companies with complex, large-scale systems, such as tech giants, cloud service providers, financial institutions, and companies offering SaaS products, typically hire Site Reliability Engineers.\n",
      "\n",
      "User: What are the daily tasks of a Franchise Manager?\n",
      "Assistant: Daily tasks include overseeing franchisee performance, addressing operational challenges, training staff, ensuring brand standards are met, reviewing financials, and communicating with franchisees and vendors.\n",
      "\n",
      "User: What skills are required to become a Salesforce Administrator?\n",
      "Assistant: Skills required include a strong understanding of Salesforce CRM, proficiency in Salesforce configuration and customization, experience with data management, user training, report building, and problem-solving abilities.\n",
      "\n",
      "User: What does a typical day look like for a Franchise Manager?\n",
      "Assistant: A typical day involves supporting franchisees, reviewing performance reports, providing operational guidance, assisting with marketing and promotions, and handling any issues that arise at franchise locations.\n",
      "\n",
      "User: Which software should a Digital Marketing Analyst be proficient in?\n",
      "Assistant: A Digital Marketing Analyst should be proficient in analytics tools like Google Analytics, SEO tools like SEMrush and Ahrefs, and advertising platforms like Google Ads and Facebook Ads Manager.\n",
      "\n",
      "User: Which software should a UX/UI Designer be proficient in?\n",
      "Assistant: A UX/UI Designer should be proficient in design tools such as Figma, Sketch, Adobe XD, and InVision. Knowledge of collaboration tools like Zeplin and prototyping tools is also valuable.\n",
      "\n",
      "User: What does an Application Support Analyst do on a daily basis?\n",
      "Assistant: On a daily basis, an Application Support Analyst resolves technical issues reported by users, monitors the health of applications, manages support tickets, ensures timely resolutions, and works with teams to improve application functionality.\n",
      "\n",
      "User: What kind of companies hire Procurement Managers?\n",
      "Assistant: Companies in manufacturing, retail, technology, healthcare, government, and other industries that require regular purchasing and supply chain management often hire Procurement Managers.\n",
      "\n",
      "User: What skills are required to become a Web Developer?\n",
      "Assistant: Skills required include proficiency in HTML, CSS, JavaScript, knowledge of web frameworks (React, Angular, Django), understanding of web hosting and server management, and a strong grasp of responsive design principles.\n",
      "\n",
      "User: Which software should a Machine Learning Engineer be proficient in?\n",
      "Assistant: Machine Learning Engineers should be proficient in Python, Jupyter notebooks, machine learning libraries (TensorFlow, PyTorch), and cloud-based services for model deployment.\n",
      "\n",
      "User: Where do Web Developers typically work?\n",
      "Assistant: Web Developers typically work in tech companies, web development agencies, IT consulting firms, or as freelancers. Many also work for large corporations with dedicated web teams.\n",
      "\n",
      "User: What is the typical career trajectory for a Cloud Consultant?\n",
      "Assistant: A typical trajectory starts with a Junior Cloud Consultant role, progresses to a Senior Cloud Consultant, then to Cloud Architect or Cloud Engineer, and may lead to leadership roles in cloud strategy or operations.\n",
      "\n",
      "User: What are the biggest challenges in being a Product Owner?\n",
      "Assistant: Challenges include managing competing priorities from stakeholders, balancing customer needs with business goals, keeping the product development team aligned with the product vision, and ensuring timely delivery of features.\n",
      "\n",
      "User: What problems does a Knowledge Manager typically encounter?\n",
      "Assistant: Common problems include ensuring that knowledge is regularly updated, overcoming siloed knowledge within departments, ensuring the adoption of knowledge-sharing tools, and making sure that knowledge is effectively utilized by employees.\n",
      "\n",
      "User: What problems does a Site Reliability Engineer (SRE) typically encounter?\n",
      "Assistant: SREs often deal with system downtime, inefficient resource usage, manual tasks that need automation, security vulnerabilities, and performance bottlenecks in cloud environments.\n",
      "\n",
      "User: What is the job description for a Cloud Consultant?\n",
      "Assistant: A Cloud Consultant advises clients on cloud strategies, helps with the migration of systems to cloud environments, and ensures that the cloud infrastructure is optimized for the client's needs.\n",
      "\n",
      "User: Where do CSR Managers typically work?\n",
      "Assistant: CSR Managers typically work in large corporations, nonprofit organizations, government agencies, and consulting firms, particularly those focused on sustainability, ethics, or corporate responsibility.\n",
      "\n",
      "User: What positions match my major in Statistics and my skills in Python, Webscrapping, PowerBI, Data Cleaning, Data Preparation, Data Analysis, Predictive Modeling, Data Analytics, Pivot Table, SQL, PostgreSQL, Analytics, Excel, Machine Learning and XML?\n",
      "Assistant: The possible positions for Statistics are: Mechanical Designer. Key responsibilities include: Design Creation, CAD Drawings, Design Optimization, Team Collaboration, Compliance Assurance, Design Reviews, Manufacturing Support, Documentation\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in BSc(CA) and MSc(CA)?\n",
      "Assistant: The possible positions for BSc(CA) and MSc(CA) are: Civil Engineer with an experience requirement of At least 5 years. The related skills are Natural Language Processing, Python and Machine learning\n",
      "\n",
      "User: What positions match my major in N/A and my skills in Business Analyst, Data Analysis, Business Analysis, Machine Learning, Tableau, Seaborn, Python, R, AWS VIEW and NodeJS?\n",
      "Assistant: The possible positions for N/A are: Data Science Engineer. Key responsibilities include: Application Development, Object-Oriented Design, Collaboration, Problem-Solving, Software Lifecycle, Innovation, Software Testing, System Analysis, Performance Monitoring, Plugin Development, Documentation, Integration Support\n",
      "\n",
      "User: What positions match my major in Computer Science and Computers and my skills in Machine Learning, Deep Learning, Neural Networks, ML Algorithms, Python, NumPy, Scikit Learn, Matplotlib, Keras, Pandas, TensorFlow, Seaborn, Java, ReactJS and NodeJS?\n",
      "Assistant: The possible positions for Computer Science and Computers are: Asst. Manager/ Manger (Administrative). Key responsibilities include: Administrative Support, Scheduling, Filing & Documentation, Communication, Team Support, Equipment Maintenance, Information Provision, Inventory Management, Team Collaboration, OHS Policy Development, Safety Advice, Risk Assessment, Policy Review, OHS Training, Safety Inspections, Unsafe Act Prevention, Incident Investigation, Report Preparation\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Tech?\n",
      "Assistant: The possible positions for B.Tech are: Full Stack Developer (Python,React js) with an experience requirement of 3 to 7 years. The related skills are NLP and Data Analysis\n",
      "\n",
      "User: What positions match my major in Statistics and Data Analysis and Statistical Computation and my skills in Data Analysis, Business Analysis, Statistical Analysis, Regression Analysis, Natural Language Processing, Machine Learning and Numerical Analysis?\n",
      "Assistant: The possible positions for Statistics and Data Analysis and Statistical Computation are: Asst. Manager/ Manger (Administrative). Key responsibilities include: Administrative Support, Scheduling, Filing & Documentation, Communication, Team Support, Equipment Maintenance, Information Provision, Inventory Management, Team Collaboration, OHS Policy Development, Safety Advice, Risk Assessment, Policy Review, OHS Training, Safety Inspections, Unsafe Act Prevention, Incident Investigation, Report Preparation\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Engineering?\n",
      "Assistant: The possible positions for Bachelor of Engineering are: Sr.Officer / Executive - Internal Audit with an experience requirement of 2 to 4 years. The related skills are Software Development and Application Programming\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Sc and MCA?\n",
      "Assistant: The possible positions for B.Sc and MCA are: Executive/ Senior Executive- Trade Marketing, Hygiene Products with an experience requirement of At least 3 years. The related skills are Neural Networks, Machine Learning and Image recognition\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Science?\n",
      "Assistant: The possible positions for Bachelor of Science are: Network Support Engineer with an experience requirement of At least 3 years. The related skills are Creating dashboards for sales and profits\n",
      "\n",
      "User: What positions match my major in Computer Engineering and my skills in Software Development, Application Programming, System Analysis, Technical Architecture, Requirement Gathering, Client Management, Server Management, Data Science, Machine Learning, Python, AWS, MySQL, NoSQL and NLP?\n",
      "Assistant: The possible positions for Computer Engineering are: Business Development Executive. Key responsibilities include: Apparel Sourcing, Quality Garment Sourcing, Reliable Partner, Buyer/Vendor Communication\n",
      "\n",
      "User: What positions match my major in Electrical and Electrical and my skills in Book, Budget 5, Budget, Carpentry, Coaching, Communication skills, Communication, Skills, CA, Consulting, Contracts, Counseling, Customer services, Designing, Drafting, Engineer, Estimating, Features, First aid, Focus, Hand tools, HVAC, Inventory, Leadership skills, Leadership, Materials, Mathematics, Mechanical, Meetings, Painting, Payroll, Performance reviews, Personnel, Physics, Plumbing, Property Management, Purchasing, Read, Reading, Record keeping, Repairs, Safety, Scanners, Staff, Training, Supervision, Supervising, Test equipment, Troubleshooting, Type and Wiring?\n",
      "Assistant: The possible positions for Electrical and Electrical are: Business Development Executive. Key responsibilities include: Apparel Sourcing, Quality Garment Sourcing, Reliable Partner, Buyer/Vendor Communication\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in BSc(CA) and MSc(CA)?\n",
      "Assistant: The possible positions for BSc(CA) and MSc(CA) are: Senior iOS Engineer with an experience requirement of At least 4 years. The related skills are Natural Language Processing, Python and Machine learning\n",
      "\n",
      "User: What positions match my major in Computer Science and Computers and my skills in Machine Learning, Deep Learning, Neural Networks, ML Algorithms, Python, NumPy, Scikit Learn, Matplotlib, Keras, Pandas, TensorFlow, Seaborn, Java, ReactJS and NodeJS?\n",
      "Assistant: The possible positions for Computer Science and Computers are: Executive/ Sr. Executive -IT. Key responsibilities include: Hardware & Software Installation, System Monitoring, IT Support, Networking Expertise, Mail Server Administration, Security Management, Troubleshooting & Repair, Operations Support\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Course Revisions for the: National Electrical Code and Associate Degree?\n",
      "Assistant: The possible positions for Course Revisions for the: National Electrical Code and Associate Degree are: Senior Software Engineer with an experience requirement of At least 1 year. The related skills are Electrical systems, Maintenance, Customer relationship, Troubleshooting, Repair, Maintenance, Day-to-day operations, Leadership and Guidance\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.E. (Computers)?\n",
      "Assistant: The possible positions for B.E. (Computers) are: Mechanical Designer with an experience requirement of At least 5 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development\n",
      "\n",
      "User: What positions match my major in Information Technology and my skills in Machine Learning, Data Analytics, Data Manipulation, Data Mining, Deep Learning, Algorithms, Selenium, Jenkins, Python, Java, SQL and Quality Control?\n",
      "Assistant: The possible positions for Information Technology are: Database Administrator (DBA). Key responsibilities include: Database Design & Development, SQL Query Optimization, Data Integrity & Security, BI Solutions Development, ETL Process Implementation, Database Maintenance, Backup & Restore Management, Index Rebuilding & Performance Tuning, SQL Server Clustering & High Availability, SQL Server Replication, High Availability Group Management, Database Monitoring & Troubleshooting\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.E. (Computers)?\n",
      "Assistant: The possible positions for B.E. (Computers) are: Asst. Manager/ Manger (Administrative) with an experience requirement of At least 5 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Business Administration?\n",
      "Assistant: The possible positions for Bachelor of Business Administration are: Data Engineer with an experience requirement of 5 to 8 years. The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router\n",
      "\n",
      "User: What positions match my major in N/A and my skills in Business Analyst, Data Analysis, Business Analysis, Machine Learning, Tableau, Seaborn, Python, R, AWS VIEW and NodeJS?\n",
      "Assistant: The possible positions for N/A are: Database Administrator (DBA). Key responsibilities include: Database Design & Development, SQL Query Optimization, Data Integrity & Security, BI Solutions Development, ETL Process Implementation, Database Maintenance, Backup & Restore Management, Index Rebuilding & Performance Tuning, SQL Server Clustering & High Availability, SQL Server Replication, High Availability Group Management, Database Monitoring & Troubleshooting\n",
      "\n",
      "User: What positions match my major in Information Technology and my skills in Machine Learning, Data Analytics, Data Manipulation, Data Mining, Deep Learning, Algorithms, Selenium, Jenkins, Python, Java, SQL and Quality Control?\n",
      "Assistant: The possible positions for Information Technology are: Manager- Human Resource Management (HRM)\n",
      ". Key responsibilities include: Recruitment Coordination, Appointment Management, Selection Criteria, Employee Orientation, Performance Evaluation, HR Database Management, Report Compilation, Documentation, Event Coordination, Task Execution\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Engineering?\n",
      "Assistant: The possible positions for Bachelor of Engineering are: Business Development Executive with an experience requirement of 1 to 3 years. The related skills are Software Development and Application Programming\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X?\n",
      "Assistant: The possible positions for B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X are: Manager- Human Resource Management (HRM)\n",
      " with an experience requirement of 5 to 6 years. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, OCR, Pytesseract and NER Text Classification\n",
      "\n",
      "User: What positions match my major in Electrical and Electrical and my skills in Book, Budget 5, Budget, Carpentry, Coaching, Communication skills, Communication, Skills, CA, Consulting, Contracts, Counseling, Customer services, Designing, Drafting, Engineer, Estimating, Features, First aid, Focus, Hand tools, HVAC, Inventory, Leadership skills, Leadership, Materials, Mathematics, Mechanical, Meetings, Painting, Payroll, Performance reviews, Personnel, Physics, Plumbing, Property Management, Purchasing, Read, Reading, Record keeping, Repairs, Safety, Scanners, Staff, Training, Supervision, Supervising, Test equipment, Troubleshooting, Type and Wiring?\n",
      "Assistant: The possible positions for Electrical and Electrical are: Executive - VAT. Key responsibilities include: Mushak Forms Maintenance, VAT Software & MS Office Maintenance, VAT Ledger Management, VAT Challan Coordination, Liaison with VAT Office, VAT Documentation, Other Assigned Tasks\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Tech and MS?\n",
      "Assistant: The possible positions for B.Tech and MS are: Civil Engineer with an experience requirement of At least 5 years. The related skills are Python, Chaco Plotting Library and Traits UI Library\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Science?\n",
      "Assistant: The possible positions for Bachelor of Science are: Head of Internal Control & Compliance (ICC) - SEVP/DMD with an experience requirement of At least 15 years. The related skills are Creating dashboards for sales and profits\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in BBA?\n",
      "Assistant: The possible positions for BBA are: Manager- Human Resource Management (HRM)\n",
      " with an experience requirement of 5 to 6 years. The related skills are Data Analysis and Business Analysis\n",
      "\n",
      "User: What positions match my major in Electrical Engineering Specialized in Computer Science, N/A and N/A and my skills in C, C++, Python, JAVA, HTML, CSS, JavaScript, Data Structures, SQL, PyCharm, Jupyter Notebook, Google Colab, Code Blocks, MATLAB, Turbo C++, MS Office, Scikit-Learn, TensorFlow, OpenCV, NumPy, Pytesseract and Keras?\n",
      "Assistant: The possible positions for Electrical Engineering Specialized in Computer Science, N/A and N/A are: Mechanical Designer. Key responsibilities include: Design Creation, CAD Drawings, Design Optimization, Team Collaboration, Compliance Assurance, Design Reviews, Manufacturing Support, Documentation\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Tech?\n",
      "Assistant: The possible positions for B.Tech are: Asst. Manager/ Manger (Administrative) with an experience requirement of At least 5 years. The related skills are Testing, Debugging and Parameter Tuning\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Course Revisions for the: National Electrical Code and Associate Degree?\n",
      "Assistant: The possible positions for Course Revisions for the: National Electrical Code and Associate Degree are: DevOps Engineer with an experience requirement of At least 3 years. The related skills are Electrical systems, Maintenance, Customer relationship, Troubleshooting, Repair, Maintenance, Day-to-day operations, Leadership and Guidance\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Science?\n",
      "Assistant: The possible positions for Bachelor of Science are: Senior iOS Engineer with an experience requirement of At least 4 years. The related skills are Creating dashboards for sales and profits\n",
      "\n",
      "User: What positions match my major in Computers and my skills in Machine Learning, Data Analysis, Data Visualization, Risk Assessment, Debugging, Database Management, Access Control, IAM, Sail point, Java, Python, MySQL, MongoDB and Data Structures?\n",
      "Assistant: The possible positions for Computers are: Data Engineer. Key responsibilities include: Data Platform Design, Data Pipeline Development, ETL Processes, SQL Query Optimization, Data Integration & Transformation, Data Modeling, Stakeholder Collaboration, Data Quality Monitoring, Continuous Learning\n",
      "\n",
      "User: What positions match my major in Electrical and Artificial intelligence and Machine Learning and my skills in Data Analysis, EDA, Python, Machine Learning, SQL, NLP, MATLAB, C#, Node.Js, Statistics, Business Analytics, Predictive Modeling and Data Modeling?\n",
      "Assistant: The possible positions for Electrical and Artificial intelligence and Machine Learning are: Data Engineer. Key responsibilities include: Data Platform Design, Data Pipeline Development, ETL Processes, SQL Query Optimization, Data Integration & Transformation, Data Modeling, Stakeholder Collaboration, Data Quality Monitoring, Continuous Learning\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Engineering?\n",
      "Assistant: The possible positions for Bachelor of Engineering are: Full Stack Developer (Python,React js) with an experience requirement of 3 to 7 years. The related skills are Software Development and Application Programming\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Course Revisions for the: National Electrical Code and Associate Degree?\n",
      "Assistant: The possible positions for Course Revisions for the: National Electrical Code and Associate Degree are: Full Stack Developer (Python,React js) with an experience requirement of 3 to 7 years. The related skills are Electrical systems, Maintenance, Customer relationship, Troubleshooting, Repair, Maintenance, Day-to-day operations, Leadership and Guidance\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in BBA?\n",
      "Assistant: The possible positions for BBA are: Head of Internal Control & Compliance (ICC) - SEVP/DMD with an experience requirement of At least 15 years. The related skills are Data Analysis and Business Analysis\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Science?\n",
      "Assistant: The possible positions for Bachelor of Science are: Data Engineer with an experience requirement of 5 to 8 years. The related skills are Creating dashboards for sales and profits\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Tech?\n",
      "Assistant: The possible positions for B.Tech are: DevOps Engineer with an experience requirement of At least 3 years. The related skills are Market Research and Data Analysis\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.E. (Computers)?\n",
      "Assistant: The possible positions for B.E. (Computers) are: Machine Learning (ML) Engineer with an experience requirement of At least 5 year(s). The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in BSc and MSc?\n",
      "Assistant: The possible positions for BSc and MSc are: Mechanical Designer with an experience requirement of At least 5 years. The related skills are NLP, ML and Amazon Comprehend Medical API\n",
      "\n",
      "User: What positions match my major in Electrical and Electrical and my skills in Book, Budget 5, Budget, Carpentry, Coaching, Communication skills, Communication, Skills, CA, Consulting, Contracts, Counseling, Customer services, Designing, Drafting, Engineer, Estimating, Features, First aid, Focus, Hand tools, HVAC, Inventory, Leadership skills, Leadership, Materials, Mathematics, Mechanical, Meetings, Painting, Payroll, Performance reviews, Personnel, Physics, Plumbing, Property Management, Purchasing, Read, Reading, Record keeping, Repairs, Safety, Scanners, Staff, Training, Supervision, Supervising, Test equipment, Troubleshooting, Type and Wiring?\n",
      "Assistant: The possible positions for Electrical and Electrical are: Site Engineer. Key responsibilities include: Supervision, Monitoring, Construction, Estimation, Planning, Material Management, Project Coordination, Quality Assurance, Cost Control, Inventory, Operations, Safety, Error Escalation, Miscellaneous Tasks\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in BSc and MSc?\n",
      "Assistant: The possible positions for BSc and MSc are: DevOps Engineer with an experience requirement of At least 3 years. The related skills are NLP, ML and Amazon Comprehend Medical API\n",
      "\n",
      "User: What positions match my major in Computer Engineering and my skills in Software Development, Application Programming, System Analysis, Technical Architecture, Requirement Gathering, Client Management, Server Management, Data Science, Machine Learning, Python, AWS, MySQL, NoSQL and NLP?\n",
      "Assistant: The possible positions for Computer Engineering are: Head of Internal Control & Compliance (ICC) - SEVP/DMD. Key responsibilities include: 15+ Years Banking Experience, Audit/Inspection/ICC Leadership, Internal Audit & Compliance, Risk-Based Operational Reviews, System-Based Audit Expertise, Knowledge of Bangladeshi Laws\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Business Administration?\n",
      "Assistant: The possible positions for Bachelor of Business Administration are: System Administrator (Operation & Maintenance of Server, Storage & Service Desk System) with an experience requirement of 4 to 5 years. The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router\n",
      "\n",
      "User: What positions match my major in Computers and my skills in Machine Learning, Data Analysis, Data Visualization, Risk Assessment, Debugging, Database Management, Access Control, IAM, Sail point, Java, Python, MySQL, MongoDB and Data Structures?\n",
      "Assistant: The possible positions for Computers are: Executive/ Sr. Executive -IT. Key responsibilities include: Hardware & Software Installation, System Monitoring, IT Support, Networking Expertise, Mail Server Administration, Security Management, Troubleshooting & Repair, Operations Support\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Science?\n",
      "Assistant: The possible positions for Bachelor of Science are: Civil Engineer with an experience requirement of At least 5 years. The related skills are Creating dashboards for sales and profits\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Tech?\n",
      "Assistant: The possible positions for B.Tech are: Business Development Executive with an experience requirement of 1 to 3 years. The related skills are Testing, Debugging and Parameter Tuning\n",
      "\n",
      "User: What positions match my major in Electrical Engineering Specialized in Computer Science, N/A and N/A and my skills in C, C++, Python, JAVA, HTML, CSS, JavaScript, Data Structures, SQL, PyCharm, Jupyter Notebook, Google Colab, Code Blocks, MATLAB, Turbo C++, MS Office, Scikit-Learn, TensorFlow, OpenCV, NumPy, Pytesseract and Keras?\n",
      "Assistant: The possible positions for Electrical Engineering Specialized in Computer Science, N/A and N/A are: Data Science Engineer. Key responsibilities include: Application Development, Object-Oriented Design, Collaboration, Problem-Solving, Software Lifecycle, Innovation, Software Testing, System Analysis, Performance Monitoring, Plugin Development, Documentation, Integration Support\n",
      "\n",
      "User: What positions match my major in Electrical and Electrical and my skills in Book, Budget 5, Budget, Carpentry, Coaching, Communication skills, Communication, Skills, CA, Consulting, Contracts, Counseling, Customer services, Designing, Drafting, Engineer, Estimating, Features, First aid, Focus, Hand tools, HVAC, Inventory, Leadership skills, Leadership, Materials, Mathematics, Mechanical, Meetings, Painting, Payroll, Performance reviews, Personnel, Physics, Plumbing, Property Management, Purchasing, Read, Reading, Record keeping, Repairs, Safety, Scanners, Staff, Training, Supervision, Supervising, Test equipment, Troubleshooting, Type and Wiring?\n",
      "Assistant: The possible positions for Electrical and Electrical are: Full Stack Developer (Python,React js). Key responsibilities include: Full Stack Development, Front-end: ReactJS, NextJS, Backend: Python, Django, API Design, Server-Side Logic, DRF (Django REST Framework), Database Management (PostgreSQL, MySQL), Version Control (Git), AWS (ECR, RDS, ECS, ALB, EC2, etc.), Linux, Docker, CI/CD, GitLab, Terraform, Shell Scripting\n",
      "\n",
      "User: What positions match my major in Computer Science and Computers and my skills in Machine Learning, Deep Learning, Neural Networks, ML Algorithms, Python, NumPy, Scikit Learn, Matplotlib, Keras, Pandas, TensorFlow, Seaborn, Java, ReactJS and NodeJS?\n",
      "Assistant: The possible positions for Computer Science and Computers are: Executive/ Senior Executive- Trade Marketing, Hygiene Products. Key responsibilities include: Trade Marketing Executive, Brand Visibility, Sales Targets, Field Marketing, Campaigns, Product Distribution, Brand Head, Excel, KPIs Tracking\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in BSc(CA) and MSc(CA)?\n",
      "Assistant: The possible positions for BSc(CA) and MSc(CA) are: Sr.Officer / Executive - Internal Audit with an experience requirement of 2 to 4 years. The related skills are Natural Language Processing, Python and Machine learning\n",
      "\n",
      "User: What positions match my major in Computer Applications and Computer Applications and my skills in Data Analysis, Machine learning, Data Mining, Natural Language Processing, Linear Regression, Cluster Analysis, Correlation Analysis, Logistic Regression, Principal Component Analysis, Anova, Neural Networks, R, Python, MySQL, Tableau, Excel, SPSS and Decision tree?\n",
      "Assistant: The possible positions for Computer Applications and Computer Applications are: Senior Software Engineer. Key responsibilities include: Technical Support, Troubleshooting, Collaboration, Documentation, System Monitoring, Software Deployment, Training & Mentorship, Industry Trends, Field Visits\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X?\n",
      "Assistant: The possible positions for B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X are: Project Coordinator (Civil) with an experience requirement of 5 to 10 years. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, OCR, Pytesseract and NER Text Classification\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Tech?\n",
      "Assistant: The possible positions for B.Tech are: Database Administrator (DBA) with an experience requirement of At least 1 year. The related skills are Market Research and Data Analysis\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Tech and MS?\n",
      "Assistant: The possible positions for B.Tech and MS are: Executive/ Senior Executive- Trade Marketing, Hygiene Products with an experience requirement of At least 3 years. The related skills are Python, Chaco Plotting Library and Traits UI Library\n",
      "\n",
      "User: What positions match my major in N/A and my skills in Business Analyst, Data Analysis, Business Analysis, Machine Learning, Tableau, Seaborn, Python, R, AWS VIEW and NodeJS?\n",
      "Assistant: The possible positions for N/A are: Manager- Human Resource Management (HRM)\n",
      ". Key responsibilities include: Recruitment Coordination, Appointment Management, Selection Criteria, Employee Orientation, Performance Evaluation, HR Database Management, Report Compilation, Documentation, Event Coordination, Task Execution\n",
      "\n",
      "User: What positions match my major in Computers and my skills in Machine Learning, Data Analysis, Data Visualization, Risk Assessment, Debugging, Database Management, Access Control, IAM, Sail point, Java, Python, MySQL, MongoDB and Data Structures?\n",
      "Assistant: The possible positions for Computers are: Business Development Executive. Key responsibilities include: Apparel Sourcing, Quality Garment Sourcing, Reliable Partner, Buyer/Vendor Communication\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in BSc(CA) and MSc(CA)?\n",
      "Assistant: The possible positions for BSc(CA) and MSc(CA) are: DevOps Engineer with an experience requirement of At least 3 years. The related skills are Natural Language Processing, Python and Machine learning\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Science?\n",
      "Assistant: The possible positions for Bachelor of Science are: Data Science Engineer with an experience requirement of At least 2 years. The related skills are Creating dashboards for sales and profits\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Tech?\n",
      "Assistant: The possible positions for B.Tech are: Executive/ Senior Executive- Trade Marketing, Hygiene Products with an experience requirement of At least 3 years. The related skills are Market Research and Data Analysis\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in BSc and MSc?\n",
      "Assistant: The possible positions for BSc and MSc are: Database Administrator (DBA) with an experience requirement of At least 1 year. The related skills are NLP, ML and Amazon Comprehend Medical API\n",
      "\n",
      "User: What positions match my major in N/A and my skills in Business Analyst, Data Analysis, Business Analysis, Machine Learning, Tableau, Seaborn, Python, R, AWS VIEW and NodeJS?\n",
      "Assistant: The possible positions for N/A are: Full Stack Developer (Python,React js). Key responsibilities include: Full Stack Development, Front-end: ReactJS, NextJS, Backend: Python, Django, API Design, Server-Side Logic, DRF (Django REST Framework), Database Management (PostgreSQL, MySQL), Version Control (Git), AWS (ECR, RDS, ECS, ALB, EC2, etc.), Linux, Docker, CI/CD, GitLab, Terraform, Shell Scripting\n",
      "\n",
      "User: What positions match my major in Mechanical and my skills in Research Associate, Business Analyst, Business Analytics, Data Mining, Data Modeling, Predictive Analysis, Business Intelligence, Machine Learning, Market Research, Customer Engagement, Risk Management, Retention, Audience and Python?\n",
      "Assistant: The possible positions for Mechanical are: DevOps Engineer. Key responsibilities include: Open-Source Technologies, CI/CD Culture & Tooling, Product Availability & Scalability, Automation (Build & Deploy), Monitoring & Reliability, Infrastructure Innovation, Software Engineering Velocity, Infrastructure Resiliency, Security & Data Availability\n",
      "\n",
      "User: What positions match my major in Statistics and Data Analysis and Statistical Computation and my skills in Data Analysis, Business Analysis, Statistical Analysis, Regression Analysis, Natural Language Processing, Machine Learning and Numerical Analysis?\n",
      "Assistant: The possible positions for Statistics and Data Analysis and Statistical Computation are: Database Administrator (DBA). Key responsibilities include: Database Design & Development, SQL Query Optimization, Data Integrity & Security, BI Solutions Development, ETL Process Implementation, Database Maintenance, Backup & Restore Management, Index Rebuilding & Performance Tuning, SQL Server Clustering & High Availability, SQL Server Replication, High Availability Group Management, Database Monitoring & Troubleshooting\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Course Revisions for the: National Electrical Code and Associate Degree?\n",
      "Assistant: The possible positions for Course Revisions for the: National Electrical Code and Associate Degree are: Business Development Executive with an experience requirement of 1 to 3 years. The related skills are Electrical systems, Maintenance, Customer relationship, Troubleshooting, Repair, Maintenance, Day-to-day operations, Leadership and Guidance\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.E. (Computers)?\n",
      "Assistant: The possible positions for B.E. (Computers) are: Executive - VAT with an experience requirement of 1 to 3 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development\n",
      "\n",
      "User: What positions match my major in Computer Applications and Computer Applications and my skills in Data Analysis, Machine learning, Data Mining, Natural Language Processing, Linear Regression, Cluster Analysis, Correlation Analysis, Logistic Regression, Principal Component Analysis, Anova, Neural Networks, R, Python, MySQL, Tableau, Excel, SPSS and Decision tree?\n",
      "Assistant: The possible positions for Computer Applications and Computer Applications are: Mechanical Engineer. Key responsibilities include: Machinery Maintenance, Troubleshooting, Report Preparation, Log Maintenance\n",
      "\n",
      "User: What positions match my major in Electrical and my skills in Machine Learning, Data Transition, Natural Language Processing, Predictive Analytics, Data Cleaning, Data Visualization, Deep Learning, BeRT Modelling, Tensorflow, Python, SciKit Learn and Data computation libraries in python?\n",
      "Assistant: The possible positions for Electrical are: Full Stack Developer (Python,React js). Key responsibilities include: Full Stack Development, Front-end: ReactJS, NextJS, Backend: Python, Django, API Design, Server-Side Logic, DRF (Django REST Framework), Database Management (PostgreSQL, MySQL), Version Control (Git), AWS (ECR, RDS, ECS, ALB, EC2, etc.), Linux, Docker, CI/CD, GitLab, Terraform, Shell Scripting\n",
      "\n",
      "User: What positions match my major in Mechanical and my skills in Research Associate, Business Analyst, Business Analytics, Data Mining, Data Modeling, Predictive Analysis, Business Intelligence, Machine Learning, Market Research, Customer Engagement, Risk Management, Retention, Audience and Python?\n",
      "Assistant: The possible positions for Mechanical are: Executive/ Senior Executive- Trade Marketing, Hygiene Products. Key responsibilities include: Trade Marketing Executive, Brand Visibility, Sales Targets, Field Marketing, Campaigns, Product Distribution, Brand Head, Excel, KPIs Tracking\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Tech and MS?\n",
      "Assistant: The possible positions for B.Tech and MS are: Machine Learning (ML) Engineer with an experience requirement of At least 5 year(s). The related skills are Python, Chaco Plotting Library and Traits UI Library\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X?\n",
      "Assistant: The possible positions for B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X are: System Administrator (Operation & Maintenance of Server, Storage & Service Desk System) with an experience requirement of 4 to 5 years. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, OCR, Pytesseract and NER Text Classification\n",
      "\n",
      "User: What positions match my major in Computer Engineering and my skills in Software Development, Application Programming, System Analysis, Technical Architecture, Requirement Gathering, Client Management, Server Management, Data Science, Machine Learning, Python, AWS, MySQL, NoSQL and NLP?\n",
      "Assistant: The possible positions for Computer Engineering are: Executive - VAT. Key responsibilities include: Mushak Forms Maintenance, VAT Software & MS Office Maintenance, VAT Ledger Management, VAT Challan Coordination, Liaison with VAT Office, VAT Documentation, Other Assigned Tasks\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Sc and MCA?\n",
      "Assistant: The possible positions for B.Sc and MCA are: Full Stack Developer (Python,React js) with an experience requirement of 3 to 7 years. The related skills are Neural Networks, Machine Learning and Image recognition\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Tech and MS?\n",
      "Assistant: The possible positions for B.Tech and MS are: Database Administrator (DBA) with an experience requirement of At least 1 year. The related skills are Python, Chaco Plotting Library and Traits UI Library\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in BBA?\n",
      "Assistant: The possible positions for BBA are: Database Administrator (DBA) with an experience requirement of At least 1 year. The related skills are Data Analysis and Business Analysis\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in BBA?\n",
      "Assistant: The possible positions for BBA are: DevOps Engineer with an experience requirement of At least 3 years. The related skills are Data Analysis and Business Analysis\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in BSc(CA) and MSc(CA)?\n",
      "Assistant: The possible positions for BSc(CA) and MSc(CA) are: Site Engineer with an experience requirement of 1 to 2 years. The related skills are Natural Language Processing, Python and Machine learning\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Engineering?\n",
      "Assistant: The possible positions for Bachelor of Engineering are: Data Science Engineer with an experience requirement of At least 2 years. The related skills are Software Development and Application Programming\n",
      "\n",
      "User: What positions match my major in Electrical Engineering Specialized in Computer Science, N/A and N/A and my skills in C, C++, Python, JAVA, HTML, CSS, JavaScript, Data Structures, SQL, PyCharm, Jupyter Notebook, Google Colab, Code Blocks, MATLAB, Turbo C++, MS Office, Scikit-Learn, TensorFlow, OpenCV, NumPy, Pytesseract and Keras?\n",
      "Assistant: The possible positions for Electrical Engineering Specialized in Computer Science, N/A and N/A are: Mechanical Engineer. Key responsibilities include: Machinery Maintenance, Troubleshooting, Report Preparation, Log Maintenance\n",
      "\n",
      "User: What positions match my major in Computer Engineering and my skills in Software Development, Application Programming, System Analysis, Technical Architecture, Requirement Gathering, Client Management, Server Management, Data Science, Machine Learning, Python, AWS, MySQL, NoSQL and NLP?\n",
      "Assistant: The possible positions for Computer Engineering are: Machine Learning (ML) Engineer. Key responsibilities include: Machine Learning Leadership, Cross-Functional Collaboration, Strategy Development, ML/NLP Infrastructure, Prototype Transformation, ML System Design, Algorithm Research, Application Development, Dataset Selection, ML Testing, Statistical Analysis, R&D in ML/NLP, Text Representation, Data Pipeline Design, Statistical Data Analysis, Model Training, Team Collaboration, Research Reporting, Algorithm Analysis\n",
      "\n",
      "User: What positions match my major in Statistics and my skills in Python, Webscrapping, PowerBI, Data Cleaning, Data Preparation, Data Analysis, Predictive Modeling, Data Analytics, Pivot Table, SQL, PostgreSQL, Analytics, Excel, Machine Learning and XML?\n",
      "Assistant: The possible positions for Statistics are: Network Support Engineer. Key responsibilities include: Mikrotik Router Configuration, OLT Device Setup & Management, Integration with Billing Software, Network Monitoring Tools Integration, Connectivity Troubleshooting, Technical Support & Escalation, Installation & Configuration, GPON/EPON Expertise, Cisco, OLT, MikroTik Knowledge\n",
      "\n",
      "User: What positions match my major in Statistics and Data Analysis and Statistical Computation and my skills in Data Analysis, Business Analysis, Statistical Analysis, Regression Analysis, Natural Language Processing, Machine Learning and Numerical Analysis?\n",
      "Assistant: The possible positions for Statistics and Data Analysis and Statistical Computation are: Mechanical Engineer. Key responsibilities include: Machinery Maintenance, Troubleshooting, Report Preparation, Log Maintenance\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Sc and MCA?\n",
      "Assistant: The possible positions for B.Sc and MCA are: Data Engineer with an experience requirement of 5 to 8 years. The related skills are Neural Networks, Machine Learning and Image recognition\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Sc and MCA?\n",
      "Assistant: The possible positions for B.Sc and MCA are: Asst. Manager/ Manger (Administrative) with an experience requirement of At least 5 years. The related skills are Neural Networks, Machine Learning and Image recognition\n",
      "\n",
      "User: What positions match my major in Computers and my skills in Machine Learning, Data Analysis, Data Visualization, Risk Assessment, Debugging, Database Management, Access Control, IAM, Sail point, Java, Python, MySQL, MongoDB and Data Structures?\n",
      "Assistant: The possible positions for Computers are: Site Engineer. Key responsibilities include: Supervision, Monitoring, Construction, Estimation, Planning, Material Management, Project Coordination, Quality Assurance, Cost Control, Inventory, Operations, Safety, Error Escalation, Miscellaneous Tasks\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Tech?\n",
      "Assistant: The possible positions for B.Tech are: Senior iOS Engineer with an experience requirement of At least 4 years. The related skills are Testing, Debugging and Parameter Tuning\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Engineering?\n",
      "Assistant: The possible positions for Bachelor of Engineering are: Executive/ Sr. Executive -IT with an experience requirement of 3 to 5 years. The related skills are Software Development and Application Programming\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.E. (Computers)?\n",
      "Assistant: The possible positions for B.E. (Computers) are: Civil Engineer with an experience requirement of At least 5 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development\n",
      "\n",
      "User: What positions match my major in Electrical and my skills in Machine Learning, Data Transition, Natural Language Processing, Predictive Analytics, Data Cleaning, Data Visualization, Deep Learning, BeRT Modelling, Tensorflow, Python, SciKit Learn and Data computation libraries in python?\n",
      "Assistant: The possible positions for Electrical are: Senior iOS Engineer. Key responsibilities include: iOS Lifecycle, Requirement Analysis, Native Frameworks, iOS Development, API Integration, Technical Communication, UI Design, Performance Optimization, Feature Collaboration, Bug Fixing, Code Translation, High-Performance Development, Task Management, Cross-Team Collaboration, Code Quality\n",
      "\n",
      "User: What positions match my major in Information Technology and my skills in Machine Learning, Data Analytics, Data Manipulation, Data Mining, Deep Learning, Algorithms, Selenium, Jenkins, Python, Java, SQL and Quality Control?\n",
      "Assistant: The possible positions for Information Technology are: Mechanical Engineer. Key responsibilities include: Machinery Maintenance, Troubleshooting, Report Preparation, Log Maintenance\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X?\n",
      "Assistant: The possible positions for B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X are: Full Stack Developer (Python,React js) with an experience requirement of 3 to 7 years. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, OCR, Pytesseract and NER Text Classification\n",
      "\n",
      "User: What positions match my major in Electrical Engineering Specialized in Computer Science, N/A and N/A and my skills in C, C++, Python, JAVA, HTML, CSS, JavaScript, Data Structures, SQL, PyCharm, Jupyter Notebook, Google Colab, Code Blocks, MATLAB, Turbo C++, MS Office, Scikit-Learn, TensorFlow, OpenCV, NumPy, Pytesseract and Keras?\n",
      "Assistant: The possible positions for Electrical Engineering Specialized in Computer Science, N/A and N/A are: Executive/ Senior Executive- Trade Marketing, Hygiene Products. Key responsibilities include: Trade Marketing Executive, Brand Visibility, Sales Targets, Field Marketing, Campaigns, Product Distribution, Brand Head, Excel, KPIs Tracking\n",
      "\n",
      "User: What positions match my major in Electrical and Electrical and my skills in Book, Budget 5, Budget, Carpentry, Coaching, Communication skills, Communication, Skills, CA, Consulting, Contracts, Counseling, Customer services, Designing, Drafting, Engineer, Estimating, Features, First aid, Focus, Hand tools, HVAC, Inventory, Leadership skills, Leadership, Materials, Mathematics, Mechanical, Meetings, Painting, Payroll, Performance reviews, Personnel, Physics, Plumbing, Property Management, Purchasing, Read, Reading, Record keeping, Repairs, Safety, Scanners, Staff, Training, Supervision, Supervising, Test equipment, Troubleshooting, Type and Wiring?\n",
      "Assistant: The possible positions for Electrical and Electrical are: Civil Engineer. Key responsibilities include: Design Review, Coordination, Proposal Preparation, Feasibility Analysis, Software Utilization, Supervision, Technical Support, Submission Review, Progress Reporting, Compliance, Site Visits\n",
      "\n",
      "User: What positions match my major in Mechanical and my skills in Research Associate, Business Analyst, Business Analytics, Data Mining, Data Modeling, Predictive Analysis, Business Intelligence, Machine Learning, Market Research, Customer Engagement, Risk Management, Retention, Audience and Python?\n",
      "Assistant: The possible positions for Mechanical are: Data Engineer. Key responsibilities include: Data Platform Design, Data Pipeline Development, ETL Processes, SQL Query Optimization, Data Integration & Transformation, Data Modeling, Stakeholder Collaboration, Data Quality Monitoring, Continuous Learning\n",
      "\n",
      "User: What positions match my major in Statistics and Data Analysis and Statistical Computation and my skills in Data Analysis, Business Analysis, Statistical Analysis, Regression Analysis, Natural Language Processing, Machine Learning and Numerical Analysis?\n",
      "Assistant: The possible positions for Statistics and Data Analysis and Statistical Computation are: Senior Software Engineer. Key responsibilities include: Technical Support, Troubleshooting, Collaboration, Documentation, System Monitoring, Software Deployment, Training & Mentorship, Industry Trends, Field Visits\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Engineering?\n",
      "Assistant: The possible positions for Bachelor of Engineering are: DevOps Engineer with an experience requirement of At least 3 years. The related skills are Software Development and Application Programming\n",
      "\n",
      "User: What positions match my major in Electrical Engineering Specialized in Computer Science, N/A and N/A and my skills in C, C++, Python, JAVA, HTML, CSS, JavaScript, Data Structures, SQL, PyCharm, Jupyter Notebook, Google Colab, Code Blocks, MATLAB, Turbo C++, MS Office, Scikit-Learn, TensorFlow, OpenCV, NumPy, Pytesseract and Keras?\n",
      "Assistant: The possible positions for Electrical Engineering Specialized in Computer Science, N/A and N/A are: Marketing Officer. Key responsibilities include: Digital Marketing Strategy, Brand Awareness, Online Traffic, Social Media Management, Google Analytics, Cross-functional Teams, Campaign Execution, SEO\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Tech?\n",
      "Assistant: The possible positions for B.Tech are: Senior iOS Engineer with an experience requirement of At least 4 years. The related skills are NLP and Data Analysis\n",
      "\n",
      "User: What positions match my major in N/A and my skills in Business Analyst, Data Analysis, Business Analysis, Machine Learning, Tableau, Seaborn, Python, R, AWS VIEW and NodeJS?\n",
      "Assistant: The possible positions for N/A are: Senior iOS Engineer. Key responsibilities include: iOS Lifecycle, Requirement Analysis, Native Frameworks, iOS Development, API Integration, Technical Communication, UI Design, Performance Optimization, Feature Collaboration, Bug Fixing, Code Translation, High-Performance Development, Task Management, Cross-Team Collaboration, Code Quality\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in BBA?\n",
      "Assistant: The possible positions for BBA are: Site Engineer with an experience requirement of 1 to 2 years. The related skills are Data Analysis and Business Analysis\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Science?\n",
      "Assistant: The possible positions for Bachelor of Science are: Mechanical Designer with an experience requirement of At least 5 years. The related skills are Creating dashboards for sales and profits\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Tech?\n",
      "Assistant: The possible positions for B.Tech are: Network Support Engineer with an experience requirement of At least 3 years. The related skills are NLP and Data Analysis\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Business Administration?\n",
      "Assistant: The possible positions for Bachelor of Business Administration are: Site Engineer with an experience requirement of 1 to 2 years. The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in BBA?\n",
      "Assistant: The possible positions for BBA are: Business Development Executive with an experience requirement of 1 to 3 years. The related skills are Data Analysis and Business Analysis\n",
      "\n",
      "User: What positions match my major in Statistics and my skills in Python, Webscrapping, PowerBI, Data Cleaning, Data Preparation, Data Analysis, Predictive Modeling, Data Analytics, Pivot Table, SQL, PostgreSQL, Analytics, Excel, Machine Learning and XML?\n",
      "Assistant: The possible positions for Statistics are: Business Development Executive. Key responsibilities include: Apparel Sourcing, Quality Garment Sourcing, Reliable Partner, Buyer/Vendor Communication\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Business Administration?\n",
      "Assistant: The possible positions for Bachelor of Business Administration are: Project Coordinator (Civil) with an experience requirement of 5 to 10 years. The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in BBA?\n",
      "Assistant: The possible positions for BBA are: Machine Learning (ML) Engineer with an experience requirement of At least 5 year(s). The related skills are Data Analysis and Business Analysis\n",
      "\n",
      "User: What positions match my major in Electrical and Artificial intelligence and Machine Learning and my skills in Data Analysis, EDA, Python, Machine Learning, SQL, NLP, MATLAB, C#, Node.Js, Statistics, Business Analytics, Predictive Modeling and Data Modeling?\n",
      "Assistant: The possible positions for Electrical and Artificial intelligence and Machine Learning are: System Administrator (Operation & Maintenance of Server, Storage & Service Desk System). Key responsibilities include: Hardware & Network Installation, Troubleshooting & Diagnostics, User Training & Capacity Building, Hardware Replacement, Fault Repair & System Setup, Software License & Account Management, Backup Management, System Updates & Maintenance, Server & Storage Management, Documentation & Technical Specifications, Data Protection & Disaster Recovery, Storage & Database Planning, Power & Disk Backup, Incident Management & Escalation, Service Restoration, User Communication & Verification, Incident Classification & Resolution, Major Incident Escalation, Problem & Error Management, Task Assignment & Execution\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in BBA?\n",
      "Assistant: The possible positions for BBA are: Data Engineer with an experience requirement of 5 to 8 years. The related skills are Data Analysis and Business Analysis\n",
      "\n",
      "User: What positions match my major in N/A and my skills in Business Analyst, Data Analysis, Business Analysis, Machine Learning, Tableau, Seaborn, Python, R, AWS VIEW and NodeJS?\n",
      "Assistant: The possible positions for N/A are: Asst. Manager/ Manger (Administrative). Key responsibilities include: Administrative Support, Scheduling, Filing & Documentation, Communication, Team Support, Equipment Maintenance, Information Provision, Inventory Management, Team Collaboration, OHS Policy Development, Safety Advice, Risk Assessment, Policy Review, OHS Training, Safety Inspections, Unsafe Act Prevention, Incident Investigation, Report Preparation\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Business Administration?\n",
      "Assistant: The possible positions for Bachelor of Business Administration are: Machine Learning (ML) Engineer with an experience requirement of At least 5 year(s). The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.E. (Computers)?\n",
      "Assistant: The possible positions for B.E. (Computers) are: Senior Software Engineer with an experience requirement of At least 1 year. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Course Revisions for the: National Electrical Code and Associate Degree?\n",
      "Assistant: The possible positions for Course Revisions for the: National Electrical Code and Associate Degree are: Civil Engineer with an experience requirement of At least 5 years. The related skills are Electrical systems, Maintenance, Customer relationship, Troubleshooting, Repair, Maintenance, Day-to-day operations, Leadership and Guidance\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Tech and MS?\n",
      "Assistant: The possible positions for B.Tech and MS are: System Administrator (Operation & Maintenance of Server, Storage & Service Desk System) with an experience requirement of 4 to 5 years. The related skills are Python, Chaco Plotting Library and Traits UI Library\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Business Administration?\n",
      "Assistant: The possible positions for Bachelor of Business Administration are: Asst. Manager/ Manger (Administrative) with an experience requirement of At least 5 years. The related skills are Maintain inventory, Manufacturing Orders, Supervise Planning Departments, customer relations, paperless manufacturing system, MRP software, Determine labor requirements, order, maintain inventories, schedule work, plan, purchase, production engineering, shipping/receiving, drafting, Determine labor requirements, Plan ship dates, order and maintain inventories, Plan work schedule, Manage people, Plan products, testing, assembly, designing BOM's and router\n",
      "\n",
      "User: What positions match my major in Mechanical and my skills in Research Associate, Business Analyst, Business Analytics, Data Mining, Data Modeling, Predictive Analysis, Business Intelligence, Machine Learning, Market Research, Customer Engagement, Risk Management, Retention, Audience and Python?\n",
      "Assistant: The possible positions for Mechanical are: Mechanical Engineer. Key responsibilities include: Machinery Maintenance, Troubleshooting, Report Preparation, Log Maintenance\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.E. (Computers)?\n",
      "Assistant: The possible positions for B.E. (Computers) are: DevOps Engineer with an experience requirement of At least 3 years. The related skills are IAM solutions, SailPoint, Java, security alerts, requirements gathering and design & development\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Science?\n",
      "Assistant: The possible positions for Bachelor of Science are: Senior Software Engineer with an experience requirement of At least 1 year. The related skills are Creating dashboards for sales and profits\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Tech?\n",
      "Assistant: The possible positions for B.Tech are: Data Engineer with an experience requirement of 5 to 8 years. The related skills are NLP and Data Analysis\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Engineering?\n",
      "Assistant: The possible positions for Bachelor of Engineering are: Mechanical Designer with an experience requirement of At least 5 years. The related skills are Software Development and Application Programming\n",
      "\n",
      "User: What positions match my major in Electrical and Electrical and my skills in Book, Budget 5, Budget, Carpentry, Coaching, Communication skills, Communication, Skills, CA, Consulting, Contracts, Counseling, Customer services, Designing, Drafting, Engineer, Estimating, Features, First aid, Focus, Hand tools, HVAC, Inventory, Leadership skills, Leadership, Materials, Mathematics, Mechanical, Meetings, Painting, Payroll, Performance reviews, Personnel, Physics, Plumbing, Property Management, Purchasing, Read, Reading, Record keeping, Repairs, Safety, Scanners, Staff, Training, Supervision, Supervising, Test equipment, Troubleshooting, Type and Wiring?\n",
      "Assistant: The possible positions for Electrical and Electrical are: Senior iOS Engineer. Key responsibilities include: iOS Lifecycle, Requirement Analysis, Native Frameworks, iOS Development, API Integration, Technical Communication, UI Design, Performance Optimization, Feature Collaboration, Bug Fixing, Code Translation, High-Performance Development, Task Management, Cross-Team Collaboration, Code Quality\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X?\n",
      "Assistant: The possible positions for B.Tech. (Electrical Engineering Specialization in Computer Science), XII and X are: Head of Internal Control & Compliance (ICC) - SEVP/DMD with an experience requirement of At least 15 years. The related skills are NLP, Web Scraping, bs4, LDA Topic Modeling, OCR, Pytesseract and NER Text Classification\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Science?\n",
      "Assistant: The possible positions for Bachelor of Science are: Machine Learning (ML) Engineer with an experience requirement of At least 5 year(s). The related skills are Creating dashboards for sales and profits\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in BSc and MSc?\n",
      "Assistant: The possible positions for BSc and MSc are: Senior iOS Engineer with an experience requirement of At least 4 years. The related skills are NLP, ML and Amazon Comprehend Medical API\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in BBA?\n",
      "Assistant: The possible positions for BBA are: Executive - VAT with an experience requirement of 1 to 3 years. The related skills are Data Analysis and Business Analysis\n",
      "\n",
      "User: What positions match my major in Statistics and my skills in Python, Webscrapping, PowerBI, Data Cleaning, Data Preparation, Data Analysis, Predictive Modeling, Data Analytics, Pivot Table, SQL, PostgreSQL, Analytics, Excel, Machine Learning and XML?\n",
      "Assistant: The possible positions for Statistics are: Full Stack Developer (Python,React js). Key responsibilities include: Full Stack Development, Front-end: ReactJS, NextJS, Backend: Python, Django, API Design, Server-Side Logic, DRF (Django REST Framework), Database Management (PostgreSQL, MySQL), Version Control (Git), AWS (ECR, RDS, ECS, ALB, EC2, etc.), Linux, Docker, CI/CD, GitLab, Terraform, Shell Scripting\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Engineering?\n",
      "Assistant: The possible positions for Bachelor of Engineering are: Mechanical Engineer with an experience requirement of 2 to 5 years. The related skills are Software Development and Application Programming\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in B.Sc and MCA?\n",
      "Assistant: The possible positions for B.Sc and MCA are: Database Administrator (DBA) with an experience requirement of At least 1 year. The related skills are Neural Networks, Machine Learning and Image recognition\n",
      "\n",
      "User: What positions match my major in Electrical and Artificial intelligence and Machine Learning and my skills in Data Analysis, EDA, Python, Machine Learning, SQL, NLP, MATLAB, C#, Node.Js, Statistics, Business Analytics, Predictive Modeling and Data Modeling?\n",
      "Assistant: The possible positions for Electrical and Artificial intelligence and Machine Learning are: Data Science Engineer. Key responsibilities include: Application Development, Object-Oriented Design, Collaboration, Problem-Solving, Software Lifecycle, Innovation, Software Testing, System Analysis, Performance Monitoring, Plugin Development, Documentation, Integration Support\n",
      "\n",
      "User: What are the positions I can apply for if I have a degree in Bachelor of Engineering?\n",
      "Assistant: The possible positions for Bachelor of Engineering are: Civil Engineer with an experience requirement of At least 5 years. The related skills are Software Development and Application Programming\n",
      "\n",
      "User: What positions match my major in Computers and my skills in Machine Learning, Data Analysis, Data Visualization, Risk Assessment, Debugging, Database Management, Access Control, IAM, Sail point, Java, Python, MySQL, MongoDB and Data Structures?\n",
      "Assistant: The possible positions for Computers are: Executive/ Senior Executive- Trade Marketing, Hygiene Products. Key responsibilities include: Trade Marketing Executive, Brand Visibility, Sales Targets, Field Marketing, Campaigns, Product Distribution, Brand Head, Excel, KPIs Tracking\n"
     ]
    }
   ],
   "source": [
    "with open(\"test_dataset.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "utIIVaLkgutC",
    "outputId": "ebb61662-39e4-4c9a-9614-09b13147cb33",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build: 6713 (d2ee056e) with cc (GCC) 11.5.0 20240719 (Red Hat 11.5.0-5) for x86_64-redhat-linux\n",
      "llama_model_loader: loaded meta data with 28 key-value pairs and 255 tensors from ./quantized_models/ft-q4_k_m-lora.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = sharshar20/lora-and-instruct-merged-m...\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = 73726fa7ef0ee6120f23358531a4862b42133839\n",
      "llama_model_loader: - kv   4:                         general.size_label str              = 3.2B\n",
      "llama_model_loader: - kv   5:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   6:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   7:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   8:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   9:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv  10:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  12:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  13:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  14:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  24:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  25:               tokenizer.ggml.add_sep_token bool             = false\n",
      "llama_model_loader: - kv  26:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  27:                          general.file_type u32              = 15\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type q4_K:  168 tensors\n",
      "llama_model_loader: - type q6_K:   29 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 1.87 GiB (5.01 BPW) \n",
      "load: printing all EOG tokens:\n",
      "load:   - 128001 ('<|end_of_text|>')\n",
      "load:   - 128008 ('<|eom_id|>')\n",
      "load:   - 128009 ('<|eot_id|>')\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.7999 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 3072\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 24\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 3\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 3.21 B\n",
      "print_info: general.name     = sharshar20/lora-and-instruct-merged-model-v8\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128009 '<|eot_id|>'\n",
      "print_info: EOT token        = 128009 '<|eot_id|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors:   CPU_Mapped model buffer size =  1904.85 MiB\n",
      "load_tensors:   CPU_REPACK model buffer size =  1299.38 MiB\n",
      "....................................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 4\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 512\n",
      "llama_context: n_batch       = 2048\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = auto\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 500000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (512) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "\u001b[0mllama_context:        CPU  output buffer size =     1.96 MiB\n",
      "llama_kv_cache:        CPU KV buffer size =   224.00 MiB\n",
      "llama_kv_cache: size =  224.00 MiB (   512 cells,  28 layers,  4/4 seqs), K (f16):  112.00 MiB, V (f16):  112.00 MiB\n",
      "llama_context: Flash Attention was auto, set to enabled\n",
      "llama_context:        CPU compute buffer size =   256.50 MiB\n",
      "llama_context: graph nodes  = 931\n",
      "llama_context: graph splits = 1\n",
      "common_init_from_params: added <|end_of_text|> logit bias = -inf\n",
      "common_init_from_params: added <|eom_id|> logit bias = -inf\n",
      "common_init_from_params: added <|eot_id|> logit bias = -inf\n",
      "common_init_from_params: setting dry_penalty_last_n to ctx_size = 2048\n",
      "common_init_from_params: warming up the model with an empty run - please wait ... (--no-warmup to disable)\n",
      "\u001b[0m\n",
      "system_info: n_threads = 36 (n_threads_batch = 36) / 72 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | AVX512_VNNI = 1 | LLAMAFILE = 1 | REPACK = 1 | \n",
      "perplexity: tokenizing the input ..\n",
      "perplexity: tokenization took 22.835 ms\n",
      "perplexity: calculating perplexity over 55 chunks, n_ctx=512, batch_size=2048, n_seq=4\n",
      "perplexity: 510.76 seconds per pass - ETA 1 hours 57.03 minutes\n",
      "[1]3.1530,[2]3.1302,[3]3.0523,[4]3.1657,[5]3.0814,[6]2.9719,[7]2.9704,[8]2.9907,[9]2.8905,[10]2.8954,[11]2.9363,[12]2.9434,[13]2.9512,[14]2.9694,[15]2.9630,[16]2.9825,^C\n"
     ]
    }
   ],
   "source": [
    "!./llama.cpp/build/bin/llama-perplexity -m ./quantized_models/ft-q4_k_m-lora.gguf -f test_dataset.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ETZzdYt51XxT",
    "outputId": "b35399c9-697f-4f73-f0d0-a6b38e7f817a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build: 6713 (d2ee056e) with cc (GCC) 11.5.0 20240719 (Red Hat 11.5.0-5) for x86_64-redhat-linux\n",
      "llama_model_loader: loaded meta data with 28 key-value pairs and 255 tensors from ./quantized_models/ft-q5_k_m-lora.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = sharshar20/lora-and-instruct-merged-m...\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = 73726fa7ef0ee6120f23358531a4862b42133839\n",
      "llama_model_loader: - kv   4:                         general.size_label str              = 3.2B\n",
      "llama_model_loader: - kv   5:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   6:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   7:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   8:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   9:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv  10:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  12:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  13:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  14:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  24:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  25:               tokenizer.ggml.add_sep_token bool             = false\n",
      "llama_model_loader: - kv  26:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  27:                          general.file_type u32              = 17\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type q5_K:  168 tensors\n",
      "llama_model_loader: - type q6_K:   29 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q5_K - Medium\n",
      "print_info: file size   = 2.16 GiB (5.76 BPW) \n",
      "load: printing all EOG tokens:\n",
      "load:   - 128001 ('<|end_of_text|>')\n",
      "load:   - 128008 ('<|eom_id|>')\n",
      "load:   - 128009 ('<|eot_id|>')\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.7999 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 3072\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 24\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 3\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 3.21 B\n",
      "print_info: general.name     = sharshar20/lora-and-instruct-merged-model-v8\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128009 '<|eot_id|>'\n",
      "print_info: EOT token        = 128009 '<|eot_id|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors:   CPU_Mapped model buffer size =  2207.10 MiB\n",
      "........................................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 4\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 512\n",
      "llama_context: n_batch       = 2048\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = auto\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 500000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (512) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "\u001b[0mllama_context:        CPU  output buffer size =     1.96 MiB\n",
      "llama_kv_cache:        CPU KV buffer size =   224.00 MiB\n",
      "llama_kv_cache: size =  224.00 MiB (   512 cells,  28 layers,  4/4 seqs), K (f16):  112.00 MiB, V (f16):  112.00 MiB\n",
      "llama_context: Flash Attention was auto, set to enabled\n",
      "llama_context:        CPU compute buffer size =   256.50 MiB\n",
      "llama_context: graph nodes  = 931\n",
      "llama_context: graph splits = 1\n",
      "common_init_from_params: added <|end_of_text|> logit bias = -inf\n",
      "common_init_from_params: added <|eom_id|> logit bias = -inf\n",
      "common_init_from_params: added <|eot_id|> logit bias = -inf\n",
      "common_init_from_params: setting dry_penalty_last_n to ctx_size = 2048\n",
      "common_init_from_params: warming up the model with an empty run - please wait ... (--no-warmup to disable)\n",
      "\u001b[0m\n",
      "system_info: n_threads = 36 (n_threads_batch = 36) / 72 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | AVX512_VNNI = 1 | LLAMAFILE = 1 | REPACK = 1 | \n",
      "perplexity: tokenizing the input ..\n",
      "perplexity: tokenization took 21.734 ms\n",
      "perplexity: calculating perplexity over 55 chunks, n_ctx=512, batch_size=2048, n_seq=4\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!./llama.cpp/build/bin/llama-perplexity -m ./quantized_models/ft-q5_k_m-lora.gguf -f test_dataset.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ETZzdYt51XxT",
    "outputId": "b35399c9-697f-4f73-f0d0-a6b38e7f817a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build: 6713 (d2ee056e) with cc (GCC) 11.5.0 20240719 (Red Hat 11.5.0-5) for x86_64-redhat-linux\n",
      "llama_model_loader: loaded meta data with 28 key-value pairs and 255 tensors from ./quantized_models/ft-q8_0-lora.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = sharshar20/lora-and-instruct-merged-m...\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = 73726fa7ef0ee6120f23358531a4862b42133839\n",
      "llama_model_loader: - kv   4:                         general.size_label str              = 3.2B\n",
      "llama_model_loader: - kv   5:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   6:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   7:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   8:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   9:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv  10:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  12:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  13:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  14:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  24:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  25:               tokenizer.ggml.add_sep_token bool             = false\n",
      "llama_model_loader: - kv  26:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  27:                          general.file_type u32              = 7\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type q8_0:  197 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q8_0\n",
      "print_info: file size   = 3.18 GiB (8.50 BPW) \n",
      "load: printing all EOG tokens:\n",
      "load:   - 128001 ('<|end_of_text|>')\n",
      "load:   - 128008 ('<|eom_id|>')\n",
      "load:   - 128009 ('<|eot_id|>')\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.7999 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 3072\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 24\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 3\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 3.21 B\n",
      "print_info: general.name     = sharshar20/lora-and-instruct-merged-model-v8\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128009 '<|eot_id|>'\n",
      "print_info: EOT token        = 128009 '<|eot_id|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors:   CPU_Mapped model buffer size =  3255.90 MiB\n",
      ".........................................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 4\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 512\n",
      "llama_context: n_batch       = 2048\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = auto\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 500000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (512) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "\u001b[0mllama_context:        CPU  output buffer size =     1.96 MiB\n",
      "llama_kv_cache:        CPU KV buffer size =   224.00 MiB\n",
      "llama_kv_cache: size =  224.00 MiB (   512 cells,  28 layers,  4/4 seqs), K (f16):  112.00 MiB, V (f16):  112.00 MiB\n",
      "llama_context: Flash Attention was auto, set to enabled\n",
      "llama_context:        CPU compute buffer size =   256.50 MiB\n",
      "llama_context: graph nodes  = 931\n",
      "llama_context: graph splits = 1\n",
      "common_init_from_params: added <|end_of_text|> logit bias = -inf\n",
      "common_init_from_params: added <|eom_id|> logit bias = -inf\n",
      "common_init_from_params: added <|eot_id|> logit bias = -inf\n",
      "common_init_from_params: setting dry_penalty_last_n to ctx_size = 2048\n",
      "common_init_from_params: warming up the model with an empty run - please wait ... (--no-warmup to disable)\n",
      "\u001b[0m^C\n"
     ]
    }
   ],
   "source": [
    "!./llama.cpp/build/bin/llama-perplexity -m ./quantized_models/ft-q8_0-lora.gguf -f test_dataset.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bX9om273MDDo",
    "outputId": "b176db28-111b-43a4-b78e-8809a4547a0c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build: 6713 (d2ee056e) with cc (GCC) 11.5.0 20240719 (Red Hat 11.5.0-5) for x86_64-redhat-linux\n",
      "llama_model_loader: loaded meta data with 28 key-value pairs and 255 tensors from ./quantized_models/fp16-ft-base.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Base_Instruct_Model\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 3.2B\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   5:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  14:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  17:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  25:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  26:               tokenizer.ggml.add_sep_token bool             = false\n",
      "llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type  f16:  197 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = F16\n",
      "print_info: file size   = 5.98 GiB (16.00 BPW) \n",
      "load: printing all EOG tokens:\n",
      "load:   - 128001 ('<|end_of_text|>')\n",
      "load:   - 128008 ('<|eom_id|>')\n",
      "load:   - 128009 ('<|eot_id|>')\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.7999 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 3072\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 24\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 3\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 3.21 B\n",
      "print_info: general.name     = Base_Instruct_Model\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128009 '<|eot_id|>'\n",
      "print_info: EOT token        = 128009 '<|eot_id|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB\n",
      ".........................................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 4\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 512\n",
      "llama_context: n_batch       = 2048\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = auto\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 500000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (512) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "\u001b[0mllama_context:        CPU  output buffer size =     1.96 MiB\n",
      "llama_kv_cache:        CPU KV buffer size =   224.00 MiB\n",
      "llama_kv_cache: size =  224.00 MiB (   512 cells,  28 layers,  4/4 seqs), K (f16):  112.00 MiB, V (f16):  112.00 MiB\n",
      "llama_context: Flash Attention was auto, set to enabled\n",
      "llama_context:        CPU compute buffer size =   256.50 MiB\n",
      "llama_context: graph nodes  = 931\n",
      "llama_context: graph splits = 1\n",
      "common_init_from_params: added <|end_of_text|> logit bias = -inf\n",
      "common_init_from_params: added <|eom_id|> logit bias = -inf\n",
      "common_init_from_params: added <|eot_id|> logit bias = -inf\n",
      "common_init_from_params: setting dry_penalty_last_n to ctx_size = 2048\n",
      "common_init_from_params: warming up the model with an empty run - please wait ... (--no-warmup to disable)\n",
      "\u001b[0m^C\n"
     ]
    }
   ],
   "source": [
    "!./llama.cpp/build/bin/llama-perplexity -m ./quantized_models/fp16-ft-base.gguf -f test_dataset.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build: 6713 (d2ee056e) with cc (GCC) 11.5.0 20240719 (Red Hat 11.5.0-5) for x86_64-redhat-linux\n",
      "llama_model_loader: loaded meta data with 28 key-value pairs and 255 tensors from ./quantized_models/fp16-ft-lora.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = sharshar20/lora-and-instruct-merged-m...\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = 73726fa7ef0ee6120f23358531a4862b42133839\n",
      "llama_model_loader: - kv   4:                         general.size_label str              = 3.2B\n",
      "llama_model_loader: - kv   5:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   6:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   7:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   8:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   9:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv  10:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  12:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  13:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  14:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  15:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  16:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  17:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  19:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  20:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  21:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  22:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  23:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  25:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  26:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  27:               tokenizer.ggml.add_sep_token bool             = false\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type  f16:  197 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = F16\n",
      "print_info: file size   = 5.98 GiB (16.00 BPW) \n",
      "load: printing all EOG tokens:\n",
      "load:   - 128001 ('<|end_of_text|>')\n",
      "load:   - 128008 ('<|eom_id|>')\n",
      "load:   - 128009 ('<|eot_id|>')\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.7999 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 3072\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 24\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 3\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 3.21 B\n",
      "print_info: general.name     = sharshar20/lora-and-instruct-merged-model-v8\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128009 '<|eot_id|>'\n",
      "print_info: EOT token        = 128009 '<|eot_id|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!./llama.cpp/build/bin/llama-perplexity -m ./quantized_models/fp16-ft-lora.gguf -f test_dataset.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build: 6713 (d2ee056e) with cc (GCC) 11.5.0 20240719 (Red Hat 11.5.0-5) for x86_64-redhat-linux\n",
      "llama_model_loader: loaded meta data with 28 key-value pairs and 255 tensors from ./quantized_models/ft-qlora-q4_k_m.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = sharshar20/qlora-and-instruct-merged-...\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = 63ca988a213869eb09ceba03025bd486edd01feb\n",
      "llama_model_loader: - kv   4:                         general.size_label str              = 3.2B\n",
      "llama_model_loader: - kv   5:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   6:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   7:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   8:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   9:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv  10:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  12:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  13:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  14:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  17:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  18:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  20:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  21:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  24:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  25:               tokenizer.ggml.add_sep_token bool             = false\n",
      "llama_model_loader: - kv  26:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  27:                          general.file_type u32              = 15\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type q4_K:  168 tensors\n",
      "llama_model_loader: - type q6_K:   29 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 1.87 GiB (5.01 BPW) \n",
      "load: printing all EOG tokens:\n",
      "load:   - 128001 ('<|end_of_text|>')\n",
      "load:   - 128008 ('<|eom_id|>')\n",
      "load:   - 128009 ('<|eot_id|>')\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.7999 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 3072\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 24\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 3\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 3.21 B\n",
      "print_info: general.name     = sharshar20/qlora-and-instruct-merged-model-v7\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128009 '<|eot_id|>'\n",
      "print_info: EOT token        = 128009 '<|eot_id|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors:   CPU_Mapped model buffer size =  1904.85 MiB\n",
      "load_tensors:   CPU_REPACK model buffer size =  1299.38 MiB\n",
      "....................................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 4\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 512\n",
      "llama_context: n_batch       = 2048\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = auto\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 500000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (512) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "\u001b[0mllama_context:        CPU  output buffer size =     1.96 MiB\n",
      "llama_kv_cache:        CPU KV buffer size =   224.00 MiB\n",
      "llama_kv_cache: size =  224.00 MiB (   512 cells,  28 layers,  4/4 seqs), K (f16):  112.00 MiB, V (f16):  112.00 MiB\n",
      "llama_context: Flash Attention was auto, set to enabled\n",
      "llama_context:        CPU compute buffer size =   256.50 MiB\n",
      "llama_context: graph nodes  = 931\n",
      "llama_context: graph splits = 1\n",
      "common_init_from_params: added <|end_of_text|> logit bias = -inf\n",
      "common_init_from_params: added <|eom_id|> logit bias = -inf\n",
      "common_init_from_params: added <|eot_id|> logit bias = -inf\n",
      "common_init_from_params: setting dry_penalty_last_n to ctx_size = 2048\n",
      "common_init_from_params: warming up the model with an empty run - please wait ... (--no-warmup to disable)\n",
      "\u001b[0m^C\n"
     ]
    }
   ],
   "source": [
    "!./llama.cpp/build/bin/llama-perplexity -m ./quantized_models/ft-qlora-q4_k_m.gguf -f test_dataset.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-jrMm9kS4CY"
   },
   "source": [
    "#### TTFT and TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_text': 'What are the entry-level requirements for a Legal Assistant?',\n",
       " 'target_text': 'Entry-level requirements typically include a Bachelor’s degree or completion of a legal assistant certification program. Some positions may accept candidates with relevant experience or internships in the legal field.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "from llama_cpp import Llama\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_llama_latency(repo_id, filename,test_dataset,cache_dir=\"latency\", n_ctx=2048,n_gpu_layers=-1,n_threads=8,max_tokens=50, num_runs=10,use_mlock=True,):\n",
    "    # Download Model\n",
    "    model_path = hf_hub_download(\n",
    "        repo_id=repo_id,\n",
    "        filename=filename,\n",
    "        cache_dir=cache_dir\n",
    "    )\n",
    "\n",
    "    # Load Model\n",
    "    start_load = time.time()\n",
    "    llm = Llama(\n",
    "        model_path=model_path,\n",
    "        n_ctx=n_ctx,\n",
    "        n_threads=n_threads,\n",
    "        #n_gpu_layers=n_gpu_layers,\n",
    "        use_mlock=use_mlock\n",
    "    )\n",
    "    load_time = time.time() - start_load\n",
    "\n",
    "    # Measure Latency\n",
    "    ttft_list = []\n",
    "    token_latency_list = []\n",
    "\n",
    "    for i in tqdm(range(num_runs), desc=\"Evaluating prompts\"):\n",
    "        prompt = test_dataset[i % len(test_dataset)][\"input_text\"]\n",
    "\n",
    "        start_time = time.time()\n",
    "        first_token_time = None\n",
    "        prev_time = None\n",
    "        token_times = []\n",
    "        output_tokens = []\n",
    "\n",
    "        for idx, token in enumerate(llm(prompt, max_tokens=max_tokens, stream=True)):\n",
    "            now = time.time()\n",
    "            if idx == 0:\n",
    "                first_token_time = now - start_time\n",
    "                prev_time = now\n",
    "            else:\n",
    "                token_times.append(now - prev_time)\n",
    "                prev_time = now\n",
    "            output_tokens.append(token[\"choices\"][0][\"text\"])\n",
    "\n",
    "        # Store metrics\n",
    "        ttft_list.append(first_token_time * 1000)\n",
    "        token_latency_list.extend([t * 1000 for t in token_times])\n",
    "\n",
    "        tpot = np.mean([t * 1000 for t in token_times]) if token_times else 0\n",
    "        e2e_latency = (time.time() - start_time) * 1000\n",
    "        formula_e2e = first_token_time * 1000 + tpot * len(token_times)\n",
    "\n",
    "        print(f\"\\nPrompt {i+1}:\")\n",
    "        print(f\"TTFT: {first_token_time*1000:.2f} ms\")\n",
    "        print(f\"TPOT: {tpot:.2f} ms/token\")\n",
    "        print(f\"E2E Measured: {e2e_latency:.2f} ms\")\n",
    "        print(f\"E2E Formula:  {formula_e2e:.2f} ms\")\n",
    "\n",
    "    # --- Compute Aggregate Statistics ---\n",
    "    avg_ttft = np.mean(ttft_list)\n",
    "    avg_token_latency = np.mean(token_latency_list)\n",
    "    p50, p95, p99 = np.percentile(token_latency_list, [50, 95, 99])\n",
    "\n",
    "    results = {\n",
    "        \"avg_ttft_ms\": avg_ttft,\n",
    "        \"avg_tpot_ms\": avg_token_latency,\n",
    "        \"p50_ms\": p50,\n",
    "        \"p95_ms\": p95,\n",
    "        \"p99_ms\": p99,\n",
    "        \"load_time_s\": load_time\n",
    "    }\n",
    "\n",
    "    print(\"\\n--- Overall Token Latency Stats ---\")\n",
    "    print(f\"Average TTFT: {avg_ttft:.2f} ms\")\n",
    "    print(f\"Average TPOT: {avg_token_latency:.2f} ms\")\n",
    "    print(f\"P50: {p50:.2f} ms, P95: {p95:.2f} ms, P99: {p99:.2f} ms\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f0c68fd9854fd1b656113f64ed8d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fp16-ft-base.gguf:   0%|          | 0.00/6.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 28 key-value pairs and 255 tensors from latency/models--sharshar20--llama3.2_3B_instruct-GGUF-v6/snapshots/6404c56ca2726fd54b86b260c71365a86b1bbd95/fp16-ft-base.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Base_Instruct_Model\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 3.2B\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   5:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  14:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  17:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  25:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  26:               tokenizer.ggml.add_sep_token bool             = false\n",
      "llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type  f16:  197 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = F16\n",
      "print_info: file size   = 5.98 GiB (16.00 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
      "load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
      "load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
      "load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
      "load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
      "load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
      "load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
      "load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
      "load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
      "load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
      "load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
      "load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
      "load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
      "load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
      "load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
      "load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
      "load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
      "load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
      "load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
      "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
      "load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
      "load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
      "load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
      "load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "load: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
      "load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
      "load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
      "load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
      "load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
      "load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
      "load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
      "load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
      "load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
      "load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "load: printing all EOG tokens:\n",
      "load:   - 128001 ('<|end_of_text|>')\n",
      "load:   - 128008 ('<|eom_id|>')\n",
      "load:   - 128009 ('<|eot_id|>')\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.7999 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 3072\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 24\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 3\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 3.21 B\n",
      "print_info: general.name     = Base_Instruct_Model\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128009 '<|eot_id|>'\n",
      "print_info: EOT token        = 128009 '<|eot_id|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (f16) (and 282 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
      "load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB\n",
      ".........................................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 2048\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 500000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.49 MiB\n",
      "create_memory: n_ctx = 2048 (padded)\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified: layer  16: dev = CPU\n",
      "llama_kv_cache_unified: layer  17: dev = CPU\n",
      "llama_kv_cache_unified: layer  18: dev = CPU\n",
      "llama_kv_cache_unified: layer  19: dev = CPU\n",
      "llama_kv_cache_unified: layer  20: dev = CPU\n",
      "llama_kv_cache_unified: layer  21: dev = CPU\n",
      "llama_kv_cache_unified: layer  22: dev = CPU\n",
      "llama_kv_cache_unified: layer  23: dev = CPU\n",
      "llama_kv_cache_unified: layer  24: dev = CPU\n",
      "llama_kv_cache_unified: layer  25: dev = CPU\n",
      "llama_kv_cache_unified: layer  26: dev = CPU\n",
      "llama_kv_cache_unified: layer  27: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =   224.00 MiB\n",
      "llama_kv_cache_unified: size =  224.00 MiB (  2048 cells,  28 layers,  1/1 seqs), K (f16):  112.00 MiB, V (f16):  112.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 1\n",
      "llama_context: max_nodes = 2040\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "llama_context:        CPU compute buffer size =   256.50 MiB\n",
      "llama_context: graph nodes  = 986\n",
      "llama_context: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | AVX512_VNNI = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- if strftime_now is defined %}\\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\\n    {%- else %}\\n        {%- set date_string = \"26 Jul 2024\" %}\\n    {%- endif %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n        {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n        {{- \\'\"parameters\": \\' }}\\n        {{- tool_call.arguments | tojson }}\\n        {{- \"}\" }}\\n        {{- \"<|eot_id|>\" }}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.eos_token_id': '128009', 'tokenizer.ggml.model': 'gpt2', 'general.quantization_version': '2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '1', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Base_Instruct_Model', 'general.type': 'model', 'general.size_label': '3.2B', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.add_sep_token': 'false', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- if strftime_now is defined %}\n",
      "        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n",
      "    {%- else %}\n",
      "        {%- set date_string = \"26 Jul 2024\" %}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "        {{- '\"parameters\": ' }}\n",
      "        {{- tool_call.arguments | tojson }}\n",
      "        {{- \"}\" }}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n",
      "Evaluating prompts:   0%|          | 0/10 [00:00<?, ?it/s]llama_perf_context_print:        load time =    1690.17 ms\n",
      "llama_perf_context_print: prompt eval time =    1690.03 ms /    12 tokens (  140.84 ms per token,     7.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24648.41 ms /    49 runs   (  503.03 ms per token,     1.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   26390.05 ms /    61 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  10%|█         | 1/10 [00:26<03:57, 26.39s/it]Llama.generate: 2 prefix-match hit, remaining 10 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1:\n",
      "TTFT: 1691.41 ms\n",
      "TPOT: 494.06 ms/token\n",
      "E2E Measured: 26394.58 ms\n",
      "E2E Formula:  26394.45 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1690.17 ms\n",
      "llama_perf_context_print: prompt eval time =    1562.40 ms /    10 tokens (  156.24 ms per token,     6.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24645.57 ms /    49 runs   (  502.97 ms per token,     1.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   26259.40 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  20%|██        | 2/10 [00:52<03:30, 26.32s/it]Llama.generate: 2 prefix-match hit, remaining 10 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 2:\n",
      "TTFT: 1563.79 ms\n",
      "TPOT: 493.97 ms/token\n",
      "E2E Measured: 26262.21 ms\n",
      "E2E Formula:  26262.12 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1690.17 ms\n",
      "llama_perf_context_print: prompt eval time =    1559.01 ms /    10 tokens (  155.90 ms per token,     6.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24641.85 ms /    49 runs   (  502.89 ms per token,     1.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   26252.35 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  30%|███       | 3/10 [01:18<03:04, 26.29s/it]Llama.generate: 2 prefix-match hit, remaining 9 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 3:\n",
      "TTFT: 1560.39 ms\n",
      "TPOT: 493.90 ms/token\n",
      "E2E Measured: 26255.47 ms\n",
      "E2E Formula:  26255.36 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1690.17 ms\n",
      "llama_perf_context_print: prompt eval time =    1495.86 ms /     9 tokens (  166.21 ms per token,     6.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24692.54 ms /    49 runs   (  503.93 ms per token,     1.98 tokens per second)\n",
      "llama_perf_context_print:       total time =   26239.73 ms /    58 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  40%|████      | 4/10 [01:45<02:37, 26.27s/it]Llama.generate: 2 prefix-match hit, remaining 13 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 4:\n",
      "TTFT: 1497.26 ms\n",
      "TPOT: 494.90 ms/token\n",
      "E2E Measured: 26242.51 ms\n",
      "E2E Formula:  26242.41 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1690.17 ms\n",
      "llama_perf_context_print: prompt eval time =    1748.00 ms /    13 tokens (  134.46 ms per token,     7.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24659.97 ms /    49 runs   (  503.26 ms per token,     1.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   26459.46 ms /    62 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  50%|█████     | 5/10 [02:11<02:11, 26.34s/it]Llama.generate: 1 prefix-match hit, remaining 14 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 5:\n",
      "TTFT: 1749.40 ms\n",
      "TPOT: 494.25 ms/token\n",
      "E2E Measured: 26461.97 ms\n",
      "E2E Formula:  26461.86 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1690.17 ms\n",
      "llama_perf_context_print: prompt eval time =    1861.10 ms /    14 tokens (  132.94 ms per token,     7.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24631.96 ms /    49 runs   (  502.69 ms per token,     1.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   26544.62 ms /    63 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  60%|██████    | 6/10 [02:38<01:45, 26.41s/it]Llama.generate: 1 prefix-match hit, remaining 13 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 6:\n",
      "TTFT: 1862.50 ms\n",
      "TPOT: 493.70 ms/token\n",
      "E2E Measured: 26547.36 ms\n",
      "E2E Formula:  26547.27 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1690.17 ms\n",
      "llama_perf_context_print: prompt eval time =    1765.94 ms /    13 tokens (  135.84 ms per token,     7.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24639.77 ms /    49 runs   (  502.85 ms per token,     1.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   26457.30 ms /    62 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  70%|███████   | 7/10 [03:04<01:19, 26.43s/it]Llama.generate: 1 prefix-match hit, remaining 8 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 7:\n",
      "TTFT: 1767.38 ms\n",
      "TPOT: 493.85 ms/token\n",
      "E2E Measured: 26459.85 ms\n",
      "E2E Formula:  26459.76 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1690.17 ms\n",
      "llama_perf_context_print: prompt eval time =    1433.15 ms /     8 tokens (  179.14 ms per token,     5.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24656.64 ms /    49 runs   (  503.20 ms per token,     1.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   26141.82 ms /    57 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  80%|████████  | 8/10 [03:30<00:52, 26.34s/it]Llama.generate: 2 prefix-match hit, remaining 10 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 8:\n",
      "TTFT: 1434.53 ms\n",
      "TPOT: 494.19 ms/token\n",
      "E2E Measured: 26144.34 ms\n",
      "E2E Formula:  26144.24 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1690.17 ms\n",
      "llama_perf_context_print: prompt eval time =    1558.91 ms /    10 tokens (  155.89 ms per token,     6.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24689.05 ms /    49 runs   (  503.86 ms per token,     1.98 tokens per second)\n",
      "llama_perf_context_print:       total time =   26299.75 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  90%|█████████ | 9/10 [03:57<00:26, 26.33s/it]Llama.generate: 2 prefix-match hit, remaining 11 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 9:\n",
      "TTFT: 1560.32 ms\n",
      "TPOT: 494.84 ms/token\n",
      "E2E Measured: 26302.23 ms\n",
      "E2E Formula:  26302.13 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1690.17 ms\n",
      "llama_perf_context_print: prompt eval time =    1605.02 ms /    11 tokens (  145.91 ms per token,     6.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24641.40 ms /    49 runs   (  502.89 ms per token,     1.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   26297.97 ms /    60 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts: 100%|██████████| 10/10 [04:23<00:00, 26.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 10:\n",
      "TTFT: 1606.45 ms\n",
      "TPOT: 493.88 ms/token\n",
      "E2E Measured: 26300.46 ms\n",
      "E2E Formula:  26300.36 ms\n",
      "\n",
      "--- Overall Token Latency Stats ---\n",
      "Average TTFT: 1629.34 ms\n",
      "Average TPOT: 494.15 ms\n",
      "P50: 503.52 ms, P95: 505.90 ms, P99: 507.95 ms\n",
      "{'avg_ttft_ms': 1629.342246055603, 'avg_tpot_ms': 494.15307092666626, 'p50_ms': 503.517746925354, 'p95_ms': 505.8958053588867, 'p99_ms': 507.95475721359253, 'load_time_s': 14.15773057937622}\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_llama_latency(repo_id=\"sharshar20/llama3.2_3B_instruct-GGUF-v6\",filename=\"fp16-ft-base.gguf\", test_dataset=test_dataset)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f102098ce244ee8b0c9c827be896363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ft-qlora-q4_k_m.gguf:   0%|          | 0.00/2.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 28 key-value pairs and 255 tensors from latency/models--sharshar20--llama3.2_3B_instruct-GGUF-v6/snapshots/6404c56ca2726fd54b86b260c71365a86b1bbd95/ft-qlora-q4_k_m.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Merged_Model_Instruct_Qlora\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 3.2B\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   5:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  14:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  15:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  16:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  17:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  18:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  19:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  21:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  22:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  23:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  24:               tokenizer.ggml.add_sep_token bool             = false\n",
      "llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - kv  26:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  27:                          general.file_type u32              = 15\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type q4_K:  168 tensors\n",
      "llama_model_loader: - type q6_K:   29 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 1.87 GiB (5.01 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
      "load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
      "load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
      "load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
      "load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
      "load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
      "load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
      "load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
      "load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
      "load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
      "load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
      "load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
      "load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
      "load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
      "load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
      "load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
      "load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
      "load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
      "load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
      "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
      "load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
      "load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
      "load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
      "load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "load: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
      "load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
      "load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
      "load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
      "load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
      "load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
      "load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
      "load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
      "load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
      "load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "load: printing all EOG tokens:\n",
      "load:   - 128001 ('<|end_of_text|>')\n",
      "load:   - 128008 ('<|eom_id|>')\n",
      "load:   - 128009 ('<|eot_id|>')\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.7999 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 3072\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 24\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 3\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 3.21 B\n",
      "print_info: general.name     = Merged_Model_Instruct_Qlora\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128009 '<|eot_id|>'\n",
      "print_info: EOT token        = 128009 '<|eot_id|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q6_K) (and 114 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
      "load_tensors:   CPU_REPACK model buffer size =  1299.38 MiB\n",
      "load_tensors:   CPU_Mapped model buffer size =  1904.85 MiB\n",
      "repack: repack tensor blk.0.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.0.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.0.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.0.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.0.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.1.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.1.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.1.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.1.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.1.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.2.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.2.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.2.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.2.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.2.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.3.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.3.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.3.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.4.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.4.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.5.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.5.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.5.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.5.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.5.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.6.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.6.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.7.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.7.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.7.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.8.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.8.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.8.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.8.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.8.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.9.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.9.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.9.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.10.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.10.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.10.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.11.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.11.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.11.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.11.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.11.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.12.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.12.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.12.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.13.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.13.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.14.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.14.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.14.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.14.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.14.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.15.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.15.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.15.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.16.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.16.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.16.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.17.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.17.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.17.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.17.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.17.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.18.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.18.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.18.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.19.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.19.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.19.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.20.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.20.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.20.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.20.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.20.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.21.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.21.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.21.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.22.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.22.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.23.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.23.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.23.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.23.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.23.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.24.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.24.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.24.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.24.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.24.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.25.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.25.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.25.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.25.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.25.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.26.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.26.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.26.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.26.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.26.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.27.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.27.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.27.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.27.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.27.ffn_up.weight with q4_K_8x8\n",
      ".................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 2048\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 500000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.49 MiB\n",
      "create_memory: n_ctx = 2048 (padded)\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified: layer  16: dev = CPU\n",
      "llama_kv_cache_unified: layer  17: dev = CPU\n",
      "llama_kv_cache_unified: layer  18: dev = CPU\n",
      "llama_kv_cache_unified: layer  19: dev = CPU\n",
      "llama_kv_cache_unified: layer  20: dev = CPU\n",
      "llama_kv_cache_unified: layer  21: dev = CPU\n",
      "llama_kv_cache_unified: layer  22: dev = CPU\n",
      "llama_kv_cache_unified: layer  23: dev = CPU\n",
      "llama_kv_cache_unified: layer  24: dev = CPU\n",
      "llama_kv_cache_unified: layer  25: dev = CPU\n",
      "llama_kv_cache_unified: layer  26: dev = CPU\n",
      "llama_kv_cache_unified: layer  27: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =   224.00 MiB\n",
      "llama_kv_cache_unified: size =  224.00 MiB (  2048 cells,  28 layers,  1/1 seqs), K (f16):  112.00 MiB, V (f16):  112.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 1\n",
      "llama_context: max_nodes = 2040\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "llama_context:        CPU compute buffer size =   256.50 MiB\n",
      "llama_context: graph nodes  = 986\n",
      "llama_context: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | AVX512_VNNI = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
      "Model metadata: {'general.file_type': '15', 'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- if strftime_now is defined %}\\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\\n    {%- else %}\\n        {%- set date_string = \"26 Jul 2024\" %}\\n    {%- endif %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n        {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n        {{- \\'\"parameters\": \\' }}\\n        {{- tool_call.arguments | tojson }}\\n        {{- \"}\" }}\\n        {{- \"<|eot_id|>\" }}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_Instruct_Qlora', 'general.type': 'model', 'general.size_label': '3.2B', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.add_sep_token': 'false', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- if strftime_now is defined %}\n",
      "        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n",
      "    {%- else %}\n",
      "        {%- set date_string = \"26 Jul 2024\" %}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "        {{- '\"parameters\": ' }}\n",
      "        {{- tool_call.arguments | tojson }}\n",
      "        {{- \"}\" }}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n",
      "Evaluating prompts:   0%|          | 0/10 [00:00<?, ?it/s]llama_perf_context_print:        load time =    1463.46 ms\n",
      "llama_perf_context_print: prompt eval time =    1463.28 ms /    12 tokens (  121.94 ms per token,     8.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10893.84 ms /    49 runs   (  222.32 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:       total time =   12408.25 ms /    61 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  10%|█         | 1/10 [00:12<01:51, 12.41s/it]Llama.generate: 2 prefix-match hit, remaining 10 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1:\n",
      "TTFT: 1464.71 ms\n",
      "TPOT: 218.92 ms/token\n",
      "E2E Measured: 12410.94 ms\n",
      "E2E Formula:  12410.74 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1463.46 ms\n",
      "llama_perf_context_print: prompt eval time =    1414.90 ms /    10 tokens (  141.49 ms per token,     7.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10914.38 ms /    49 runs   (  222.74 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:       total time =   12380.40 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  20%|██        | 2/10 [00:24<01:39, 12.40s/it]Llama.generate: 2 prefix-match hit, remaining 10 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 2:\n",
      "TTFT: 1416.40 ms\n",
      "TPOT: 219.34 ms/token\n",
      "E2E Measured: 12383.31 ms\n",
      "E2E Formula:  12383.20 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1463.46 ms\n",
      "llama_perf_context_print: prompt eval time =    1426.47 ms /    10 tokens (  142.65 ms per token,     7.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10933.25 ms /    49 runs   (  223.13 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:       total time =   12410.67 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  30%|███       | 3/10 [00:37<01:26, 12.40s/it]Llama.generate: 2 prefix-match hit, remaining 9 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 3:\n",
      "TTFT: 1427.95 ms\n",
      "TPOT: 219.71 ms/token\n",
      "E2E Measured: 12413.34 ms\n",
      "E2E Formula:  12413.24 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1463.46 ms\n",
      "llama_perf_context_print: prompt eval time =    1310.45 ms /     9 tokens (  145.61 ms per token,     6.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10982.60 ms /    49 runs   (  224.13 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:       total time =   12343.97 ms /    58 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  40%|████      | 4/10 [00:49<01:14, 12.38s/it]Llama.generate: 2 prefix-match hit, remaining 13 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 4:\n",
      "TTFT: 1311.94 ms\n",
      "TPOT: 220.70 ms/token\n",
      "E2E Measured: 12346.79 ms\n",
      "E2E Formula:  12346.69 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1463.46 ms\n",
      "llama_perf_context_print: prompt eval time =    1562.46 ms /    13 tokens (  120.19 ms per token,     8.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10904.39 ms /    49 runs   (  222.54 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:       total time =   12517.86 ms /    62 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  50%|█████     | 5/10 [01:02<01:02, 12.43s/it]Llama.generate: 1 prefix-match hit, remaining 14 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 5:\n",
      "TTFT: 1564.00 ms\n",
      "TPOT: 219.13 ms/token\n",
      "E2E Measured: 12520.70 ms\n",
      "E2E Formula:  12520.61 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1463.46 ms\n",
      "llama_perf_context_print: prompt eval time =    1671.36 ms /    14 tokens (  119.38 ms per token,     8.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10890.87 ms /    49 runs   (  222.26 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:       total time =   12614.79 ms /    63 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  60%|██████    | 6/10 [01:14<00:49, 12.50s/it]Llama.generate: 1 prefix-match hit, remaining 13 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 6:\n",
      "TTFT: 1672.82 ms\n",
      "TPOT: 218.89 ms/token\n",
      "E2E Measured: 12617.41 ms\n",
      "E2E Formula:  12617.31 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1463.46 ms\n",
      "llama_perf_context_print: prompt eval time =    1567.92 ms /    13 tokens (  120.61 ms per token,     8.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10894.34 ms /    49 runs   (  222.33 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:       total time =   12513.45 ms /    62 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  70%|███████   | 7/10 [01:27<00:37, 12.50s/it]Llama.generate: 1 prefix-match hit, remaining 8 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 7:\n",
      "TTFT: 1569.42 ms\n",
      "TPOT: 218.93 ms/token\n",
      "E2E Measured: 12516.08 ms\n",
      "E2E Formula:  12515.99 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1463.46 ms\n",
      "llama_perf_context_print: prompt eval time =    1197.20 ms /     8 tokens (  149.65 ms per token,     6.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10947.45 ms /    49 runs   (  223.42 ms per token,     4.48 tokens per second)\n",
      "llama_perf_context_print:       total time =   12195.54 ms /    57 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  80%|████████  | 8/10 [01:39<00:24, 12.41s/it]Llama.generate: 2 prefix-match hit, remaining 10 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 8:\n",
      "TTFT: 1198.65 ms\n",
      "TPOT: 220.00 ms/token\n",
      "E2E Measured: 12198.74 ms\n",
      "E2E Formula:  12198.65 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1463.46 ms\n",
      "llama_perf_context_print: prompt eval time =    1416.67 ms /    10 tokens (  141.67 ms per token,     7.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10918.48 ms /    49 runs   (  222.83 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:       total time =   12386.10 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  90%|█████████ | 9/10 [01:51<00:12, 12.40s/it]Llama.generate: 2 prefix-match hit, remaining 11 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 9:\n",
      "TTFT: 1418.13 ms\n",
      "TPOT: 219.41 ms/token\n",
      "E2E Measured: 12388.63 ms\n",
      "E2E Formula:  12388.53 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1463.46 ms\n",
      "llama_perf_context_print: prompt eval time =    1518.70 ms /    11 tokens (  138.06 ms per token,     7.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10910.04 ms /    49 runs   (  222.65 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:       total time =   12479.76 ms /    60 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts: 100%|██████████| 10/10 [02:04<00:00, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 10:\n",
      "TTFT: 1520.17 ms\n",
      "TPOT: 219.25 ms/token\n",
      "E2E Measured: 12482.55 ms\n",
      "E2E Formula:  12482.45 ms\n",
      "\n",
      "--- Overall Token Latency Stats ---\n",
      "Average TTFT: 1456.42 ms\n",
      "Average TPOT: 219.43 ms\n",
      "P50: 223.27 ms, P95: 227.49 ms, P99: 233.89 ms\n",
      "{'avg_ttft_ms': 1456.4182758331299, 'avg_tpot_ms': 219.4264702796936, 'p50_ms': 223.2745885848999, 'p95_ms': 227.4920105934143, 'p99_ms': 233.88677835464478, 'load_time_s': 4.971662282943726}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_llama_latency(repo_id=\"sharshar20/llama3.2_3B_instruct-GGUF-v6\",filename=\"ft-qlora-q4_k_m.gguf\", test_dataset=test_dataset)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 28 key-value pairs and 255 tensors from latency/models--sharshar20--llama3.2_3B_instruct-GGUF-v6/snapshots/6404c56ca2726fd54b86b260c71365a86b1bbd95/ft-q5_k_m-lora.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Merged_Model_Instruct_Lora\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 3.2B\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   5:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  14:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  15:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  16:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  17:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  18:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  19:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  21:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  22:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  23:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  24:               tokenizer.ggml.add_sep_token bool             = false\n",
      "llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - kv  26:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  27:                          general.file_type u32              = 17\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type q5_K:  168 tensors\n",
      "llama_model_loader: - type q6_K:   29 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q5_K - Medium\n",
      "print_info: file size   = 2.16 GiB (5.76 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
      "load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
      "load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
      "load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
      "load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
      "load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
      "load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
      "load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
      "load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
      "load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
      "load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
      "load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
      "load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
      "load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
      "load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
      "load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
      "load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
      "load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
      "load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
      "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
      "load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
      "load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
      "load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
      "load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "load: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
      "load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
      "load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
      "load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
      "load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
      "load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
      "load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
      "load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
      "load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
      "load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "load: printing all EOG tokens:\n",
      "load:   - 128001 ('<|end_of_text|>')\n",
      "load:   - 128008 ('<|eom_id|>')\n",
      "load:   - 128009 ('<|eot_id|>')\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.7999 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 3072\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 24\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 3\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 3.21 B\n",
      "print_info: general.name     = Merged_Model_Instruct_Lora\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128009 '<|eot_id|>'\n",
      "print_info: EOT token        = 128009 '<|eot_id|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q6_K) (and 282 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
      "load_tensors:   CPU_Mapped model buffer size =  2207.10 MiB\n",
      "........................................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 2048\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 500000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.49 MiB\n",
      "create_memory: n_ctx = 2048 (padded)\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified: layer  16: dev = CPU\n",
      "llama_kv_cache_unified: layer  17: dev = CPU\n",
      "llama_kv_cache_unified: layer  18: dev = CPU\n",
      "llama_kv_cache_unified: layer  19: dev = CPU\n",
      "llama_kv_cache_unified: layer  20: dev = CPU\n",
      "llama_kv_cache_unified: layer  21: dev = CPU\n",
      "llama_kv_cache_unified: layer  22: dev = CPU\n",
      "llama_kv_cache_unified: layer  23: dev = CPU\n",
      "llama_kv_cache_unified: layer  24: dev = CPU\n",
      "llama_kv_cache_unified: layer  25: dev = CPU\n",
      "llama_kv_cache_unified: layer  26: dev = CPU\n",
      "llama_kv_cache_unified: layer  27: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =   224.00 MiB\n",
      "llama_kv_cache_unified: size =  224.00 MiB (  2048 cells,  28 layers,  1/1 seqs), K (f16):  112.00 MiB, V (f16):  112.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 1\n",
      "llama_context: max_nodes = 2040\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "llama_context:        CPU compute buffer size =   256.50 MiB\n",
      "llama_context: graph nodes  = 986\n",
      "llama_context: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | AVX512_VNNI = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
      "Model metadata: {'general.file_type': '17', 'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- if strftime_now is defined %}\\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\\n    {%- else %}\\n        {%- set date_string = \"26 Jul 2024\" %}\\n    {%- endif %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n        {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n        {{- \\'\"parameters\": \\' }}\\n        {{- tool_call.arguments | tojson }}\\n        {{- \"}\" }}\\n        {{- \"<|eot_id|>\" }}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_Instruct_Lora', 'general.type': 'model', 'general.size_label': '3.2B', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.add_sep_token': 'false', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- if strftime_now is defined %}\n",
      "        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n",
      "    {%- else %}\n",
      "        {%- set date_string = \"26 Jul 2024\" %}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "        {{- '\"parameters\": ' }}\n",
      "        {{- tool_call.arguments | tojson }}\n",
      "        {{- \"}\" }}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n",
      "Evaluating prompts:   0%|          | 0/10 [00:00<?, ?it/s]llama_perf_context_print:        load time =    2498.68 ms\n",
      "llama_perf_context_print: prompt eval time =    2498.53 ms /    12 tokens (  208.21 ms per token,     4.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12856.79 ms /    49 runs   (  262.38 ms per token,     3.81 tokens per second)\n",
      "llama_perf_context_print:       total time =   15407.42 ms /    61 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  10%|█         | 1/10 [00:15<02:18, 15.41s/it]Llama.generate: 2 prefix-match hit, remaining 10 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1:\n",
      "TTFT: 2500.49 ms\n",
      "TPOT: 258.19 ms/token\n",
      "E2E Measured: 15410.40 ms\n",
      "E2E Formula:  15410.22 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    2498.68 ms\n",
      "llama_perf_context_print: prompt eval time =    2181.82 ms /    10 tokens (  218.18 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12869.08 ms /    49 runs   (  262.63 ms per token,     3.81 tokens per second)\n",
      "llama_perf_context_print:       total time =   15102.66 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  20%|██        | 2/10 [00:30<02:01, 15.23s/it]Llama.generate: 2 prefix-match hit, remaining 10 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 2:\n",
      "TTFT: 2183.29 ms\n",
      "TPOT: 258.44 ms/token\n",
      "E2E Measured: 15105.39 ms\n",
      "E2E Formula:  15105.30 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    2498.68 ms\n",
      "llama_perf_context_print: prompt eval time =    2180.93 ms /    10 tokens (  218.09 ms per token,     4.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12863.14 ms /    49 runs   (  262.51 ms per token,     3.81 tokens per second)\n",
      "llama_perf_context_print:       total time =   15096.62 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  30%|███       | 3/10 [00:45<01:46, 15.17s/it]Llama.generate: 2 prefix-match hit, remaining 9 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 3:\n",
      "TTFT: 2182.33 ms\n",
      "TPOT: 258.34 ms/token\n",
      "E2E Measured: 15099.27 ms\n",
      "E2E Formula:  15099.15 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    2498.68 ms\n",
      "llama_perf_context_print: prompt eval time =    2036.47 ms /     9 tokens (  226.27 ms per token,     4.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12854.13 ms /    49 runs   (  262.33 ms per token,     3.81 tokens per second)\n",
      "llama_perf_context_print:       total time =   14942.39 ms /    58 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  40%|████      | 4/10 [01:00<01:30, 15.08s/it]Llama.generate: 2 prefix-match hit, remaining 13 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 4:\n",
      "TTFT: 2038.01 ms\n",
      "TPOT: 258.14 ms/token\n",
      "E2E Measured: 14944.91 ms\n",
      "E2E Formula:  14944.83 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    2498.68 ms\n",
      "llama_perf_context_print: prompt eval time =    2648.94 ms /    13 tokens (  203.76 ms per token,     4.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12842.91 ms /    49 runs   (  262.10 ms per token,     3.82 tokens per second)\n",
      "llama_perf_context_print:       total time =   15543.42 ms /    62 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  50%|█████     | 5/10 [01:16<01:16, 15.25s/it]Llama.generate: 1 prefix-match hit, remaining 14 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 5:\n",
      "TTFT: 2650.39 ms\n",
      "TPOT: 257.91 ms/token\n",
      "E2E Measured: 15546.19 ms\n",
      "E2E Formula:  15546.09 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    2498.68 ms\n",
      "llama_perf_context_print: prompt eval time =    2754.19 ms /    14 tokens (  196.73 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12840.89 ms /    49 runs   (  262.06 ms per token,     3.82 tokens per second)\n",
      "llama_perf_context_print:       total time =   15646.78 ms /    63 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  60%|██████    | 6/10 [01:31<01:01, 15.39s/it]Llama.generate: 1 prefix-match hit, remaining 13 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 6:\n",
      "TTFT: 2755.66 ms\n",
      "TPOT: 257.87 ms/token\n",
      "E2E Measured: 15649.49 ms\n",
      "E2E Formula:  15649.40 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    2498.68 ms\n",
      "llama_perf_context_print: prompt eval time =    2605.91 ms /    13 tokens (  200.45 ms per token,     4.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12912.18 ms /    49 runs   (  263.51 ms per token,     3.79 tokens per second)\n",
      "llama_perf_context_print:       total time =   15569.87 ms /    62 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  70%|███████   | 7/10 [01:47<00:46, 15.45s/it]Llama.generate: 1 prefix-match hit, remaining 8 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 7:\n",
      "TTFT: 2607.45 ms\n",
      "TPOT: 259.30 ms/token\n",
      "E2E Measured: 15572.57 ms\n",
      "E2E Formula:  15572.47 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    2498.68 ms\n",
      "llama_perf_context_print: prompt eval time =    1880.72 ms /     8 tokens (  235.09 ms per token,     4.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12843.13 ms /    49 runs   (  262.10 ms per token,     3.82 tokens per second)\n",
      "llama_perf_context_print:       total time =   14775.63 ms /    57 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  80%|████████  | 8/10 [02:02<00:30, 15.23s/it]Llama.generate: 2 prefix-match hit, remaining 10 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 8:\n",
      "TTFT: 1882.13 ms\n",
      "TPOT: 257.92 ms/token\n",
      "E2E Measured: 14778.13 ms\n",
      "E2E Formula:  14778.04 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    2498.68 ms\n",
      "llama_perf_context_print: prompt eval time =    2172.46 ms /    10 tokens (  217.25 ms per token,     4.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12856.64 ms /    49 runs   (  262.38 ms per token,     3.81 tokens per second)\n",
      "llama_perf_context_print:       total time =   15080.54 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  90%|█████████ | 9/10 [02:17<00:15, 15.19s/it]Llama.generate: 2 prefix-match hit, remaining 11 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 9:\n",
      "TTFT: 2173.89 ms\n",
      "TPOT: 258.19 ms/token\n",
      "E2E Measured: 15083.24 ms\n",
      "E2E Formula:  15083.15 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    2498.68 ms\n",
      "llama_perf_context_print: prompt eval time =    2323.15 ms /    11 tokens (  211.20 ms per token,     4.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12852.91 ms /    49 runs   (  262.30 ms per token,     3.81 tokens per second)\n",
      "llama_perf_context_print:       total time =   15227.64 ms /    60 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts: 100%|██████████| 10/10 [02:32<00:00, 15.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 10:\n",
      "TTFT: 2324.56 ms\n",
      "TPOT: 258.11 ms/token\n",
      "E2E Measured: 15230.21 ms\n",
      "E2E Formula:  15230.12 ms\n",
      "\n",
      "--- Overall Token Latency Stats ---\n",
      "Average TTFT: 2329.82 ms\n",
      "Average TPOT: 258.24 ms\n",
      "P50: 263.01 ms, P95: 265.49 ms, P99: 268.31 ms\n",
      "{'avg_ttft_ms': 2329.8202991485596, 'avg_tpot_ms': 258.24116039276123, 'p50_ms': 263.0103826522827, 'p95_ms': 265.4910445213318, 'p99_ms': 268.31345319747925, 'load_time_s': 6.694820880889893}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_llama_latency(repo_id=\"sharshar20/llama3.2_3B_instruct-GGUF-v6\",filename=\"ft-q5_k_m-lora.gguf\", test_dataset=test_dataset)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a892cc216112468da495d187527ee1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ft-q4_k_m-lora.gguf:   0%|          | 0.00/2.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 28 key-value pairs and 255 tensors from latency/models--sharshar20--llama3.2_3B_instruct-GGUF-v6/snapshots/6404c56ca2726fd54b86b260c71365a86b1bbd95/ft-q4_k_m-lora.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Merged_Model_Instruct_Lora\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 3.2B\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   5:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  14:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  15:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  16:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  17:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  18:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  19:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  21:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  22:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  23:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  24:               tokenizer.ggml.add_sep_token bool             = false\n",
      "llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - kv  26:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  27:                          general.file_type u32              = 15\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type q4_K:  168 tensors\n",
      "llama_model_loader: - type q6_K:   29 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 1.87 GiB (5.01 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
      "load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
      "load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
      "load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
      "load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
      "load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
      "load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
      "load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
      "load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
      "load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
      "load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
      "load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
      "load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
      "load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
      "load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
      "load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
      "load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
      "load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
      "load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
      "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
      "load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
      "load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
      "load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
      "load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "load: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
      "load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
      "load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
      "load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
      "load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
      "load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
      "load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
      "load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
      "load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
      "load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "load: printing all EOG tokens:\n",
      "load:   - 128001 ('<|end_of_text|>')\n",
      "load:   - 128008 ('<|eom_id|>')\n",
      "load:   - 128009 ('<|eot_id|>')\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.7999 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 3072\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 24\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 3\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 3.21 B\n",
      "print_info: general.name     = Merged_Model_Instruct_Lora\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128009 '<|eot_id|>'\n",
      "print_info: EOT token        = 128009 '<|eot_id|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q6_K) (and 114 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
      "load_tensors:   CPU_REPACK model buffer size =  1299.38 MiB\n",
      "load_tensors:   CPU_Mapped model buffer size =  1904.85 MiB\n",
      "repack: repack tensor blk.0.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.0.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.0.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.0.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.0.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.1.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.1.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.1.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.1.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.1.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.2.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.2.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.2.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.2.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.2.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.3.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.3.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.3.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.4.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.4.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.5.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.5.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.5.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.5.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.5.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.6.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.6.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.7.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.7.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.7.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.8.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.8.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.8.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.8.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.8.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.9.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.9.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.9.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.10.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.10.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.10.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.11.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.11.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.11.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.11.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.11.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.12.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.12.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.12.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.13.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.13.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.14.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.14.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.14.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.14.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.14.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.15.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.15.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.15.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.16.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.16.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.16.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.17.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.17.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.17.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.17.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.17.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.18.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.18.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.18.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.19.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.19.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.19.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.20.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.20.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.20.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.20.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.20.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.21.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.21.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.21.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.22.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.22.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.23.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.23.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.23.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.23.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.23.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.24.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.24.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.24.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.24.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.24.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.25.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.25.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.25.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.25.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.25.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.26.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.26.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.26.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.26.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.26.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.27.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.27.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.27.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.27.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.27.ffn_up.weight with q4_K_8x8\n",
      ".................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 2048\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 500000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.49 MiB\n",
      "create_memory: n_ctx = 2048 (padded)\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified: layer  16: dev = CPU\n",
      "llama_kv_cache_unified: layer  17: dev = CPU\n",
      "llama_kv_cache_unified: layer  18: dev = CPU\n",
      "llama_kv_cache_unified: layer  19: dev = CPU\n",
      "llama_kv_cache_unified: layer  20: dev = CPU\n",
      "llama_kv_cache_unified: layer  21: dev = CPU\n",
      "llama_kv_cache_unified: layer  22: dev = CPU\n",
      "llama_kv_cache_unified: layer  23: dev = CPU\n",
      "llama_kv_cache_unified: layer  24: dev = CPU\n",
      "llama_kv_cache_unified: layer  25: dev = CPU\n",
      "llama_kv_cache_unified: layer  26: dev = CPU\n",
      "llama_kv_cache_unified: layer  27: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =   224.00 MiB\n",
      "llama_kv_cache_unified: size =  224.00 MiB (  2048 cells,  28 layers,  1/1 seqs), K (f16):  112.00 MiB, V (f16):  112.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 1\n",
      "llama_context: max_nodes = 2040\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "llama_context:        CPU compute buffer size =   256.50 MiB\n",
      "llama_context: graph nodes  = 986\n",
      "llama_context: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | AVX512_VNNI = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
      "Model metadata: {'general.file_type': '15', 'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- if strftime_now is defined %}\\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\\n    {%- else %}\\n        {%- set date_string = \"26 Jul 2024\" %}\\n    {%- endif %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n        {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n        {{- \\'\"parameters\": \\' }}\\n        {{- tool_call.arguments | tojson }}\\n        {{- \"}\" }}\\n        {{- \"<|eot_id|>\" }}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_Instruct_Lora', 'general.type': 'model', 'general.size_label': '3.2B', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.add_sep_token': 'false', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- if strftime_now is defined %}\n",
      "        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n",
      "    {%- else %}\n",
      "        {%- set date_string = \"26 Jul 2024\" %}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "        {{- '\"parameters\": ' }}\n",
      "        {{- tool_call.arguments | tojson }}\n",
      "        {{- \"}\" }}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n",
      "Evaluating prompts:   0%|          | 0/10 [00:00<?, ?it/s]llama_perf_context_print:        load time =    1457.88 ms\n",
      "llama_perf_context_print: prompt eval time =    1457.76 ms /    12 tokens (  121.48 ms per token,     8.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10887.55 ms /    49 runs   (  222.19 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:       total time =   12395.97 ms /    61 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  10%|█         | 1/10 [00:12<01:51, 12.40s/it]Llama.generate: 2 prefix-match hit, remaining 10 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1:\n",
      "TTFT: 1459.11 ms\n",
      "TPOT: 218.79 ms/token\n",
      "E2E Measured: 12398.80 ms\n",
      "E2E Formula:  12398.70 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1457.88 ms\n",
      "llama_perf_context_print: prompt eval time =    1477.55 ms /    10 tokens (  147.76 ms per token,     6.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10892.32 ms /    49 runs   (  222.29 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:       total time =   12420.75 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  20%|██        | 2/10 [00:24<01:39, 12.41s/it]Llama.generate: 2 prefix-match hit, remaining 10 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 2:\n",
      "TTFT: 1478.95 ms\n",
      "TPOT: 218.88 ms/token\n",
      "E2E Measured: 12423.22 ms\n",
      "E2E Formula:  12423.12 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1457.88 ms\n",
      "llama_perf_context_print: prompt eval time =    1417.93 ms /    10 tokens (  141.79 ms per token,     7.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10893.18 ms /    49 runs   (  222.31 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:       total time =   12361.93 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  30%|███       | 3/10 [00:37<01:26, 12.39s/it]Llama.generate: 2 prefix-match hit, remaining 9 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 3:\n",
      "TTFT: 1419.31 ms\n",
      "TPOT: 218.90 ms/token\n",
      "E2E Measured: 12364.48 ms\n",
      "E2E Formula:  12364.38 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1457.88 ms\n",
      "llama_perf_context_print: prompt eval time =    1310.39 ms /     9 tokens (  145.60 ms per token,     6.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10894.76 ms /    49 runs   (  222.34 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:       total time =   12255.79 ms /    58 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  40%|████      | 4/10 [00:49<01:14, 12.34s/it]Llama.generate: 2 prefix-match hit, remaining 13 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 4:\n",
      "TTFT: 1311.79 ms\n",
      "TPOT: 218.93 ms/token\n",
      "E2E Measured: 12258.26 ms\n",
      "E2E Formula:  12258.17 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1457.88 ms\n",
      "llama_perf_context_print: prompt eval time =    1564.79 ms /    13 tokens (  120.37 ms per token,     8.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10891.31 ms /    49 runs   (  222.27 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:       total time =   12507.07 ms /    62 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  50%|█████     | 5/10 [01:01<01:02, 12.40s/it]Llama.generate: 1 prefix-match hit, remaining 14 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 5:\n",
      "TTFT: 1566.25 ms\n",
      "TPOT: 218.87 ms/token\n",
      "E2E Measured: 12509.69 ms\n",
      "E2E Formula:  12509.59 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1457.88 ms\n",
      "llama_perf_context_print: prompt eval time =    1671.20 ms /    14 tokens (  119.37 ms per token,     8.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10872.06 ms /    49 runs   (  221.88 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:       total time =   12594.11 ms /    63 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  60%|██████    | 6/10 [01:14<00:49, 12.47s/it]Llama.generate: 1 prefix-match hit, remaining 13 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 6:\n",
      "TTFT: 1672.61 ms\n",
      "TPOT: 218.48 ms/token\n",
      "E2E Measured: 12596.96 ms\n",
      "E2E Formula:  12596.86 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1457.88 ms\n",
      "llama_perf_context_print: prompt eval time =    1557.50 ms /    13 tokens (  119.81 ms per token,     8.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10874.26 ms /    49 runs   (  221.92 ms per token,     4.51 tokens per second)\n",
      "llama_perf_context_print:       total time =   12482.54 ms /    62 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  70%|███████   | 7/10 [01:27<00:37, 12.47s/it]Llama.generate: 1 prefix-match hit, remaining 8 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 7:\n",
      "TTFT: 1558.94 ms\n",
      "TPOT: 218.53 ms/token\n",
      "E2E Measured: 12485.36 ms\n",
      "E2E Formula:  12485.26 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1457.88 ms\n",
      "llama_perf_context_print: prompt eval time =    1195.91 ms /     8 tokens (  149.49 ms per token,     6.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10887.20 ms /    49 runs   (  222.19 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:       total time =   12133.76 ms /    57 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  80%|████████  | 8/10 [01:39<00:24, 12.37s/it]Llama.generate: 2 prefix-match hit, remaining 10 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 8:\n",
      "TTFT: 1197.32 ms\n",
      "TPOT: 218.78 ms/token\n",
      "E2E Measured: 12136.53 ms\n",
      "E2E Formula:  12136.43 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1457.88 ms\n",
      "llama_perf_context_print: prompt eval time =    1414.89 ms /    10 tokens (  141.49 ms per token,     7.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10887.29 ms /    49 runs   (  222.19 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:       total time =   12352.96 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  90%|█████████ | 9/10 [01:51<00:12, 12.36s/it]Llama.generate: 2 prefix-match hit, remaining 11 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 9:\n",
      "TTFT: 1416.28 ms\n",
      "TPOT: 218.78 ms/token\n",
      "E2E Measured: 12355.47 ms\n",
      "E2E Formula:  12355.38 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1457.88 ms\n",
      "llama_perf_context_print: prompt eval time =    1520.83 ms /    11 tokens (  138.26 ms per token,     7.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10920.58 ms /    49 runs   (  222.87 ms per token,     4.49 tokens per second)\n",
      "llama_perf_context_print:       total time =   12492.20 ms /    60 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts: 100%|██████████| 10/10 [02:04<00:00, 12.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 10:\n",
      "TTFT: 1522.22 ms\n",
      "TPOT: 219.45 ms/token\n",
      "E2E Measured: 12494.93 ms\n",
      "E2E Formula:  12494.83 ms\n",
      "\n",
      "--- Overall Token Latency Stats ---\n",
      "Average TTFT: 1460.28 ms\n",
      "Average TPOT: 218.84 ms\n",
      "P50: 222.99 ms, P95: 225.53 ms, P99: 226.51 ms\n",
      "{'avg_ttft_ms': 1460.2785348892212, 'avg_tpot_ms': 218.83984422683716, 'p50_ms': 222.98824787139893, 'p95_ms': 225.52956342697144, 'p99_ms': 226.5090847015381, 'load_time_s': 5.153078317642212}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_llama_latency(repo_id=\"sharshar20/llama3.2_3B_instruct-GGUF-v6\",filename=\"ft-q4_k_m-lora.gguf\", test_dataset=test_dataset)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2501535032946eba4b41e8ba48bfabd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ft-q8_0-lora.gguf:   0%|          | 0.00/3.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 28 key-value pairs and 255 tensors from latency/models--sharshar20--llama3.2_3B_instruct-GGUF-v6/snapshots/6404c56ca2726fd54b86b260c71365a86b1bbd95/ft-q8_0-lora.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Merged_Model_Instruct_Lora\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 3.2B\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   5:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  14:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  15:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  16:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  17:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  18:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  19:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  21:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  22:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  23:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  24:               tokenizer.ggml.add_sep_token bool             = false\n",
      "llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - kv  26:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  27:                          general.file_type u32              = 7\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type q8_0:  197 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q8_0\n",
      "print_info: file size   = 3.18 GiB (8.50 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
      "load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
      "load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
      "load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
      "load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
      "load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
      "load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
      "load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
      "load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
      "load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
      "load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
      "load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
      "load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
      "load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
      "load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
      "load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
      "load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
      "load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
      "load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
      "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
      "load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
      "load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
      "load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
      "load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "load: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
      "load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
      "load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
      "load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
      "load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
      "load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
      "load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
      "load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
      "load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
      "load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "load: printing all EOG tokens:\n",
      "load:   - 128001 ('<|end_of_text|>')\n",
      "load:   - 128008 ('<|eom_id|>')\n",
      "load:   - 128009 ('<|eot_id|>')\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.7999 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 3072\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 24\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 3\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 3.21 B\n",
      "print_info: general.name     = Merged_Model_Instruct_Lora\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128009 '<|eot_id|>'\n",
      "print_info: EOT token        = 128009 '<|eot_id|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q8_0) (and 282 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
      "load_tensors:   CPU_Mapped model buffer size =  3255.90 MiB\n",
      ".........................................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 2048\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 500000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.49 MiB\n",
      "create_memory: n_ctx = 2048 (padded)\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified: layer  16: dev = CPU\n",
      "llama_kv_cache_unified: layer  17: dev = CPU\n",
      "llama_kv_cache_unified: layer  18: dev = CPU\n",
      "llama_kv_cache_unified: layer  19: dev = CPU\n",
      "llama_kv_cache_unified: layer  20: dev = CPU\n",
      "llama_kv_cache_unified: layer  21: dev = CPU\n",
      "llama_kv_cache_unified: layer  22: dev = CPU\n",
      "llama_kv_cache_unified: layer  23: dev = CPU\n",
      "llama_kv_cache_unified: layer  24: dev = CPU\n",
      "llama_kv_cache_unified: layer  25: dev = CPU\n",
      "llama_kv_cache_unified: layer  26: dev = CPU\n",
      "llama_kv_cache_unified: layer  27: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =   224.00 MiB\n",
      "llama_kv_cache_unified: size =  224.00 MiB (  2048 cells,  28 layers,  1/1 seqs), K (f16):  112.00 MiB, V (f16):  112.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 1\n",
      "llama_context: max_nodes = 2040\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "llama_context:        CPU compute buffer size =   256.50 MiB\n",
      "llama_context: graph nodes  = 986\n",
      "llama_context: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | AVX512_VNNI = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
      "Model metadata: {'general.file_type': '7', 'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- if strftime_now is defined %}\\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\\n    {%- else %}\\n        {%- set date_string = \"26 Jul 2024\" %}\\n    {%- endif %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n        {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n        {{- \\'\"parameters\": \\' }}\\n        {{- tool_call.arguments | tojson }}\\n        {{- \"}\" }}\\n        {{- \"<|eot_id|>\" }}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_Instruct_Lora', 'general.type': 'model', 'general.size_label': '3.2B', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.add_sep_token': 'false', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- if strftime_now is defined %}\n",
      "        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n",
      "    {%- else %}\n",
      "        {%- set date_string = \"26 Jul 2024\" %}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "        {{- '\"parameters\": ' }}\n",
      "        {{- tool_call.arguments | tojson }}\n",
      "        {{- \"}\" }}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n",
      "Evaluating prompts:   0%|          | 0/10 [00:00<?, ?it/s]llama_perf_context_print:        load time =    1567.26 ms\n",
      "llama_perf_context_print: prompt eval time =    1567.13 ms /    12 tokens (  130.59 ms per token,     7.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15238.82 ms /    49 runs   (  311.00 ms per token,     3.22 tokens per second)\n",
      "llama_perf_context_print:       total time =   16857.08 ms /    61 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  10%|█         | 1/10 [00:16<02:31, 16.86s/it]Llama.generate: 2 prefix-match hit, remaining 10 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1:\n",
      "TTFT: 1568.57 ms\n",
      "TPOT: 305.82 ms/token\n",
      "E2E Measured: 16859.73 ms\n",
      "E2E Formula:  16859.63 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1567.26 ms\n",
      "llama_perf_context_print: prompt eval time =    1462.24 ms /    10 tokens (  146.22 ms per token,     6.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15226.22 ms /    49 runs   (  310.74 ms per token,     3.22 tokens per second)\n",
      "llama_perf_context_print:       total time =   16739.83 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  20%|██        | 2/10 [00:33<02:14, 16.79s/it]Llama.generate: 2 prefix-match hit, remaining 10 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 2:\n",
      "TTFT: 1463.65 ms\n",
      "TPOT: 305.58 ms/token\n",
      "E2E Measured: 16742.58 ms\n",
      "E2E Formula:  16742.48 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1567.26 ms\n",
      "llama_perf_context_print: prompt eval time =    1465.47 ms /    10 tokens (  146.55 ms per token,     6.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15242.80 ms /    49 runs   (  311.08 ms per token,     3.21 tokens per second)\n",
      "llama_perf_context_print:       total time =   16759.72 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  30%|███       | 3/10 [00:50<01:57, 16.78s/it]Llama.generate: 2 prefix-match hit, remaining 9 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 3:\n",
      "TTFT: 1466.87 ms\n",
      "TPOT: 305.91 ms/token\n",
      "E2E Measured: 16762.23 ms\n",
      "E2E Formula:  16762.14 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1567.26 ms\n",
      "llama_perf_context_print: prompt eval time =    1411.30 ms /     9 tokens (  156.81 ms per token,     6.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15297.95 ms /    49 runs   (  312.20 ms per token,     3.20 tokens per second)\n",
      "llama_perf_context_print:       total time =   16761.09 ms /    58 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  40%|████      | 4/10 [01:07<01:40, 16.77s/it]Llama.generate: 2 prefix-match hit, remaining 13 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 4:\n",
      "TTFT: 1412.70 ms\n",
      "TPOT: 307.04 ms/token\n",
      "E2E Measured: 16764.62 ms\n",
      "E2E Formula:  16764.52 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1567.26 ms\n",
      "llama_perf_context_print: prompt eval time =    1704.77 ms /    13 tokens (  131.14 ms per token,     7.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15234.59 ms /    49 runs   (  310.91 ms per token,     3.22 tokens per second)\n",
      "llama_perf_context_print:       total time =   16990.81 ms /    62 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  50%|█████     | 5/10 [01:24<01:24, 16.85s/it]Llama.generate: 1 prefix-match hit, remaining 14 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 5:\n",
      "TTFT: 1706.18 ms\n",
      "TPOT: 305.75 ms/token\n",
      "E2E Measured: 16993.76 ms\n",
      "E2E Formula:  16993.66 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1567.26 ms\n",
      "llama_perf_context_print: prompt eval time =    1752.79 ms /    14 tokens (  125.20 ms per token,     7.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15239.13 ms /    49 runs   (  311.00 ms per token,     3.22 tokens per second)\n",
      "llama_perf_context_print:       total time =   17043.44 ms /    63 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  60%|██████    | 6/10 [01:41<01:07, 16.92s/it]Llama.generate: 1 prefix-match hit, remaining 13 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 6:\n",
      "TTFT: 1754.18 ms\n",
      "TPOT: 305.84 ms/token\n",
      "E2E Measured: 17046.40 ms\n",
      "E2E Formula:  17046.29 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1567.26 ms\n",
      "llama_perf_context_print: prompt eval time =    1715.67 ms /    13 tokens (  131.97 ms per token,     7.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15224.07 ms /    49 runs   (  310.70 ms per token,     3.22 tokens per second)\n",
      "llama_perf_context_print:       total time =   16991.09 ms /    62 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  70%|███████   | 7/10 [01:58<00:50, 16.94s/it]Llama.generate: 1 prefix-match hit, remaining 8 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 7:\n",
      "TTFT: 1717.12 ms\n",
      "TPOT: 305.53 ms/token\n",
      "E2E Measured: 16993.59 ms\n",
      "E2E Formula:  16993.49 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1567.26 ms\n",
      "llama_perf_context_print: prompt eval time =    1280.00 ms /     8 tokens (  160.00 ms per token,     6.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15237.88 ms /    49 runs   (  310.98 ms per token,     3.22 tokens per second)\n",
      "llama_perf_context_print:       total time =   16569.24 ms /    57 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  80%|████████  | 8/10 [02:14<00:33, 16.83s/it]Llama.generate: 2 prefix-match hit, remaining 10 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 8:\n",
      "TTFT: 1281.39 ms\n",
      "TPOT: 305.81 ms/token\n",
      "E2E Measured: 16571.78 ms\n",
      "E2E Formula:  16571.68 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1567.26 ms\n",
      "llama_perf_context_print: prompt eval time =    1460.13 ms /    10 tokens (  146.01 ms per token,     6.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15236.18 ms /    49 runs   (  310.94 ms per token,     3.22 tokens per second)\n",
      "llama_perf_context_print:       total time =   16747.63 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  90%|█████████ | 9/10 [02:31<00:16, 16.80s/it]Llama.generate: 2 prefix-match hit, remaining 11 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 9:\n",
      "TTFT: 1461.55 ms\n",
      "TPOT: 305.78 ms/token\n",
      "E2E Measured: 16750.45 ms\n",
      "E2E Formula:  16750.34 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1567.26 ms\n",
      "llama_perf_context_print: prompt eval time =    1515.58 ms /    11 tokens (  137.78 ms per token,     7.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15237.10 ms /    49 runs   (  310.96 ms per token,     3.22 tokens per second)\n",
      "llama_perf_context_print:       total time =   16804.10 ms /    60 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts: 100%|██████████| 10/10 [02:48<00:00, 16.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 10:\n",
      "TTFT: 1516.97 ms\n",
      "TPOT: 305.79 ms/token\n",
      "E2E Measured: 16806.60 ms\n",
      "E2E Formula:  16806.49 ms\n",
      "\n",
      "--- Overall Token Latency Stats ---\n",
      "Average TTFT: 1534.92 ms\n",
      "Average TPOT: 305.88 ms\n",
      "P50: 311.65 ms, P95: 314.01 ms, P99: 315.34 ms\n",
      "{'avg_ttft_ms': 1534.9178075790405, 'avg_tpot_ms': 305.88307428359985, 'p50_ms': 311.651349067688, 'p95_ms': 314.00651931762695, 'p99_ms': 315.3407287597656, 'load_time_s': 11.904460668563843}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_llama_latency(repo_id=\"sharshar20/llama3.2_3B_instruct-GGUF-v6\",filename=\"ft-q8_0-lora.gguf\", test_dataset=test_dataset)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c5985c7b6e42e1b02075157e1ed74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fp16-ft-lora.gguf:   0%|          | 0.00/6.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 28 key-value pairs and 255 tensors from latency/models--sharshar20--llama3.2_3B_instruct-GGUF-v6/snapshots/6404c56ca2726fd54b86b260c71365a86b1bbd95/fp16-ft-lora.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Merged_Model_Instruct_Lora\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 3.2B\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   5:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  14:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  17:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  25:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  26:               tokenizer.ggml.add_sep_token bool             = false\n",
      "llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type  f16:  197 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = F16\n",
      "print_info: file size   = 5.98 GiB (16.00 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
      "load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
      "load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
      "load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
      "load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
      "load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
      "load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
      "load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
      "load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
      "load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
      "load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
      "load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
      "load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
      "load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
      "load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
      "load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
      "load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
      "load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
      "load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
      "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
      "load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
      "load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
      "load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
      "load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "load: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
      "load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
      "load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
      "load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
      "load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
      "load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
      "load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
      "load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
      "load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
      "load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "load: printing all EOG tokens:\n",
      "load:   - 128001 ('<|end_of_text|>')\n",
      "load:   - 128008 ('<|eom_id|>')\n",
      "load:   - 128009 ('<|eot_id|>')\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.7999 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 3072\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 24\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 3\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 3.21 B\n",
      "print_info: general.name     = Merged_Model_Instruct_Lora\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128009 '<|eot_id|>'\n",
      "print_info: EOT token        = 128009 '<|eot_id|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (f16) (and 282 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
      "load_tensors:   CPU_Mapped model buffer size =  6128.17 MiB\n",
      ".........................................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 2048\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 500000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.49 MiB\n",
      "create_memory: n_ctx = 2048 (padded)\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified: layer  16: dev = CPU\n",
      "llama_kv_cache_unified: layer  17: dev = CPU\n",
      "llama_kv_cache_unified: layer  18: dev = CPU\n",
      "llama_kv_cache_unified: layer  19: dev = CPU\n",
      "llama_kv_cache_unified: layer  20: dev = CPU\n",
      "llama_kv_cache_unified: layer  21: dev = CPU\n",
      "llama_kv_cache_unified: layer  22: dev = CPU\n",
      "llama_kv_cache_unified: layer  23: dev = CPU\n",
      "llama_kv_cache_unified: layer  24: dev = CPU\n",
      "llama_kv_cache_unified: layer  25: dev = CPU\n",
      "llama_kv_cache_unified: layer  26: dev = CPU\n",
      "llama_kv_cache_unified: layer  27: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =   224.00 MiB\n",
      "llama_kv_cache_unified: size =  224.00 MiB (  2048 cells,  28 layers,  1/1 seqs), K (f16):  112.00 MiB, V (f16):  112.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 1\n",
      "llama_context: max_nodes = 2040\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "llama_context:        CPU compute buffer size =   256.50 MiB\n",
      "llama_context: graph nodes  = 986\n",
      "llama_context: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | AVX512_VNNI = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- if strftime_now is defined %}\\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\\n    {%- else %}\\n        {%- set date_string = \"26 Jul 2024\" %}\\n    {%- endif %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n        {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n        {{- \\'\"parameters\": \\' }}\\n        {{- tool_call.arguments | tojson }}\\n        {{- \"}\" }}\\n        {{- \"<|eot_id|>\" }}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.eos_token_id': '128009', 'tokenizer.ggml.model': 'gpt2', 'general.quantization_version': '2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '1', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_Instruct_Lora', 'general.type': 'model', 'general.size_label': '3.2B', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.add_sep_token': 'false', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- if strftime_now is defined %}\n",
      "        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n",
      "    {%- else %}\n",
      "        {%- set date_string = \"26 Jul 2024\" %}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "        {{- '\"parameters\": ' }}\n",
      "        {{- tool_call.arguments | tojson }}\n",
      "        {{- \"}\" }}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n",
      "Evaluating prompts:   0%|          | 0/10 [00:00<?, ?it/s]llama_perf_context_print:        load time =    1673.15 ms\n",
      "llama_perf_context_print: prompt eval time =    1673.03 ms /    12 tokens (  139.42 ms per token,     7.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24667.85 ms /    49 runs   (  503.43 ms per token,     1.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   26392.37 ms /    61 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  10%|█         | 1/10 [00:26<03:57, 26.40s/it]Llama.generate: 2 prefix-match hit, remaining 10 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1:\n",
      "TTFT: 1674.35 ms\n",
      "TPOT: 494.41 ms/token\n",
      "E2E Measured: 26395.14 ms\n",
      "E2E Formula:  26395.04 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1673.15 ms\n",
      "llama_perf_context_print: prompt eval time =    1541.42 ms /    10 tokens (  154.14 ms per token,     6.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24662.82 ms /    49 runs   (  503.32 ms per token,     1.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   26255.83 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  20%|██        | 2/10 [00:52<03:30, 26.32s/it]Llama.generate: 2 prefix-match hit, remaining 10 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 2:\n",
      "TTFT: 1542.81 ms\n",
      "TPOT: 494.32 ms/token\n",
      "E2E Measured: 26258.69 ms\n",
      "E2E Formula:  26258.59 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1673.15 ms\n",
      "llama_perf_context_print: prompt eval time =    1543.74 ms /    10 tokens (  154.37 ms per token,     6.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24656.61 ms /    49 runs   (  503.20 ms per token,     1.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   26251.92 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  30%|███       | 3/10 [01:18<03:04, 26.29s/it]Llama.generate: 2 prefix-match hit, remaining 9 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 3:\n",
      "TTFT: 1545.12 ms\n",
      "TPOT: 494.18 ms/token\n",
      "E2E Measured: 26254.47 ms\n",
      "E2E Formula:  26254.37 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1673.15 ms\n",
      "llama_perf_context_print: prompt eval time =    1472.87 ms /     9 tokens (  163.65 ms per token,     6.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24659.41 ms /    49 runs   (  503.25 ms per token,     1.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   26183.80 ms /    58 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  40%|████      | 4/10 [01:45<02:37, 26.25s/it]Llama.generate: 2 prefix-match hit, remaining 13 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 4:\n",
      "TTFT: 1474.30 ms\n",
      "TPOT: 494.26 ms/token\n",
      "E2E Measured: 26187.32 ms\n",
      "E2E Formula:  26187.22 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1673.15 ms\n",
      "llama_perf_context_print: prompt eval time =    1744.95 ms /    13 tokens (  134.23 ms per token,     7.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24706.07 ms /    49 runs   (  504.21 ms per token,     1.98 tokens per second)\n",
      "llama_perf_context_print:       total time =   26502.93 ms /    62 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  50%|█████     | 5/10 [02:11<02:11, 26.34s/it]Llama.generate: 1 prefix-match hit, remaining 14 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 5:\n",
      "TTFT: 1746.35 ms\n",
      "TPOT: 495.18 ms/token\n",
      "E2E Measured: 26505.39 ms\n",
      "E2E Formula:  26505.30 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1673.15 ms\n",
      "llama_perf_context_print: prompt eval time =    1817.30 ms /    14 tokens (  129.81 ms per token,     7.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24651.58 ms /    49 runs   (  503.09 ms per token,     1.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   26520.66 ms /    63 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  60%|██████    | 6/10 [02:38<01:45, 26.40s/it]Llama.generate: 1 prefix-match hit, remaining 13 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 6:\n",
      "TTFT: 1818.71 ms\n",
      "TPOT: 494.10 ms/token\n",
      "E2E Measured: 26523.56 ms\n",
      "E2E Formula:  26523.47 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1673.15 ms\n",
      "llama_perf_context_print: prompt eval time =    1769.42 ms /    13 tokens (  136.11 ms per token,     7.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24652.01 ms /    49 runs   (  503.10 ms per token,     1.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   26473.05 ms /    62 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  70%|███████   | 7/10 [03:04<01:19, 26.43s/it]Llama.generate: 1 prefix-match hit, remaining 8 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 7:\n",
      "TTFT: 1770.84 ms\n",
      "TPOT: 494.09 ms/token\n",
      "E2E Measured: 26475.57 ms\n",
      "E2E Formula:  26475.47 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1673.15 ms\n",
      "llama_perf_context_print: prompt eval time =    1422.37 ms /     8 tokens (  177.80 ms per token,     5.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24664.41 ms /    49 runs   (  503.36 ms per token,     1.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   26138.27 ms /    57 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  80%|████████  | 8/10 [03:30<00:52, 26.34s/it]Llama.generate: 2 prefix-match hit, remaining 10 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 8:\n",
      "TTFT: 1423.76 ms\n",
      "TPOT: 494.34 ms/token\n",
      "E2E Measured: 26140.75 ms\n",
      "E2E Formula:  26140.66 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1673.15 ms\n",
      "llama_perf_context_print: prompt eval time =    1544.18 ms /    10 tokens (  154.42 ms per token,     6.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24658.72 ms /    49 runs   (  503.24 ms per token,     1.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   26254.40 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts:  90%|█████████ | 9/10 [03:57<00:26, 26.31s/it]Llama.generate: 2 prefix-match hit, remaining 11 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 9:\n",
      "TTFT: 1545.57 ms\n",
      "TPOT: 494.23 ms/token\n",
      "E2E Measured: 26257.18 ms\n",
      "E2E Formula:  26257.09 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1673.15 ms\n",
      "llama_perf_context_print: prompt eval time =    1595.25 ms /    11 tokens (  145.02 ms per token,     6.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24707.59 ms /    49 runs   (  504.24 ms per token,     1.98 tokens per second)\n",
      "llama_perf_context_print:       total time =   26354.64 ms /    60 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Evaluating prompts: 100%|██████████| 10/10 [04:23<00:00, 26.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 10:\n",
      "TTFT: 1596.66 ms\n",
      "TPOT: 495.21 ms/token\n",
      "E2E Measured: 26357.14 ms\n",
      "E2E Formula:  26357.05 ms\n",
      "\n",
      "--- Overall Token Latency Stats ---\n",
      "Average TTFT: 1613.85 ms\n",
      "Average TPOT: 494.43 ms\n",
      "P50: 503.80 ms, P95: 506.05 ms, P99: 507.77 ms\n",
      "{'avg_ttft_ms': 1613.8480424880981, 'avg_tpot_ms': 494.43152046203613, 'p50_ms': 503.7965774536133, 'p95_ms': 506.05132579803467, 'p99_ms': 507.76520252227783, 'load_time_s': 16.707031726837158}\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_llama_latency(repo_id=\"sharshar20/llama3.2_3B_instruct-GGUF-v6\",filename=\"fp16-ft-lora.gguf\", test_dataset=test_dataset)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6LPPl86hm72p",
    "outputId": "53404a76-4cc2-4e77-e620-b45d405171b0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 28 key-value pairs and 255 tensors from quantized_models/ft-q4_k_m.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Merged_Model_Instruct_Lora\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 3.2B\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   5:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  14:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  15:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  16:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  17:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  18:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  19:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  21:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  22:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  23:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  24:               tokenizer.ggml.add_sep_token bool             = false\n",
      "llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - kv  26:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  27:                          general.file_type u32              = 15\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type q4_K:  168 tensors\n",
      "llama_model_loader: - type q6_K:   29 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 1.87 GiB (5.01 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
      "load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
      "load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
      "load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
      "load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
      "load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
      "load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
      "load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
      "load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
      "load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
      "load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
      "load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
      "load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
      "load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
      "load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
      "load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
      "load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
      "load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
      "load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
      "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
      "load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
      "load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
      "load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
      "load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "load: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
      "load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
      "load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
      "load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
      "load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
      "load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
      "load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
      "load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
      "load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
      "load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "load: printing all EOG tokens:\n",
      "load:   - 128001 ('<|end_of_text|>')\n",
      "load:   - 128008 ('<|eom_id|>')\n",
      "load:   - 128009 ('<|eot_id|>')\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.7999 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 3072\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 24\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 3\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 3.21 B\n",
      "print_info: general.name     = Merged_Model_Instruct_Lora\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128009 '<|eot_id|>'\n",
      "print_info: EOT token        = 128009 '<|eot_id|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q6_K) (and 114 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
      "load_tensors:   CPU_REPACK model buffer size =  1299.38 MiB\n",
      "load_tensors:   CPU_Mapped model buffer size =  1904.85 MiB\n",
      "repack: repack tensor blk.0.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.0.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.0.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.0.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.0.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.1.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.1.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.1.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.1.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.1.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.2.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.2.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.2.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.2.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.2.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.3.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.3.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.3.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.4.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.4.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.5.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.5.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.5.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.5.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.5.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.6.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.6.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.7.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.7.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.7.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.8.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.8.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.8.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.8.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.8.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.9.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.9.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.9.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.10.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.10.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.10.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.11.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.11.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.11.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.11.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.11.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.12.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.12.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.12.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.13.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.13.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.14.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.14.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.14.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.14.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.14.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.15.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.15.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.15.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.16.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.16.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.16.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.17.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.17.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.17.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.17.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.17.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.18.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.18.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.18.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.19.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.19.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.19.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.20.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.20.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.20.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.20.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.20.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.21.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.21.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.21.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.22.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.22.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.23.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.23.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.23.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.23.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.23.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.24.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.24.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.24.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.24.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.24.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.25.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.25.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.25.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.25.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.25.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.26.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.26.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.26.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.26.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.26.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.27.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.27.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.27.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.27.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.27.ffn_up.weight with q4_K_8x8\n",
      ".................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 2048\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 500000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.49 MiB\n",
      "create_memory: n_ctx = 2048 (padded)\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified: layer  16: dev = CPU\n",
      "llama_kv_cache_unified: layer  17: dev = CPU\n",
      "llama_kv_cache_unified: layer  18: dev = CPU\n",
      "llama_kv_cache_unified: layer  19: dev = CPU\n",
      "llama_kv_cache_unified: layer  20: dev = CPU\n",
      "llama_kv_cache_unified: layer  21: dev = CPU\n",
      "llama_kv_cache_unified: layer  22: dev = CPU\n",
      "llama_kv_cache_unified: layer  23: dev = CPU\n",
      "llama_kv_cache_unified: layer  24: dev = CPU\n",
      "llama_kv_cache_unified: layer  25: dev = CPU\n",
      "llama_kv_cache_unified: layer  26: dev = CPU\n",
      "llama_kv_cache_unified: layer  27: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =   224.00 MiB\n",
      "llama_kv_cache_unified: size =  224.00 MiB (  2048 cells,  28 layers,  1/1 seqs), K (f16):  112.00 MiB, V (f16):  112.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 1\n",
      "llama_context: max_nodes = 2040\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "llama_context:        CPU compute buffer size =   256.50 MiB\n",
      "llama_context: graph nodes  = 986\n",
      "llama_context: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | AVX512_VNNI = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
      "Model metadata: {'general.file_type': '15', 'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- if strftime_now is defined %}\\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\\n    {%- else %}\\n        {%- set date_string = \"26 Jul 2024\" %}\\n    {%- endif %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n        {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n        {{- \\'\"parameters\": \\' }}\\n        {{- tool_call.arguments | tojson }}\\n        {{- \"}\" }}\\n        {{- \"<|eot_id|>\" }}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_Instruct_Lora', 'general.type': 'model', 'general.size_label': '3.2B', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.add_sep_token': 'false', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- if strftime_now is defined %}\n",
      "        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n",
      "    {%- else %}\n",
      "        {%- set date_string = \"26 Jul 2024\" %}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "        {{- '\"parameters\": ' }}\n",
      "        {{- tool_call.arguments | tojson }}\n",
      "        {{- \"}\" }}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1516.92 ms /    11 tokens (  137.90 ms per token,     7.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =     881.09 ms /     4 runs   (  220.27 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    2403.35 ms /    15 tokens\n",
      "llama_perf_context_print:    graphs reused =          3\n",
      "Llama.generate: 10 prefix-match hit, remaining 1 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =   10982.60 ms /    50 runs   (  219.65 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:       total time =   11034.67 ms /    51 tokens\n",
      "llama_perf_context_print:    graphs reused =         49\n",
      "Llama.generate: 7 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1153.14 ms /     6 tokens (  192.19 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10742.33 ms /    49 runs   (  219.23 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11947.35 ms /    55 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1411.17 ms /    10 tokens (  141.12 ms per token,     7.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10736.24 ms /    49 runs   (  219.11 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   12198.68 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 3 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1015.31 ms /     3 tokens (  338.44 ms per token,     2.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10777.67 ms /    49 runs   (  219.95 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:       total time =   11844.11 ms /    52 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =     948.40 ms /     4 tokens (  237.10 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10747.28 ms /    49 runs   (  219.33 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11746.97 ms /    53 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1603.88 ms /    17 tokens (   94.35 ms per token,    10.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10801.01 ms /    49 runs   (  220.43 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:       total time =   12456.39 ms /    66 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1312.78 ms /     9 tokens (  145.86 ms per token,     6.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10722.37 ms /    49 runs   (  218.82 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   12086.52 ms /    58 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 3 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1016.28 ms /     3 tokens (  338.76 ms per token,     2.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10744.38 ms /    49 runs   (  219.27 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11812.06 ms /    52 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1207.29 ms /     8 tokens (  150.91 ms per token,     6.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10737.68 ms /    49 runs   (  219.14 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11996.53 ms /    57 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 9 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1664.02 ms /    14 tokens (  118.86 ms per token,     8.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10735.65 ms /    49 runs   (  219.09 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   12451.02 ms /    63 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1205.70 ms /     8 tokens (  150.71 ms per token,     6.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10717.06 ms /    49 runs   (  218.72 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11973.91 ms /    57 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1412.22 ms /    10 tokens (  141.22 ms per token,     7.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10728.24 ms /    49 runs   (  218.94 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   12191.87 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1051.58 ms /     5 tokens (  210.32 ms per token,     4.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10727.61 ms /    49 runs   (  218.93 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11830.23 ms /    54 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1155.03 ms /     6 tokens (  192.51 ms per token,     5.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10725.43 ms /    49 runs   (  218.89 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11931.58 ms /    55 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1513.85 ms /    11 tokens (  137.62 ms per token,     7.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10719.25 ms /    49 runs   (  218.76 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   12284.95 ms /    60 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1407.42 ms /    10 tokens (  140.74 ms per token,     7.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10809.59 ms /    49 runs   (  220.60 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:       total time =   12268.62 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1514.60 ms /    11 tokens (  137.69 ms per token,     7.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10748.51 ms /    49 runs   (  219.36 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   12314.55 ms /    60 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 2 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =     906.25 ms /     2 tokens (  453.13 ms per token,     2.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10735.74 ms /    49 runs   (  219.10 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11693.10 ms /    51 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 3 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1019.56 ms /     3 tokens (  339.85 ms per token,     2.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10743.38 ms /    49 runs   (  219.25 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11814.49 ms /    52 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1205.95 ms /     8 tokens (  150.74 ms per token,     6.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10720.80 ms /    49 runs   (  218.79 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11978.32 ms /    57 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =     945.50 ms /     4 tokens (  236.37 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10734.09 ms /    49 runs   (  219.06 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11730.84 ms /    53 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 3 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1010.02 ms /     3 tokens (  336.67 ms per token,     2.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10752.90 ms /    49 runs   (  219.45 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11814.50 ms /    52 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 3 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1013.92 ms /     3 tokens (  337.97 ms per token,     2.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10742.83 ms /    49 runs   (  219.24 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11808.38 ms /    52 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1599.57 ms /    17 tokens (   94.09 ms per token,    10.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10765.79 ms /    49 runs   (  219.71 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:       total time =   12416.97 ms /    66 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 3 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1005.29 ms /     3 tokens (  335.10 ms per token,     2.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10751.03 ms /    49 runs   (  219.41 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11807.43 ms /    52 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1467.93 ms /    12 tokens (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10848.72 ms /    49 runs   (  221.40 ms per token,     4.52 tokens per second)\n",
      "llama_perf_context_print:       total time =   12368.44 ms /    61 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =     956.49 ms /     4 tokens (  239.12 ms per token,     4.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10743.12 ms /    49 runs   (  219.25 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11751.24 ms /    53 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =     942.30 ms /     4 tokens (  235.57 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10734.75 ms /    49 runs   (  219.08 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11727.99 ms /    53 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1204.29 ms /     8 tokens (  150.54 ms per token,     6.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10733.85 ms /    49 runs   (  219.06 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11989.51 ms /    57 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =     952.38 ms /     4 tokens (  238.10 ms per token,     4.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10722.66 ms /    49 runs   (  218.83 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11726.40 ms /    53 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =     940.38 ms /     4 tokens (  235.09 ms per token,     4.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10728.45 ms /    49 runs   (  218.95 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11720.05 ms /    53 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1203.48 ms /     8 tokens (  150.43 ms per token,     6.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10731.47 ms /    49 runs   (  219.01 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11986.34 ms /    57 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =     946.34 ms /     4 tokens (  236.59 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10729.86 ms /    49 runs   (  218.98 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11727.29 ms /    53 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =     943.72 ms /     4 tokens (  235.93 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10731.67 ms /    49 runs   (  219.01 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11726.91 ms /    53 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1464.62 ms /    12 tokens (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10749.23 ms /    49 runs   (  219.37 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   12264.94 ms /    61 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 3 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1014.69 ms /     3 tokens (  338.23 ms per token,     2.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10812.22 ms /    49 runs   (  220.66 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:       total time =   11878.83 ms /    52 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =     945.57 ms /     4 tokens (  236.39 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10747.22 ms /    49 runs   (  219.33 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11744.46 ms /    53 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1207.44 ms /     8 tokens (  150.93 ms per token,     6.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10731.99 ms /    49 runs   (  219.02 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11991.11 ms /    57 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1163.09 ms /     6 tokens (  193.85 ms per token,     5.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10745.85 ms /    49 runs   (  219.30 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11960.24 ms /    55 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1415.66 ms /    10 tokens (  141.57 ms per token,     7.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10729.93 ms /    49 runs   (  218.98 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   12197.14 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1424.74 ms /    10 tokens (  142.47 ms per token,     7.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10724.08 ms /    49 runs   (  218.86 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   12200.00 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 3 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1013.07 ms /     3 tokens (  337.69 ms per token,     2.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10730.31 ms /    49 runs   (  218.99 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11794.54 ms /    52 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1773.75 ms /    15 tokens (  118.25 ms per token,     8.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10729.66 ms /    49 runs   (  218.97 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   12554.81 ms /    64 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 9 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1050.71 ms /     5 tokens (  210.14 ms per token,     4.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10717.32 ms /    49 runs   (  218.72 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11819.65 ms /    54 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1485.26 ms /    16 tokens (   92.83 ms per token,    10.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10734.69 ms /    49 runs   (  219.08 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   12271.29 ms /    65 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 3 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1030.12 ms /     3 tokens (  343.37 ms per token,     2.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10804.34 ms /    49 runs   (  220.50 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:       total time =   11887.33 ms /    52 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1311.00 ms /     9 tokens (  145.67 ms per token,     6.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10730.43 ms /    49 runs   (  218.99 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   12093.19 ms /    58 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1411.37 ms /    10 tokens (  141.14 ms per token,     7.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10730.00 ms /    49 runs   (  218.98 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   12192.97 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1046.28 ms /     5 tokens (  209.26 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10747.62 ms /    49 runs   (  219.34 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11845.58 ms /    54 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1517.04 ms\n",
      "llama_perf_context_print: prompt eval time =    1201.91 ms /     8 tokens (  150.24 ms per token,     6.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10724.68 ms /    49 runs   (  218.87 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11978.50 ms /    57 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Time to First Token: 1182.33 ms\n",
      "Average Time per Output Token: 215.95 ms\n",
      "Token Latency - P50: 219.76 ms, P95: 223.84 ms, P99: 232.21 ms\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Load your quantized GGUF model\n",
    "llm = Llama(\n",
    "    model_path=\"quantized_models/ft-q4_k_m.gguf\", # LoRA INT 4 model\n",
    "    n_ctx=2048, # context window in tokens (prompt + generated)\n",
    "    n_threads=8,  # Adjust for CPU threads if CPU inference\n",
    "    n_gpu_layers=-1,  # -1 = all layers on GPU\n",
    "    use_mlock=True #asks OS to lock model in RAM to reduce paging\n",
    ")\n",
    "\n",
    "# Warm-up\n",
    "first_example = test_dataset[0]\n",
    "warmup_prompt = first_example[\"input_text\"]\n",
    "_ = llm(warmup_prompt, max_tokens=5)\n",
    "print(\"Warm-up done.\\n\")\n",
    "\n",
    "# Latency measurement\n",
    "num_runs = 50\n",
    "ttft_list = [] # in ms\n",
    "token_latency_list = [] # in ms\n",
    "\n",
    "for run in range(num_runs):\n",
    "    example = test_dataset[run % len(test_dataset)]  # Loop through val set\n",
    "    full_prompt = example[\"input_text\"]\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    first_token_time = None\n",
    "    prev_time = None\n",
    "    token_times = []\n",
    "\n",
    "    # Stream output tokens\n",
    "    for idx, output in enumerate(\n",
    "        llm(full_prompt, max_tokens=50, stream=True)\n",
    "    ):\n",
    "        now = time.perf_counter()\n",
    "\n",
    "        if idx == 0:\n",
    "            # Time to first token\n",
    "            first_token_time = now - start_time\n",
    "            prev_time = now\n",
    "        else:\n",
    "            # Time per subsequent token\n",
    "            token_times.append(now - prev_time)\n",
    "            prev_time = now\n",
    "\n",
    "    ttft_list.append(first_token_time * 1000)  # ms\n",
    "    token_latency_list.extend([t * 1000 for t in token_times])\n",
    "\n",
    "# Results\n",
    "avg_ttft = np.mean(ttft_list)\n",
    "avg_token_latency = np.mean(token_latency_list)\n",
    "p50_token, p95_token, p99_token = np.percentile(token_latency_list, [50, 95, 99])\n",
    "\n",
    "print(f\"Average Time to First Token: {avg_ttft:.2f} ms\")\n",
    "print(f\"Average Time per Output Token: {avg_token_latency:.2f} ms\")\n",
    "print(f\"Token Latency - P50: {p50_token:.2f} ms, P95: {p95_token:.2f} ms, P99: {p99_token:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 28 key-value pairs and 255 tensors from quantized_models/ft-qlora-q4_k_m.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Merged_Model_Instruct_Qlora\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 3.2B\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv   5:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  14:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  15:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  16:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  17:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  18:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  19:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  21:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  22:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  23:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  24:               tokenizer.ggml.add_sep_token bool             = false\n",
      "llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - kv  26:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  27:                          general.file_type u32              = 15\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type q4_K:  168 tensors\n",
      "llama_model_loader: - type q6_K:   29 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 1.87 GiB (5.01 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
      "load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
      "load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
      "load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
      "load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
      "load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
      "load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
      "load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
      "load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
      "load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
      "load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
      "load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
      "load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
      "load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
      "load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
      "load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
      "load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
      "load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
      "load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
      "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
      "load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
      "load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
      "load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
      "load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "load: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
      "load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
      "load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
      "load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
      "load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
      "load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
      "load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
      "load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
      "load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
      "load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "load: printing all EOG tokens:\n",
      "load:   - 128001 ('<|end_of_text|>')\n",
      "load:   - 128008 ('<|eom_id|>')\n",
      "load:   - 128009 ('<|eot_id|>')\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.7999 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 3072\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 24\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 3\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 8192\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 3B\n",
      "print_info: model params     = 3.21 B\n",
      "print_info: general.name     = Merged_Model_Instruct_Qlora\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128009 '<|eot_id|>'\n",
      "print_info: EOT token        = 128009 '<|eot_id|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q6_K) (and 114 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
      "load_tensors:   CPU_REPACK model buffer size =  1299.38 MiB\n",
      "load_tensors:   CPU_Mapped model buffer size =  1904.85 MiB\n",
      "repack: repack tensor blk.0.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.0.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.0.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.0.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.0.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.1.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.1.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.1.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.1.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.1.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.2.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.2.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.2.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.2.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.2.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.3.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.3.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.3.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.4.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.4.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.5.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.5.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.5.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.5.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.5.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.6.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.6.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.7.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.7.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.7.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.8.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.8.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.8.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.8.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.8.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.9.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.9.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.9.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.10.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.10.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.10.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.11.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.11.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.11.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.11.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.11.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.12.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.12.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.12.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.13.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.13.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.14.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.14.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.14.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.14.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.14.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.15.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.15.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.15.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.16.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.16.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.16.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.17.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.17.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.17.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.17.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.17.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.18.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.18.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.18.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.19.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.19.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.19.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.20.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.20.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.20.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.20.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.20.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.21.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.21.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.21.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.22.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.22.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.23.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.23.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.23.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.23.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.23.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.24.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.24.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.24.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.24.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.24.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.25.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.25.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.25.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.25.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.25.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.26.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.26.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.26.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.26.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.26.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.27.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.27.attn_k.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.27.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.27.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.27.ffn_up.weight with q4_K_8x8\n",
      ".................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 2048\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 500000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.49 MiB\n",
      "create_memory: n_ctx = 2048 (padded)\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified: layer  16: dev = CPU\n",
      "llama_kv_cache_unified: layer  17: dev = CPU\n",
      "llama_kv_cache_unified: layer  18: dev = CPU\n",
      "llama_kv_cache_unified: layer  19: dev = CPU\n",
      "llama_kv_cache_unified: layer  20: dev = CPU\n",
      "llama_kv_cache_unified: layer  21: dev = CPU\n",
      "llama_kv_cache_unified: layer  22: dev = CPU\n",
      "llama_kv_cache_unified: layer  23: dev = CPU\n",
      "llama_kv_cache_unified: layer  24: dev = CPU\n",
      "llama_kv_cache_unified: layer  25: dev = CPU\n",
      "llama_kv_cache_unified: layer  26: dev = CPU\n",
      "llama_kv_cache_unified: layer  27: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =   224.00 MiB\n",
      "llama_kv_cache_unified: size =  224.00 MiB (  2048 cells,  28 layers,  1/1 seqs), K (f16):  112.00 MiB, V (f16):  112.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 1\n",
      "llama_context: max_nodes = 2040\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "llama_context:        CPU compute buffer size =   256.50 MiB\n",
      "llama_context: graph nodes  = 986\n",
      "llama_context: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | AVX512_VNNI = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
      "Model metadata: {'general.file_type': '15', 'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- if strftime_now is defined %}\\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\\n    {%- else %}\\n        {%- set date_string = \"26 Jul 2024\" %}\\n    {%- endif %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n        {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n        {{- \\'\"parameters\": \\' }}\\n        {{- tool_call.arguments | tojson }}\\n        {{- \"}\" }}\\n        {{- \"<|eot_id|>\" }}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'llama.attention.value_length': '128', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '24', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Merged_Model_Instruct_Qlora', 'general.type': 'model', 'general.size_label': '3.2B', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.add_sep_token': 'false', 'llama.block_count': '28', 'llama.attention.head_count_kv': '8', 'llama.attention.key_length': '128'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- if strftime_now is defined %}\n",
      "        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n",
      "    {%- else %}\n",
      "        {%- set date_string = \"26 Jul 2024\" %}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "        {{- '\"parameters\": ' }}\n",
      "        {{- tool_call.arguments | tojson }}\n",
      "        {{- \"}\" }}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1519.80 ms /    11 tokens (  138.16 ms per token,     7.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =     897.68 ms /     4 runs   (  224.42 ms per token,     4.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    2422.51 ms /    15 tokens\n",
      "llama_perf_context_print:    graphs reused =          3\n",
      "Llama.generate: 10 prefix-match hit, remaining 1 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =   10970.69 ms /    50 runs   (  219.41 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11022.68 ms /    51 tokens\n",
      "llama_perf_context_print:    graphs reused =         49\n",
      "Llama.generate: 7 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1152.94 ms /     6 tokens (  192.16 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10729.00 ms /    49 runs   (  218.96 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11933.40 ms /    55 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1408.14 ms /    10 tokens (  140.81 ms per token,     7.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10746.93 ms /    49 runs   (  219.33 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   12206.84 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 3 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1013.96 ms /     3 tokens (  337.99 ms per token,     2.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10731.84 ms /    49 runs   (  219.02 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11797.18 ms /    52 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =     942.64 ms /     4 tokens (  235.66 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10744.30 ms /    49 runs   (  219.27 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11738.22 ms /    53 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1603.44 ms /    17 tokens (   94.32 ms per token,    10.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10733.21 ms /    49 runs   (  219.05 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   12388.15 ms /    66 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1306.42 ms /     9 tokens (  145.16 ms per token,     6.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10722.95 ms /    49 runs   (  218.84 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   12080.66 ms /    58 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 3 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1020.43 ms /     3 tokens (  340.14 ms per token,     2.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10741.81 ms /    49 runs   (  219.22 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11813.42 ms /    52 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1205.91 ms /     8 tokens (  150.74 ms per token,     6.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10788.92 ms /    49 runs   (  220.18 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:       total time =   12046.73 ms /    57 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 9 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1660.99 ms /    14 tokens (  118.64 ms per token,     8.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10718.21 ms /    49 runs   (  218.74 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   12430.07 ms /    63 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1202.89 ms /     8 tokens (  150.36 ms per token,     6.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10706.56 ms /    49 runs   (  218.50 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:       total time =   11960.68 ms /    57 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1408.63 ms /    10 tokens (  140.86 ms per token,     7.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10710.82 ms /    49 runs   (  218.59 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   12170.49 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1046.18 ms /     5 tokens (  209.24 ms per token,     4.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10711.26 ms /    49 runs   (  218.60 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11808.44 ms /    54 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1153.29 ms /     6 tokens (  192.22 ms per token,     5.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10718.29 ms /    49 runs   (  218.74 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11922.88 ms /    55 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1512.85 ms /    11 tokens (  137.53 ms per token,     7.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10725.58 ms /    49 runs   (  218.89 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   12290.08 ms /    60 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1409.72 ms /    10 tokens (  140.97 ms per token,     7.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10706.65 ms /    49 runs   (  218.50 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:       total time =   12167.57 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1513.44 ms /    11 tokens (  137.59 ms per token,     7.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10712.00 ms /    49 runs   (  218.61 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   12276.55 ms /    60 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 2 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =     915.42 ms /     2 tokens (  457.71 ms per token,     2.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10731.60 ms /    49 runs   (  219.01 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11698.18 ms /    51 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 3 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1016.05 ms /     3 tokens (  338.68 ms per token,     2.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10801.64 ms /    49 runs   (  220.44 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:       total time =   11869.54 ms /    52 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1202.28 ms /     8 tokens (  150.28 ms per token,     6.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10779.57 ms /    49 runs   (  219.99 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:       total time =   12033.60 ms /    57 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =     950.14 ms /     4 tokens (  237.53 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10740.05 ms /    49 runs   (  219.18 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11741.40 ms /    53 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 3 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1011.15 ms /     3 tokens (  337.05 ms per token,     2.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10736.67 ms /    49 runs   (  219.12 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11798.87 ms /    52 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 3 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1008.26 ms /     3 tokens (  336.09 ms per token,     2.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10728.34 ms /    49 runs   (  218.95 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11787.80 ms /    52 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1603.00 ms /    17 tokens (   94.29 ms per token,    10.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10715.56 ms /    49 runs   (  218.68 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   12369.45 ms /    66 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 3 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1010.47 ms /     3 tokens (  336.82 ms per token,     2.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10726.84 ms /    49 runs   (  218.92 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11788.60 ms /    52 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1475.63 ms /    12 tokens (  122.97 ms per token,     8.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10720.09 ms /    49 runs   (  218.78 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   12246.59 ms /    61 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =     945.20 ms /     4 tokens (  236.30 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10712.48 ms /    49 runs   (  218.62 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11708.82 ms /    53 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =     939.79 ms /     4 tokens (  234.95 ms per token,     4.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10722.95 ms /    49 runs   (  218.84 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11713.56 ms /    53 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1201.67 ms /     8 tokens (  150.21 ms per token,     6.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10763.53 ms /    49 runs   (  219.66 ms per token,     4.55 tokens per second)\n",
      "llama_perf_context_print:       total time =   12016.36 ms /    57 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =     944.42 ms /     4 tokens (  236.10 ms per token,     4.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10714.88 ms /    49 runs   (  218.67 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11710.54 ms /    53 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =     946.06 ms /     4 tokens (  236.52 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10725.19 ms /    49 runs   (  218.88 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11722.22 ms /    53 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1204.60 ms /     8 tokens (  150.58 ms per token,     6.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10698.75 ms /    49 runs   (  218.34 ms per token,     4.58 tokens per second)\n",
      "llama_perf_context_print:       total time =   11954.49 ms /    57 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =     944.92 ms /     4 tokens (  236.23 ms per token,     4.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10722.26 ms /    49 runs   (  218.82 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11718.23 ms /    53 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =     948.01 ms /     4 tokens (  237.00 ms per token,     4.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10721.35 ms /    49 runs   (  218.80 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11720.47 ms /    53 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1462.37 ms /    12 tokens (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10712.43 ms /    49 runs   (  218.62 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   12226.10 ms /    61 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 3 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1022.51 ms /     3 tokens (  340.84 ms per token,     2.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10739.59 ms /    49 runs   (  219.18 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11813.28 ms /    52 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 4 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =     950.39 ms /     4 tokens (  237.60 ms per token,     4.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10722.19 ms /    49 runs   (  218.82 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11723.78 ms /    53 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1209.93 ms /     8 tokens (  151.24 ms per token,     6.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10715.42 ms /    49 runs   (  218.68 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11976.63 ms /    57 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1161.26 ms /     6 tokens (  193.54 ms per token,     5.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10785.77 ms /    49 runs   (  220.12 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:       total time =   11998.30 ms /    55 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1420.41 ms /    10 tokens (  142.04 ms per token,     7.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10723.72 ms /    49 runs   (  218.85 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   12195.00 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1416.62 ms /    10 tokens (  141.66 ms per token,     7.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10718.94 ms /    49 runs   (  218.75 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   12186.57 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 3 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1022.14 ms /     3 tokens (  340.71 ms per token,     2.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10718.67 ms /    49 runs   (  218.75 ms per token,     4.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   11791.97 ms /    52 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1777.94 ms /    15 tokens (  118.53 ms per token,     8.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10737.68 ms /    49 runs   (  219.14 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   12566.58 ms /    64 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 9 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1071.81 ms /     5 tokens (  214.36 ms per token,     4.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10751.87 ms /    49 runs   (  219.43 ms per token,     4.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   11875.67 ms /    54 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1494.56 ms /    16 tokens (   93.41 ms per token,    10.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10805.68 ms /    49 runs   (  220.52 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:       total time =   12351.61 ms /    65 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 3 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1042.81 ms /     3 tokens (  347.60 ms per token,     2.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10807.90 ms /    49 runs   (  220.57 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:       total time =   11902.65 ms /    52 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1347.33 ms /     9 tokens (  149.70 ms per token,     6.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10802.08 ms /    49 runs   (  220.45 ms per token,     4.54 tokens per second)\n",
      "llama_perf_context_print:       total time =   12201.20 ms /    58 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1443.00 ms /    10 tokens (  144.30 ms per token,     6.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10814.76 ms /    49 runs   (  220.71 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:       total time =   12309.18 ms /    59 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n",
      "Llama.generate: 7 prefix-match hit, remaining 5 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1081.11 ms /     5 tokens (  216.22 ms per token,     4.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10881.93 ms /    49 runs   (  222.08 ms per token,     4.50 tokens per second)\n",
      "llama_perf_context_print:       total time =   12014.67 ms /    54 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n",
      "Llama.generate: 7 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1519.92 ms\n",
      "llama_perf_context_print: prompt eval time =    1242.74 ms /     8 tokens (  155.34 ms per token,     6.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10828.24 ms /    49 runs   (  220.98 ms per token,     4.53 tokens per second)\n",
      "llama_perf_context_print:       total time =   12122.64 ms /    57 tokens\n",
      "llama_perf_context_print:    graphs reused =         47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Time to First Token: 1185.94 ms\n",
      "Average Time per Output Token: 215.91 ms\n",
      "Token Latency - P50: 219.84 ms, P95: 223.32 ms, P99: 226.33 ms\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Load your quantized GGUF model\n",
    "llm = Llama(\n",
    "    model_path=\"quantized_models/ft-qlora-q4_k_m.gguf\", # QLoRA INT 4 model\n",
    "    n_ctx=2048, # context window in tokens (prompt + generated)\n",
    "    n_threads=8,  # Adjust for CPU threads if CPU inference\n",
    "    n_gpu_layers=-1,  # -1 = all layers on GPU\n",
    "    use_mlock=True #asks OS to lock model in RAM to reduce paging\n",
    ")\n",
    "\n",
    "# Warm-up\n",
    "first_example = test_dataset[0]\n",
    "warmup_prompt = first_example[\"input_text\"]\n",
    "_ = llm(warmup_prompt, max_tokens=5)\n",
    "print(\"Warm-up done.\\n\")\n",
    "\n",
    "# Latency measurement\n",
    "num_runs = 50\n",
    "ttft_list = [] # in ms\n",
    "token_latency_list = [] # in ms\n",
    "\n",
    "for run in range(num_runs):\n",
    "    example = test_dataset[run % len(test_dataset)]  # Loop through val set\n",
    "    full_prompt = example[\"input_text\"]\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    first_token_time = None\n",
    "    prev_time = None\n",
    "    token_times = []\n",
    "\n",
    "    for idx, output in enumerate(\n",
    "        llm(full_prompt, max_tokens=50, stream=True)\n",
    "    ):\n",
    "        now = time.perf_counter()\n",
    "\n",
    "        if idx == 0:\n",
    "            # Time to first token\n",
    "            first_token_time = now - start_time\n",
    "            prev_time = now\n",
    "        else:\n",
    "            # Time per subsequent token\n",
    "            token_times.append(now - prev_time)\n",
    "            prev_time = now\n",
    "\n",
    "    ttft_list.append(first_token_time * 1000)  # ms\n",
    "    token_latency_list.extend([t * 1000 for t in token_times])\n",
    "\n",
    "# Results\n",
    "avg_ttft = np.mean(ttft_list)\n",
    "avg_token_latency = np.mean(token_latency_list)\n",
    "p50_token, p95_token, p99_token = np.percentile(token_latency_list, [50, 95, 99])\n",
    "\n",
    "print(f\"Average Time to First Token: {avg_ttft:.2f} ms\")\n",
    "print(f\"Average Time per Output Token: {avg_token_latency:.2f} ms\")\n",
    "print(f\"Token Latency - P50: {p50_token:.2f} ms, P95: {p95_token:.2f} ms, P99: {p99_token:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQiAiWBVzrA_"
   },
   "source": [
    "#### Memory Bandwidth: How fast CPU/GPU can read/write from/to RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3h69tIOoxxP1",
    "outputId": "69b97923-5ad5-480e-ddd9-d8d5885d4f22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: x86_64\n",
      "Cores: 2\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import multiprocessing\n",
    "\n",
    "print(\"CPU:\", platform.processor())\n",
    "print(\"Cores:\", multiprocessing.cpu_count())\n",
    "\n",
    "# This tells you your CPU is 64-bit and follows the x86 instruction set (common for Intel and AMD CPUs).\n",
    "# x86_64 means it can handle 64-bit operations, which allows addressing more memory and generally better performance for modern applications.\n",
    "# Your CPU has 2 physical cores. Each core can execute instructions independently, so more cores = better parallel performance. With 2 cores, your CPU can do at most 2 independent tasks simultaneously (without hyperthreading)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UxHbxBiBzFZ6",
    "outputId": "b5dc424b-bed8-4f65-e0ca-e13beb4b729d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:             x86_64\n",
      "  CPU op-mode(s):         32-bit, 64-bit\n",
      "  Address sizes:          46 bits physical, 48 bits virtual\n",
      "  Byte Order:             Little Endian\n",
      "CPU(s):                   2\n",
      "  On-line CPU(s) list:    0,1\n",
      "Vendor ID:                GenuineIntel\n",
      "  Model name:             Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "    CPU family:           6\n",
      "    Model:                85\n",
      "    Thread(s) per core:   2\n",
      "    Core(s) per socket:   1\n",
      "    Socket(s):            1\n",
      "    Stepping:             3\n",
      "    BogoMIPS:             4000.36\n",
      "    Flags:                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge m\n",
      "                          ca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht sysc\n",
      "                          all nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xt\n",
      "                          opology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq\n",
      "                           ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt\n",
      "                           aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dno\n",
      "                          wprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase\n",
      "                           tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm m\n",
      "                          px avx512f avx512dq rdseed adx smap clflushopt clwb av\n",
      "                          x512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsave\n",
      "                          s arat md_clear arch_capabilities\n",
      "Virtualization features:  \n",
      "  Hypervisor vendor:      KVM\n",
      "  Virtualization type:    full\n",
      "Caches (sum of all):      \n",
      "  L1d:                    32 KiB (1 instance)\n",
      "  L1i:                    32 KiB (1 instance)\n",
      "  L2:                     1 MiB (1 instance)\n",
      "  L3:                     38.5 MiB (1 instance)\n",
      "NUMA:                     \n",
      "  NUMA node(s):           1\n",
      "  NUMA node0 CPU(s):      0,1\n",
      "Vulnerabilities:          \n",
      "  Gather data sampling:   Not affected\n",
      "  Itlb multihit:          Not affected\n",
      "  L1tf:                   Mitigation; PTE Inversion\n",
      "  Mds:                    Vulnerable; SMT Host state unknown\n",
      "  Meltdown:               Vulnerable\n",
      "  Mmio stale data:        Vulnerable\n",
      "  Reg file data sampling: Not affected\n",
      "  Retbleed:               Vulnerable\n",
      "  Spec rstack overflow:   Not affected\n",
      "  Spec store bypass:      Vulnerable\n",
      "  Spectre v1:             Vulnerable: __user pointer sanitization and usercopy b\n",
      "                          arriers only; no swapgs barriers\n",
      "  Spectre v2:             Vulnerable; IBPB: disabled; STIBP: disabled; PBRSB-eIB\n",
      "                          RS: Not affected; BHI: Vulnerable\n",
      "  Srbds:                  Not affected\n",
      "  Tsx async abort:        Vulnerable\n"
     ]
    }
   ],
   "source": [
    "# check CPU info\n",
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xbNuzQsOzMUy",
    "outputId": "067f71f0-1896-44db-a904-d5217ac391cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total RAM: 13.61 GB\n",
      "Available RAM: 7.60 GB\n"
     ]
    }
   ],
   "source": [
    "# check RAM\n",
    "import psutil\n",
    "ram = psutil.virtual_memory()\n",
    "print(f\"Total RAM: {ram.total / 1e9:.2f} GB\")\n",
    "print(f\"Available RAM: {ram.available / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EpSUNogmzRjl",
    "outputId": "8fce32ce-7b8d-41f6-d6cb-324746a97bc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated memory bandwidth: 3.16 GB/s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "size = 100_000_000  # ~100 million floats ~0.8GB\n",
    "a = np.random.rand(size).astype(np.float32)\n",
    "b = np.zeros_like(a)\n",
    "\n",
    "start = time.time()\n",
    "b[:] = a[:]  # copy operation\n",
    "end = time.time()\n",
    "\n",
    "bandwidth = a.nbytes / (end - start) / 1e9  # GB/s\n",
    "print(f\"Estimated memory bandwidth: {bandwidth:.2f} GB/s\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0288c3a537534527beca3c9546889619": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79c9cc0a53484b2b8de512ed6e8df4ad",
      "max": 50500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b72ef72f0c0b4979b427023ce2761ddb",
      "value": 50500
     }
    },
    "03742ca8f0f64ca4b0f31ec9c094f6fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0663a3cc37d04fe0979a76abb882597d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "066899c1d2474d61976be431588b678a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "088c8a35a2fe47679849d702fbb8160b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0994b4f2277f4c7cae295bf8c9e413f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_84c8c20e02774ede96768e4ed9983f62",
       "IPY_MODEL_5b5a332cda7a446d91201e61794658af",
       "IPY_MODEL_eb5693ff20c14e24a210f2e2518780c4"
      ],
      "layout": "IPY_MODEL_93eab46e8f4e476996d8924f59cc2b70"
     }
    },
    "0a7e09ccde6042a4af8d5ed179d3db2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d15b60eac0244e7baeed958bffe06a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0eb24510fd144cb88c565e35be4e2f12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65a60afee7b144018c41c3462d91d232",
      "placeholder": "​",
      "style": "IPY_MODEL_8510cce4a0354d30a27490fe0da82cdd",
      "value": " 2/2 [01:42&lt;00:00, 102.74s/it]"
     }
    },
    "0f8a62fd50574c038a40112963aa6cca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_640524ea94aa436daabe9e843e6efb71",
      "placeholder": "​",
      "style": "IPY_MODEL_1d1f9d9423d449a9833bff4c77042a76",
      "value": "ft-q5_k_m.gguf: 100%"
     }
    },
    "10986a42d3fe4051bc6796b15b7cd423": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "10e8e5d0112649a6998e829ec7d16a45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9653583d2d4e4f06b832eacd902ed78b",
      "placeholder": "​",
      "style": "IPY_MODEL_81f608c8f5f946a6890d7ac38f0e5753",
      "value": "ft-q4_k_m.gguf: 100%"
     }
    },
    "1159428d248c4ec5adc88013abe22152": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f01ed6bdd5904f60a0ab9b197befbd30",
       "IPY_MODEL_5ecf368fc0d240eba41835848b68ceba",
       "IPY_MODEL_4effd5c268e74bbdaa273e13cedbafac"
      ],
      "layout": "IPY_MODEL_cc0d5484dfb840fc941c27ba7bfffb1e"
     }
    },
    "12638571d5514bd0bdd92eb53fbc85c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0eba376927048dfb4ed23363c45e122",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5f868c83de0741af90b6ea4c931edec9",
      "value": 2
     }
    },
    "1290b76a455f4f349338946ee08041d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c10f1a3a1e9e45f399f31a7761bb9450",
      "placeholder": "​",
      "style": "IPY_MODEL_a31204c7013a4576a02849434438ac7a",
      "value": " 2.02G/2.02G [00:52&lt;00:00, 37.8MB/s]"
     }
    },
    "13140568accd49e7bb86152e6bcaf515": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1378b3a8765c4c4d8b0f3bfb44495032": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6286ff0daa3470194da5d945fceb31e",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f772c8f163214fdd8e4d8845bf037ced",
      "value": 2
     }
    },
    "14b27c4a88ca44f1be0dc7c4d5ecdb1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_800acb17d0834793b13fd543a93e2d6f",
      "placeholder": "​",
      "style": "IPY_MODEL_ae7aee0f7d8d4c90842c1edd9e89564a",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "14e59081345d4b1ab34ee1a2179c02dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17eb4d538db640bbaf88ab8a5714a572": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e546e41db58046aaa0676d4e3f5d5ad2",
      "placeholder": "​",
      "style": "IPY_MODEL_90662068fb2543d187e48a50e7107aaa",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "183498c56b9b47a88be92bc1bacd0cca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a27e8cef1274ddfb7888c59e0fcaa94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0663a3cc37d04fe0979a76abb882597d",
      "placeholder": "​",
      "style": "IPY_MODEL_d3233dac7f024ac29a9bd4f34c02c8c9",
      "value": "adapter_config.json: 100%"
     }
    },
    "1b9b479a729b417288b35d7e063811d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1c152f62467c46689c4435bb959410b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1cf39698f3744e9593101c7e6f1b521b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d1f9d9423d449a9833bff4c77042a76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e3a2c0ab05e4c2fa7e757ecc34cd818": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ee71ca73fc8418d9b37a5dbd3582618": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cff5f5e2ccf64a559e750ce970127a88",
      "placeholder": "​",
      "style": "IPY_MODEL_24b3a3b0e1184c3697f019d22112e080",
      "value": " 2.02G/2.02G [01:30&lt;00:00, 25.1MB/s]"
     }
    },
    "1eff09b5ad1d495fb26d9284a5c52640": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecbd6647c0dc4516a733dd419d7c734d",
      "placeholder": "​",
      "style": "IPY_MODEL_1cf39698f3744e9593101c7e6f1b521b",
      "value": " 9544/0 [00:00&lt;00:00, 62576.01 examples/s]"
     }
    },
    "200d294388bb45c680f1858bc0f8f59a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "24b3a3b0e1184c3697f019d22112e080": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "24cda1761122448188b9b010e4b77904": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "250116a2003143a2a9c9fa810949cec4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_db13c86da84b442581e1c43295e36ea8",
       "IPY_MODEL_ba61498e74464a71bc88b43121df0ba1",
       "IPY_MODEL_1ee71ca73fc8418d9b37a5dbd3582618"
      ],
      "layout": "IPY_MODEL_481ceb2535004568bb3f58ec139ebd70"
     }
    },
    "257d232a8608462c8455bfd276239e9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27949bec6bff45739a51f787121387a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_95a1ce2a6ca04fb2aa1ca6dfb50bac57",
      "placeholder": "​",
      "style": "IPY_MODEL_6e5c08d303664d6a85dfd65a32f3fca9",
      "value": "Fetching 4 files: 100%"
     }
    },
    "2902cfa699974bd3a8cd42f4162e0578": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a07ab49b8ba4ea589b8d2b4e3f00299": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a15e4161972427f83023fac141a7af7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2aff03fc4aea4e86b66cad0f8d195b07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b3cdea42e8e44fca2ff7be2f87407f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b3f483db9e74a648a073add58ce5be1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2bb2b76e465b4624b5149cd7a36505f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e1aacc2d33d40d98a3bde57ede456cd",
      "placeholder": "​",
      "style": "IPY_MODEL_b402347aa60f4c73b3e70a9439a42f8f",
      "value": "fp16-ft.gguf: 100%"
     }
    },
    "2c02861753364342b3ff8e140832b52a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c23bdcf40b04c058e6600e6377ce525": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cbb0bd72b684576b0a22d23d20a1136": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e3950d23a014c808af0e525f6712253": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f4e16a1faa649c69574889550e2f5f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_930fef61078540a5a5aae792e889d7ce",
       "IPY_MODEL_846480380db347888c12f25010959867",
       "IPY_MODEL_ff37f5ae2bec4e34981d12a9e40cb1f7"
      ],
      "layout": "IPY_MODEL_7cb798c039d3491ea18f66d385583b93"
     }
    },
    "31eb546c6a674e5c9505c2ed6a8592b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "321db23478bf4fa9b4135fcbe42a321d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3347f53c397543c9b07b7cfaa30acac3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35a132df44364f5c9b0e67417708db52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3618831bd1734c95a0c7132974e856fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4079bfe12b44140b874fee5b3578d41",
      "max": 1459729880,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fc8348e8f2c64404bfb99770882f8a9c",
      "value": 1459729880
     }
    },
    "36c4f9b4c473493992ca608e6dad1fb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73a1219c4d0343628c8e3a8446a14f3d",
      "max": 2019373280,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_10986a42d3fe4051bc6796b15b7cd423",
      "value": 2019373280
     }
    },
    "3730040ac5bb44c69845296cea8944e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "379a7d9947e24b4bbbebe7b9b0d68d70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_986d8c7950824d25a7d16abcef3e1980",
      "max": 9085657,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_643a82a3ac5a4fcc88c36c6502a4e7ff",
      "value": 9085657
     }
    },
    "39a245e31a5046559a33e6c91f383510": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a0d28bcfd724c7c802bad4c1e35c887": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3a5b729d477047249f880eae85bdabc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75c115fb48d84b4786c668ccc7dc7cea",
      "placeholder": "​",
      "style": "IPY_MODEL_54265dfb860446aa9d3ef4e6eb40ae38",
      "value": "Upload 2 LFS files: 100%"
     }
    },
    "3be525d0fd2f48e3bdcbc144caa0215d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3be82b3111ca42b5a76d62caa38cbf96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3d174d49dfcc4443a91dfd29d9ab5779": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ad9f70e7e5c40d7b11f210c9ffd8889",
      "placeholder": "​",
      "style": "IPY_MODEL_ee790f82326c4803bf90ac780e93fb44",
      "value": "tokenizer.json: 100%"
     }
    },
    "3d2306ec989142fda86d124359d8e08e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fb78b8f953d44cf95d853e5fec926fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "400561504e604ed183c799bd4dcb32ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41ffc4de51854f38bff7cb7c691169aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1a27e8cef1274ddfb7888c59e0fcaa94",
       "IPY_MODEL_99fb537695074a0099c42bddb9f08171",
       "IPY_MODEL_9bb5835be9cc4bb5acd4d1f7fac92ce7"
      ],
      "layout": "IPY_MODEL_2c02861753364342b3ff8e140832b52a"
     }
    },
    "435a93f2eaac48fcb178c7ae99806360": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43e4cccc375f489eb9cd60522e7b106d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03742ca8f0f64ca4b0f31ec9c094f6fb",
      "placeholder": "​",
      "style": "IPY_MODEL_446061878beb4ecc8bf07725876f0ac3",
      "value": " 2/2 [01:27&lt;00:00, 87.91s/it]"
     }
    },
    "446061878beb4ecc8bf07725876f0ac3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "45666996b40a48aab86346d104598396": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56afee73304f46769ba4540e5b948950",
      "max": 4965799096,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1b9b479a729b417288b35d7e063811d2",
      "value": 4965799096
     }
    },
    "46a5473473534f2882d364dba680a1d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4817179b5911487eb3144202b3c811b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "481ceb2535004568bb3f58ec139ebd70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48ab1e8d79f944178c0029c47c3c536c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2f30b8dafa64954b6803a3286b8bf01",
      "placeholder": "​",
      "style": "IPY_MODEL_ee3092c7a3784539937b00165544bd1b",
      "value": " 2/2 [00:09&lt;00:00,  4.46s/it]"
     }
    },
    "48ff244d4472495da478789616a9b04d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5edfc7ef96854c69ab0a2f431150c11e",
      "max": 17209920,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_200d294388bb45c680f1858bc0f8f59a",
      "value": 17209920
     }
    },
    "4a2798e8cb4c4065ba1218c1c277b3f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e0075ea7dcf4f66975aea94fc47c7ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ede66d7a5d44912b009a699aac5810f",
      "placeholder": "​",
      "style": "IPY_MODEL_72e87311db4449c980e36e83cdd3b104",
      "value": " 4.97G/4.97G [01:42&lt;00:00, 44.7MB/s]"
     }
    },
    "4e0b0b0979b04eadb15469f2b4040968": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b887cf08ec2e4a17bb1ed2eeb12487c4",
       "IPY_MODEL_3618831bd1734c95a0c7132974e856fe",
       "IPY_MODEL_e026e63e2cba4d53abe032fe47c6fe59"
      ],
      "layout": "IPY_MODEL_4817179b5911487eb3144202b3c811b2"
     }
    },
    "4effd5c268e74bbdaa273e13cedbafac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3be525d0fd2f48e3bdcbc144caa0215d",
      "placeholder": "​",
      "style": "IPY_MODEL_98df1fee28424a1d909be25e9ef169be",
      "value": " 36.7M/36.7M [00:00&lt;00:00, 73.0MB/s]"
     }
    },
    "5128e4f716c74284b8dabd35d3b75bf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f901ca0e497c4a37912a2c72844582dc",
       "IPY_MODEL_d8dfa8714e22456ebfecad383b40f737",
       "IPY_MODEL_e186637138f646c8aa9e7c6151ca2d64"
      ],
      "layout": "IPY_MODEL_75a59fa33bc3407a99264cea16824c58"
     }
    },
    "54265dfb860446aa9d3ef4e6eb40ae38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "566c113518b64a979b19a932e1af7251": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "56afee73304f46769ba4540e5b948950": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "575ce6cb0fde466484f4f25ff2d655b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58bf3d73c97c4f128565aef1f09135b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a48f4f5470814f9d99fff6fc26e21c23",
      "placeholder": "​",
      "style": "IPY_MODEL_eb1ebacb23324f35a1dcfd584d6ff70f",
      "value": " 1.46G/1.46G [01:01&lt;00:00, 6.69MB/s]"
     }
    },
    "5a7643587f704932bc6a8c47f58e720b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5a87181b3a1a408a8a1ce205defdc239": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5b5a332cda7a446d91201e61794658af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fae2590ce87d4f67bad72279a3bfcbc5",
      "max": 844,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cfdfc5378eb144659dcad68fba408887",
      "value": 844
     }
    },
    "5bd2d31bf2aa4fafa78e598d931ed4ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c2874a67c1d4484b474a730c9132563": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e5a51d1354640848401b103901d381e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ecf368fc0d240eba41835848b68ceba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d44ff8e83b9d433a873b10b7e92bef4d",
      "max": 36730224,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a8364496f60b49658cb1292df2dd08e0",
      "value": 36730224
     }
    },
    "5edfc7ef96854c69ab0a2f431150c11e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f868c83de0741af90b6ea4c931edec9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5fcedce52f1b423a995eef9725a5ea4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6092d59cc3ce46648dd3d07e53f3e972": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7c59587d51c7439a8083068ed4c7e684",
       "IPY_MODEL_6fde98bb3a654885bcc1fc276cb5b079",
       "IPY_MODEL_7da62dcc79214a368d6ff9a68f3404cb"
      ],
      "layout": "IPY_MODEL_cf93f08baa97487db0f4e103e5c57d1a"
     }
    },
    "63642d304461443fba6e9f37ab644bab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_31eb546c6a674e5c9505c2ed6a8592b6",
      "placeholder": "​",
      "style": "IPY_MODEL_0d15b60eac0244e7baeed958bffe06a4",
      "value": " 20.9k/20.9k [00:00&lt;00:00, 2.21MB/s]"
     }
    },
    "63ad5d7b259a4e93b71de386c99f3721": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c2874a67c1d4484b474a730c9132563",
      "max": 2322149600,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f3d4eb4aa71349e29ab6fb1b7d2f7646",
      "value": 2322149600
     }
    },
    "63df08a761cf4d16911b109f04bc5700": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a2798e8cb4c4065ba1218c1c277b3f3",
      "max": 4965798912,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1c152f62467c46689c4435bb959410b7",
      "value": 4965798912
     }
    },
    "640524ea94aa436daabe9e843e6efb71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6435402333d24907b7cc3d5bfe016eea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a7e09ccde6042a4af8d5ed179d3db2b",
      "max": 6433683680,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9b0cf395d31043b7975c8ef96fb41655",
      "value": 6433683680
     }
    },
    "643a82a3ac5a4fcc88c36c6502a4e7ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "64f79a712cd84e5caaee582a2302ab26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65a60afee7b144018c41c3462d91d232": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66da01361dcd4b3cb426ff28814ba317": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ed0325dd08a44a68a54dca6ab6bc1ad7",
       "IPY_MODEL_a2794e32c1974e7e8f9e7478baadfbeb",
       "IPY_MODEL_bedf1a44baad417ba144c6149688af5e"
      ],
      "layout": "IPY_MODEL_d166eeec8d414e9fbe6b807d07648f65"
     }
    },
    "672547640d344161b51ad763aefbcf77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "674dda9a47724ba8870530536de5ac32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67b2740c64ed474a91fa4961299b91ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c6dc41f61fd43939a215b362d497156",
      "placeholder": "​",
      "style": "IPY_MODEL_1e3a2c0ab05e4c2fa7e757ecc34cd818",
      "value": "model-00001-of-00002.safetensors: 100%"
     }
    },
    "68822745572944bebcbc787374e61425": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6948ae96ea4945ab9d6698850d77795e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c51a29a6f13436481c793f938544714",
      "max": 1459729952,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b5960a63868c4aa18ac3b507b25750d6",
      "value": 1459729952
     }
    },
    "69d8af7e0b3c47a08f23fa3e562c8655": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ad9f70e7e5c40d7b11f210c9ffd8889": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b8bb3f6c0e747fab63d02da68677ee5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c6dc41f61fd43939a215b362d497156": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e1aacc2d33d40d98a3bde57ede456cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e29b86aea584507ab553dd1934c1893": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e5c08d303664d6a85dfd65a32f3fca9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e6e9450b6264254960b0296233c74c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ede66d7a5d44912b009a699aac5810f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fdacd717a0449cda2a77ea11b1b469b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2bb2b76e465b4624b5149cd7a36505f3",
       "IPY_MODEL_6435402333d24907b7cc3d5bfe016eea",
       "IPY_MODEL_e996b5f33a8f4d8bb2a6f9ef961767e1"
      ],
      "layout": "IPY_MODEL_257d232a8608462c8455bfd276239e9a"
     }
    },
    "6fde98bb3a654885bcc1fc276cb5b079": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14e59081345d4b1ab34ee1a2179c02dc",
      "max": 301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8c77b1129830468c9bed8edc907672be",
      "value": 301
     }
    },
    "71652bc242fc4fa9abc02a6ef71619a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84e6b20859094a16be58f6ec99c5c7c4",
      "max": 5174,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3be82b3111ca42b5a76d62caa38cbf96",
      "value": 5174
     }
    },
    "7234a61c87304727ba52bcbbd0237c59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "72dad2cfe6af48688783eef9b888feef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "72e87311db4449c980e36e83cdd3b104": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73a1219c4d0343628c8e3a8446a14f3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7497de783d374200ad461531f5b070f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_954deda696d44e149da468cb044a569e",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3a0d28bcfd724c7c802bad4c1e35c887",
      "value": 2
     }
    },
    "75a59fa33bc3407a99264cea16824c58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75c115fb48d84b4786c668ccc7dc7cea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "765a33db0ac646598051efc89d14e56e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "76a52ba3e7b544db8c9d546c82e96cd4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77e0da2869bb427db25600549fd5a389": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79967df77bd14dec808f46ebb7860487": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b64101b9cb414947ab3017ed6168533f",
       "IPY_MODEL_e766b80163cc4ed583e33fa4f90ca608",
       "IPY_MODEL_63642d304461443fba6e9f37ab644bab"
      ],
      "layout": "IPY_MODEL_2c23bdcf40b04c058e6600e6377ce525"
     }
    },
    "79c9cc0a53484b2b8de512ed6e8df4ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7aaf02e821b04233a2d25eba17a8ef44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ae0c882155c4f9d955559ef8b81d209": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d2306ec989142fda86d124359d8e08e",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd8b586bb0544c3fb90c3f9caf39ab01",
      "value": 3
     }
    },
    "7b6f03e3fdf64bab92f03f3db26348b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c59587d51c7439a8083068ed4c7e684": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d806b3a8d9f0431d8861acee5962bcf3",
      "placeholder": "​",
      "style": "IPY_MODEL_13140568accd49e7bb86152e6bcaf515",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "7cb798c039d3491ea18f66d385583b93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7da62dcc79214a368d6ff9a68f3404cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_674dda9a47724ba8870530536de5ac32",
      "placeholder": "​",
      "style": "IPY_MODEL_8ee02eb13cf342a897261e389f5c2ae8",
      "value": " 301/301 [00:00&lt;00:00, 42.9kB/s]"
     }
    },
    "7df05a1780f24b80a1f1f4b67fffaed1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f460bfcb90f4fd999546a9240ec44aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7fc16bb542f74248a3b61eeea754bd30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc95a715f5dc44908ecd59830814938f",
       "IPY_MODEL_48ff244d4472495da478789616a9b04d",
       "IPY_MODEL_fb087ed8f6d24e0895edf7425c77c427"
      ],
      "layout": "IPY_MODEL_24cda1761122448188b9b010e4b77904"
     }
    },
    "7fd720c03370455893704a4c980b3229": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "800acb17d0834793b13fd543a93e2d6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "803fc165e3164175927cf4afb72f2c12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "81f608c8f5f946a6890d7ac38f0e5753": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8319c55fc8d7432fba3eb7fbf04970e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3d174d49dfcc4443a91dfd29d9ab5779",
       "IPY_MODEL_379a7d9947e24b4bbbebe7b9b0d68d70",
       "IPY_MODEL_f6d32088da8c42259971d83f977740af"
      ],
      "layout": "IPY_MODEL_e465145941694efc842e5ffef949376c"
     }
    },
    "846480380db347888c12f25010959867": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbfc084fa5c44001b6c199647f0dbc21",
      "max": 6433683680,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_35a132df44364f5c9b0e67417708db52",
      "value": 6433683680
     }
    },
    "84c8c20e02774ede96768e4ed9983f62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c75c014eb20f4f23bda9e6f89efa7766",
      "placeholder": "​",
      "style": "IPY_MODEL_e97e42daf542446993b8d33fc2f20313",
      "value": "config.json: 100%"
     }
    },
    "84e6b20859094a16be58f6ec99c5c7c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8510cce4a0354d30a27490fe0da82cdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8644664fc98c4635b8f518b8619149a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_672547640d344161b51ad763aefbcf77",
      "placeholder": "​",
      "style": "IPY_MODEL_bee908ff03e6405dbfda496f244143b2",
      "value": "Generating train split: "
     }
    },
    "8749e9f967de43f4ad7e60547cfb0977": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b3f483db9e74a648a073add58ce5be1",
      "placeholder": "​",
      "style": "IPY_MODEL_ce15639b38a045e2b5ec879a860150e7",
      "value": " 50.5k/50.5k [00:00&lt;00:00, 5.28MB/s]"
     }
    },
    "87c1ac43e0bb41688594f4ac6dca6dda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88884cca615f4f1ea9247f12e5624ae0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f684efaa68d140db96ffd07c16432da0",
       "IPY_MODEL_45666996b40a48aab86346d104598396",
       "IPY_MODEL_feeacebb2051403693905f5108ffa216"
      ],
      "layout": "IPY_MODEL_a1d1b3ca9d814da498ff6fbe84a65aeb"
     }
    },
    "8b1ae460628c43cc8b8913a4675e2193": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8bc8765ea4fd4e2b9ae74deabc50bc12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c51a29a6f13436481c793f938544714": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c77b1129830468c9bed8edc907672be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8ee02eb13cf342a897261e389f5c2ae8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "90195d993564483c9d7a2ab39f1876fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae2269e0a6b84aa8952ebcd2aaa5755c",
      "placeholder": "​",
      "style": "IPY_MODEL_9909d6f0d22042cbb4d2840d0df04dfe",
      "value": "Fetching 2 files: 100%"
     }
    },
    "90662068fb2543d187e48a50e7107aaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "91326534b61d47b9be2106d32f1ca7b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df10a926ca754fe99456e53521d4d94d",
      "placeholder": "​",
      "style": "IPY_MODEL_87c1ac43e0bb41688594f4ac6dca6dda",
      "value": " 2.32G/2.32G [01:39&lt;00:00, 23.7MB/s]"
     }
    },
    "91cfa139678142c6ad8c93146829f22f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17eb4d538db640bbaf88ab8a5714a572",
       "IPY_MODEL_0288c3a537534527beca3c9546889619",
       "IPY_MODEL_8749e9f967de43f4ad7e60547cfb0977"
      ],
      "layout": "IPY_MODEL_77e0da2869bb427db25600549fd5a389"
     }
    },
    "930fef61078540a5a5aae792e889d7ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a07ab49b8ba4ea589b8d2b4e3f00299",
      "placeholder": "​",
      "style": "IPY_MODEL_6e29b86aea584507ab553dd1934c1893",
      "value": "fp16-ft.gguf: 100%"
     }
    },
    "93eab46e8f4e476996d8924f59cc2b70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94757b8abe5740279b628bf414f0cc04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "954deda696d44e149da468cb044a569e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "956d81bc64b6496eadedf3e146abf63d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_14b27c4a88ca44f1be0dc7c4d5ecdb1d",
       "IPY_MODEL_12638571d5514bd0bdd92eb53fbc85c0",
       "IPY_MODEL_48ab1e8d79f944178c0029c47c3c536c"
      ],
      "layout": "IPY_MODEL_c525a7d9f0394d55bb9152c5a33b6503"
     }
    },
    "95a1ce2a6ca04fb2aa1ca6dfb50bac57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9653583d2d4e4f06b832eacd902ed78b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "986d8c7950824d25a7d16abcef3e1980": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9888660ab20f433a800929970f063162": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98df1fee28424a1d909be25e9ef169be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9909d6f0d22042cbb4d2840d0df04dfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "99fb537695074a0099c42bddb9f08171": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_321db23478bf4fa9b4135fcbe42a321d",
      "max": 807,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c2ede3abefb447f38d3f6c17d744af35",
      "value": 807
     }
    },
    "9a132782006f45cab2bad7ece20e64cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ae48c1f2ef5408b9801d3d5dc973c06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b0cf395d31043b7975c8ef96fb41655": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9bb5835be9cc4bb5acd4d1f7fac92ce7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f974c4bc87af4bb29e36e1b4cbfed50a",
      "placeholder": "​",
      "style": "IPY_MODEL_fe1dbdc202a747f58ad6504fb7391a38",
      "value": " 807/807 [00:00&lt;00:00, 94.3kB/s]"
     }
    },
    "9d620eaffd804253b1a0acbd3264d70d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d7f601e1a71457f8a8bea8619ec4bee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9dc1ccc23f8847c1b6fbc47a9f485373": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e8613fe87e5437ba0b56054ae589b64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1c4c6641c084f3abd095bac36ef303c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1d1b3ca9d814da498ff6fbe84a65aeb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1f2736db8d24e159e3dc074dbb8c032": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2794e32c1974e7e8f9e7478baadfbeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db069c410e1948b9b1e5fc597fc1bd44",
      "max": 185,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9d620eaffd804253b1a0acbd3264d70d",
      "value": 185
     }
    },
    "a31204c7013a4576a02849434438ac7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4079bfe12b44140b874fee5b3578d41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a48f4f5470814f9d99fff6fc26e21c23": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4b932b835234279b361aab1a5cfae9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ce809809448f42ae86230a68e70c46e0",
       "IPY_MODEL_6948ae96ea4945ab9d6698850d77795e",
       "IPY_MODEL_58bf3d73c97c4f128565aef1f09135b5"
      ],
      "layout": "IPY_MODEL_9a132782006f45cab2bad7ece20e64cf"
     }
    },
    "a5692d2b93334d17805fc6f5bc9c291c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a8364496f60b49658cb1292df2dd08e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a913bddc21374fcfa56f4ef0afdc4902": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_67b2740c64ed474a91fa4961299b91ab",
       "IPY_MODEL_63df08a761cf4d16911b109f04bc5700",
       "IPY_MODEL_4e0075ea7dcf4f66975aea94fc47c7ce"
      ],
      "layout": "IPY_MODEL_2aff03fc4aea4e86b66cad0f8d195b07"
     }
    },
    "aca3db0575ff40aa9536142677590ce0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afb587bab9c54d8ba374dbd42d157b90",
      "placeholder": "​",
      "style": "IPY_MODEL_b415db5defb54dff9cad28349d2e257d",
      "value": " 4/4 [04:40&lt;00:00, 164.74s/it]"
     }
    },
    "ad689c5d773949ad9c62d720ea904aa7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8644664fc98c4635b8f518b8619149a5",
       "IPY_MODEL_d88d8bfdb4ec4bd8b002c018fc5c0a66",
       "IPY_MODEL_1eff09b5ad1d495fb26d9284a5c52640"
      ],
      "layout": "IPY_MODEL_2b3cdea42e8e44fca2ff7be2f87407f4"
     }
    },
    "ae2269e0a6b84aa8952ebcd2aaa5755c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae7aee0f7d8d4c90842c1edd9e89564a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af3c4516c0354ab3a4d5770d51ad2104": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46a5473473534f2882d364dba680a1d4",
      "placeholder": "​",
      "style": "IPY_MODEL_cb216c94f65b466a9abd25d1ab4cfdfc",
      "value": " 5.17k/5.17k [00:00&lt;00:00, 756kB/s]"
     }
    },
    "afb587bab9c54d8ba374dbd42d157b90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b402347aa60f4c73b3e70a9439a42f8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b415db5defb54dff9cad28349d2e257d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4710c592a9d4816a40e1932707f934a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbe6a9d638e34703b58012d1c0fe943f",
      "placeholder": "​",
      "style": "IPY_MODEL_9ae48c1f2ef5408b9801d3d5dc973c06",
      "value": " 3/3 [02:20&lt;00:00, 140.56s/it]"
     }
    },
    "b5960a63868c4aa18ac3b507b25750d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b64101b9cb414947ab3017ed6168533f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8fc7192f40748899681df2bd01e79b8",
      "placeholder": "​",
      "style": "IPY_MODEL_7fd720c03370455893704a4c980b3229",
      "value": "model.safetensors.index.json: 100%"
     }
    },
    "b72ef72f0c0b4979b427023ce2761ddb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b887cf08ec2e4a17bb1ed2eeb12487c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca37f765c2c04f93a8397108125630da",
      "placeholder": "​",
      "style": "IPY_MODEL_fe724c782e5046b5b8620ae89dd95fc4",
      "value": "model-00002-of-00002.safetensors: 100%"
     }
    },
    "b9a08546be624b909257a7b2a44f98d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9f84ab2f3d047efbf3a1edf053af384": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba61498e74464a71bc88b43121df0ba1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b6f03e3fdf64bab92f03f3db26348b7",
      "max": 2019373280,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eed9bfba30384489bc0b451721983052",
      "value": 2019373280
     }
    },
    "bbe6a9d638e34703b58012d1c0fe943f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bedf1a44baad417ba144c6149688af5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39a245e31a5046559a33e6c91f383510",
      "placeholder": "​",
      "style": "IPY_MODEL_8b1ae460628c43cc8b8913a4675e2193",
      "value": " 185/185 [00:00&lt;00:00, 23.4kB/s]"
     }
    },
    "bee908ff03e6405dbfda496f244143b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c0cf9b496d144382a4f2083b7e72ff4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_435a93f2eaac48fcb178c7ae99806360",
      "placeholder": "​",
      "style": "IPY_MODEL_9888660ab20f433a800929970f063162",
      "value": "ft-q5_k_m.gguf: 100%"
     }
    },
    "c10f1a3a1e9e45f399f31a7761bb9450": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2ede3abefb447f38d3f6c17d744af35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c525a7d9f0394d55bb9152c5a33b6503": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c75c014eb20f4f23bda9e6f89efa7766": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8753847ff9747f0a4b491ee41e2b98c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c87685ed41d64896828f6a3a9045a0a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c91718027fbb42438354b23afa1faa19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_90195d993564483c9d7a2ab39f1876fd",
       "IPY_MODEL_7497de783d374200ad461531f5b070f8",
       "IPY_MODEL_43e4cccc375f489eb9cd60522e7b106d"
      ],
      "layout": "IPY_MODEL_2cbb0bd72b684576b0a22d23d20a1136"
     }
    },
    "ca37f765c2c04f93a8397108125630da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb216c94f65b466a9abd25d1ab4cfdfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cbc8f36449104deab1e791f70a67e58e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbfc084fa5c44001b6c199647f0dbc21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc0d5484dfb840fc941c27ba7bfffb1e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd8b586bb0544c3fb90c3f9caf39ab01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ce15639b38a045e2b5ec879a860150e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce18c7064dd74f089689e10d1f5aea7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1c4c6641c084f3abd095bac36ef303c",
      "max": 2322149600,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a5692d2b93334d17805fc6f5bc9c291c",
      "value": 2322149600
     }
    },
    "ce809809448f42ae86230a68e70c46e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76a52ba3e7b544db8c9d546c82e96cd4",
      "placeholder": "​",
      "style": "IPY_MODEL_9d7f601e1a71457f8a8bea8619ec4bee",
      "value": "model-00002-of-00002.safetensors: 100%"
     }
    },
    "cf290aa1a7e041a4a8f83c2a7ffaa5ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf93f08baa97487db0f4e103e5c57d1a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfdfc5378eb144659dcad68fba408887": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cff5f5e2ccf64a559e750ce970127a88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d166eeec8d414e9fbe6b807d07648f65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d27cb34a0b474fecbbea352f75142703": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9dc1ccc23f8847c1b6fbc47a9f485373",
      "placeholder": "​",
      "style": "IPY_MODEL_183498c56b9b47a88be92bc1bacd0cca",
      "value": " 2.32G/2.32G [00:59&lt;00:00, 59.1MB/s]"
     }
    },
    "d3233dac7f024ac29a9bd4f34c02c8c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d3e8ca177ea94d3281e4baf365cd2078": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d41217326bbc4552878e955f31fed033": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_10e8e5d0112649a6998e829ec7d16a45",
       "IPY_MODEL_36c4f9b4c473493992ca608e6dad1fb2",
       "IPY_MODEL_1290b76a455f4f349338946ee08041d6"
      ],
      "layout": "IPY_MODEL_d3e8ca177ea94d3281e4baf365cd2078"
     }
    },
    "d44ff8e83b9d433a873b10b7e92bef4d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5b319fe32e14836b99c7cc13c69d8c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c0cf9b496d144382a4f2083b7e72ff4f",
       "IPY_MODEL_ce18c7064dd74f089689e10d1f5aea7c",
       "IPY_MODEL_91326534b61d47b9be2106d32f1ca7b6"
      ],
      "layout": "IPY_MODEL_db0e2bd1244e455e9e5b7918fadfcc93"
     }
    },
    "d806b3a8d9f0431d8861acee5962bcf3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d88d8bfdb4ec4bd8b002c018fc5c0a66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_803fc165e3164175927cf4afb72f2c12",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fcfb477f396d4d1e812a0a631f31362f",
      "value": 1
     }
    },
    "d8dfa8714e22456ebfecad383b40f737": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7df05a1780f24b80a1f1f4b67fffaed1",
      "max": 1670,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_566c113518b64a979b19a932e1af7251",
      "value": 1670
     }
    },
    "d8fc7192f40748899681df2bd01e79b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db069c410e1948b9b1e5fc597fc1bd44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db0e2bd1244e455e9e5b7918fadfcc93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db13c86da84b442581e1c43295e36ea8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69d8af7e0b3c47a08f23fa3e562c8655",
      "placeholder": "​",
      "style": "IPY_MODEL_765a33db0ac646598051efc89d14e56e",
      "value": "ft-q4_k_m.gguf: 100%"
     }
    },
    "dddef5b605114e7584afb948c0db964e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df10a926ca754fe99456e53521d4d94d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df2749eb46d74c85a57b8bd3c61a76fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e01eeacbdedc4eb189b6d002b2bf1a6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e026e63e2cba4d53abe032fe47c6fe59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1f2736db8d24e159e3dc074dbb8c032",
      "placeholder": "​",
      "style": "IPY_MODEL_5fcedce52f1b423a995eef9725a5ea4a",
      "value": " 1.46G/1.46G [00:36&lt;00:00, 43.4MB/s]"
     }
    },
    "e0eba376927048dfb4ed23363c45e122": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0f21439d9df4265adb93e99983d2a82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fcd2bb823bc94d62a45189d478bcada4",
      "placeholder": "​",
      "style": "IPY_MODEL_5bd2d31bf2aa4fafa78e598d931ed4ee",
      "value": "README.md: 100%"
     }
    },
    "e186637138f646c8aa9e7c6151ca2d64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3fb78b8f953d44cf95d853e5fec926fe",
      "placeholder": "​",
      "style": "IPY_MODEL_c8753847ff9747f0a4b491ee41e2b98c",
      "value": " 1.67k/1.67k [00:00&lt;00:00, 149kB/s]"
     }
    },
    "e268de2ba38144ce968a0eb6719b0e8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3a5b729d477047249f880eae85bdabc3",
       "IPY_MODEL_1378b3a8765c4c4d8b0f3bfb44495032",
       "IPY_MODEL_0eb24510fd144cb88c565e35be4e2f12"
      ],
      "layout": "IPY_MODEL_cbc8f36449104deab1e791f70a67e58e"
     }
    },
    "e2f30b8dafa64954b6803a3286b8bf01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e339372b085c432598a97dfd00dcb662": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68822745572944bebcbc787374e61425",
      "placeholder": "​",
      "style": "IPY_MODEL_f1b4287abdec4f32bfc3c106a2720fdd",
      "value": "Upload 3 LFS files: 100%"
     }
    },
    "e465145941694efc842e5ffef949376c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e546e41db58046aaa0676d4e3f5d5ad2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6450d08b424417882aafd2f5949a41e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e339372b085c432598a97dfd00dcb662",
       "IPY_MODEL_7ae0c882155c4f9d955559ef8b81d209",
       "IPY_MODEL_b4710c592a9d4816a40e1932707f934a"
      ],
      "layout": "IPY_MODEL_6b8bb3f6c0e747fab63d02da68677ee5"
     }
    },
    "e766b80163cc4ed583e33fa4f90ca608": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a15e4161972427f83023fac141a7af7",
      "max": 20919,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5a7643587f704932bc6a8c47f58e720b",
      "value": 20919
     }
    },
    "e97e42daf542446993b8d33fc2f20313": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e996b5f33a8f4d8bb2a6f9ef961767e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f460bfcb90f4fd999546a9240ec44aa",
      "placeholder": "​",
      "style": "IPY_MODEL_2902cfa699974bd3a8cd42f4162e0578",
      "value": " 6.43G/6.43G [04:39&lt;00:00, 24.1MB/s]"
     }
    },
    "eacb9bcf8be541828ff3a55006bb2463": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e0f21439d9df4265adb93e99983d2a82",
       "IPY_MODEL_71652bc242fc4fa9abc02a6ef71619a3",
       "IPY_MODEL_af3c4516c0354ab3a4d5770d51ad2104"
      ],
      "layout": "IPY_MODEL_e01eeacbdedc4eb189b6d002b2bf1a6d"
     }
    },
    "eb1ebacb23324f35a1dcfd584d6ff70f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eb5693ff20c14e24a210f2e2518780c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_400561504e604ed183c799bd4dcb32ba",
      "placeholder": "​",
      "style": "IPY_MODEL_72dad2cfe6af48688783eef9b888feef",
      "value": " 844/844 [00:00&lt;00:00, 113kB/s]"
     }
    },
    "ecbd6647c0dc4516a733dd419d7c734d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecff251e35b34c0fb57a1aecad825a0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0f8a62fd50574c038a40112963aa6cca",
       "IPY_MODEL_63ad5d7b259a4e93b71de386c99f3721",
       "IPY_MODEL_d27cb34a0b474fecbbea352f75142703"
      ],
      "layout": "IPY_MODEL_3730040ac5bb44c69845296cea8944e2"
     }
    },
    "ed0325dd08a44a68a54dca6ab6bc1ad7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e6e9450b6264254960b0296233c74c6",
      "placeholder": "​",
      "style": "IPY_MODEL_b9f84ab2f3d047efbf3a1edf053af384",
      "value": "generation_config.json: 100%"
     }
    },
    "ee3092c7a3784539937b00165544bd1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee790f82326c4803bf90ac780e93fb44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eed9bfba30384489bc0b451721983052": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "efce22dcc28940308b68de05be92aad2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94757b8abe5740279b628bf414f0cc04",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5a87181b3a1a408a8a1ce205defdc239",
      "value": 4
     }
    },
    "f01ed6bdd5904f60a0ab9b197befbd30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7aaf02e821b04233a2d25eba17a8ef44",
      "placeholder": "​",
      "style": "IPY_MODEL_8bc8765ea4fd4e2b9ae74deabc50bc12",
      "value": "adapter_model.safetensors: 100%"
     }
    },
    "f1b4287abdec4f32bfc3c106a2720fdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f1dc578700a7412d9b8ac8e90e8bda5b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f36b22b0a75344338a5706612e83a169": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_27949bec6bff45739a51f787121387a6",
       "IPY_MODEL_efce22dcc28940308b68de05be92aad2",
       "IPY_MODEL_aca3db0575ff40aa9536142677590ce0"
      ],
      "layout": "IPY_MODEL_088c8a35a2fe47679849d702fbb8160b"
     }
    },
    "f3d4eb4aa71349e29ab6fb1b7d2f7646": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f6286ff0daa3470194da5d945fceb31e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f684efaa68d140db96ffd07c16432da0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1dc578700a7412d9b8ac8e90e8bda5b",
      "placeholder": "​",
      "style": "IPY_MODEL_9e8613fe87e5437ba0b56054ae589b64",
      "value": "model-00001-of-00002.safetensors: 100%"
     }
    },
    "f6d32088da8c42259971d83f977740af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9a08546be624b909257a7b2a44f98d3",
      "placeholder": "​",
      "style": "IPY_MODEL_df2749eb46d74c85a57b8bd3c61a76fd",
      "value": " 9.09M/9.09M [00:00&lt;00:00, 22.7MB/s]"
     }
    },
    "f772c8f163214fdd8e4d8845bf037ced": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f901ca0e497c4a37912a2c72844582dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dddef5b605114e7584afb948c0db964e",
      "placeholder": "​",
      "style": "IPY_MODEL_c87685ed41d64896828f6a3a9045a0a0",
      "value": ".gitattributes: 100%"
     }
    },
    "f974c4bc87af4bb29e36e1b4cbfed50a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fae2590ce87d4f67bad72279a3bfcbc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb087ed8f6d24e0895edf7425c77c427": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_575ce6cb0fde466484f4f25ff2d655b5",
      "placeholder": "​",
      "style": "IPY_MODEL_5e5a51d1354640848401b103901d381e",
      "value": " 17.2M/17.2M [00:00&lt;00:00, 31.0MB/s]"
     }
    },
    "fc8348e8f2c64404bfb99770882f8a9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fc95a715f5dc44908ecd59830814938f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e3950d23a014c808af0e525f6712253",
      "placeholder": "​",
      "style": "IPY_MODEL_3347f53c397543c9b07b7cfaa30acac3",
      "value": "tokenizer.json: 100%"
     }
    },
    "fcd2bb823bc94d62a45189d478bcada4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcfb477f396d4d1e812a0a631f31362f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fe1dbdc202a747f58ad6504fb7391a38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe724c782e5046b5b8620ae89dd95fc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "feeacebb2051403693905f5108ffa216": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_066899c1d2474d61976be431588b678a",
      "placeholder": "​",
      "style": "IPY_MODEL_7234a61c87304727ba52bcbbd0237c59",
      "value": " 4.97G/4.97G [01:27&lt;00:00, 116MB/s]"
     }
    },
    "ff37f5ae2bec4e34981d12a9e40cb1f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64f79a712cd84e5caaee582a2302ab26",
      "placeholder": "​",
      "style": "IPY_MODEL_cf290aa1a7e041a4a8f83c2a7ffaa5ef",
      "value": " 6.43G/6.43G [02:20&lt;00:00, 60.1MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
